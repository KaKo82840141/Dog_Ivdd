{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632d690d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f101cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_7420\\3365079893.py:22: The name tf.disable_v2_behavior is deprecated. Please use tf.compat.v1.disable_v2_behavior instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\admin\\anaconda3\\envs\\ML2\\Lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "--- [STEP 1] ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŒ²ç”» ---\n",
      "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã‚’åˆã‚ã›ã¦ãã ã•ã„ã€‚\n",
      "  's'ã‚­ãƒ¼: éŒ²ç”»é–‹å§‹\n",
      "  'e'ã‚­ãƒ¼: éŒ²ç”»åœæ­¢\n",
      "  'q'ã‚­ãƒ¼: ãƒ—ãƒ­ã‚°ãƒ©ãƒ çµ‚äº†\n",
      "\n",
      "[éŒ²ç”»é–‹å§‹] -> ä¿å­˜å…ˆ: c:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\Inference_Pipeline\\recorded_videos\\rec_20251011_104113.mp4\n",
      "[éŒ²ç”»çµ‚äº†]\n",
      "\n",
      "--- [STEP 2] MediaPipeã«ã‚ˆã‚‹éª¨æ ¼åº§æ¨™ã®æŠ½å‡º ---\n",
      "å‡¦ç†ä¸­ã®å‹•ç”»: c:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\Inference_Pipeline\\recorded_videos\\rec_20251011_104113.mp4\n",
      "\n",
      "ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: module 'google.protobuf.message_factory' has no attribute 'GetMessageClass'\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã™ã¹ã¦ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "import sys\n",
    "sys.path.insert(0, 'C:\\\\Users\\\\admin\\\\anaconda3\\\\envs\\\\final\\\\lib\\\\site-packages')\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "\n",
    "# TensorFlow 1.xç³»ã®è­¦å‘Šã‚’æŠ‘åˆ¶ã—ã€GPUã‚’ä½¿ç”¨ã—ãªã„ã‚ˆã†ã«è¨­å®š\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "# TensorFlow 1.xç³»ã®é–¢æ•°ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã®ãŠã¾ã˜ãªã„ (tf.contribã‚„tf.nn.rnn_cellã‚’ä½¿ã†ãŸã‚)\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "## ------------------------------------------------------------------------------------\n",
    "## --- ç·åˆè¨­å®š (â˜…â˜… ã“ã“ã‚’ã‚ãªãŸã®ç’°å¢ƒã«åˆã‚ã›ã¦å¿…ãšå¤‰æ›´ã—ã¦ãã ã•ã„) ---\n",
    "## ------------------------------------------------------------------------------------\n",
    "\n",
    "# 1. å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‘ã‚¹\n",
    "# (ä¾‹: \"C:\\\\Users\\\\your_name\\\\weights\\\\model.ckpt\")\n",
    "MODEL_PATH = r\"C:\\\\Users\\\\admin\\\\Downloads\\\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\\\weights\\\\model.ckpt\"\n",
    "\n",
    "# 2. ãƒ©ãƒ™ãƒ«ã®å®šç¾© (å­¦ç¿’æ™‚ã¨å®Œå…¨ã«åŒã˜é †ç•ªãƒ»å†…å®¹ã«ã—ã¦ãã ã•ã„)\n",
    "LABELS = [\n",
    "    \"ageru\", \"understand\", \"annsinnsuru\", \"heavy\"\n",
    "]\n",
    "\n",
    "# 3. ä¸­é–“ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»æœ€çµ‚çš„ãªæ¨è«–ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã™ã‚‹è¦ªãƒ•ã‚©ãƒ«ãƒ€\n",
    "# ã“ã®ãƒ•ã‚©ãƒ«ãƒ€å†…ã« 'recorded_videos', 'json_output' ãªã©ã®ãƒ•ã‚©ãƒ«ãƒ€ãŒè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã™ã€‚\n",
    "BASE_OUTPUT_DIR = os.path.join(os.getcwd(), \"Inference_Pipeline\")\n",
    "\n",
    "# 4. ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š (å­¦ç¿’æ™‚ã¨å®Œå…¨ã«åŒã˜ã«ã—ã¦ãã ã•ã„)\n",
    "SEQUENCE_LENGTH = 30  # 1å‹•ç”»ã‚ãŸã‚Šã®ãƒ•ãƒ¬ãƒ¼ãƒ æ•°\n",
    "N_HIDDEN = 30         # LSTMã®éš ã‚Œå±¤ã®æ•°\n",
    "\n",
    "## ------------------------------------------------------------------------------------\n",
    "## --- STEP 1: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŒ²ç”» (realtime.ipynb) ---\n",
    "## ------------------------------------------------------------------------------------\n",
    "def record_video(save_dir, sequence_length):\n",
    "    \"\"\"\n",
    "    Webã‚«ãƒ¡ãƒ©ã‹ã‚‰å‹•ç”»ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§éŒ²ç”»ã—ã€æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜ã™ã‚‹é–¢æ•°ã€‚\n",
    "    's'ã‚­ãƒ¼ã§éŒ²ç”»é–‹å§‹ã€'e'ã‚­ãƒ¼ã§éŒ²ç”»åœæ­¢ã€‚\n",
    "    Returns:\n",
    "        str: ä¿å­˜ã•ã‚ŒãŸå‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ãƒ«ãƒ‘ã‚¹ã€‚éŒ²ç”»ã•ã‚Œãªã‹ã£ãŸå ´åˆã¯Noneã€‚\n",
    "    \"\"\"\n",
    "    print(\"--- [STEP 1] ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŒ²ç”» ---\")\n",
    "    print(\"ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã‚’åˆã‚ã›ã¦ãã ã•ã„ã€‚\")\n",
    "    print(\"  's'ã‚­ãƒ¼: éŒ²ç”»é–‹å§‹\")\n",
    "    print(\"  'e'ã‚­ãƒ¼: éŒ²ç”»åœæ­¢\")\n",
    "    print(\"  'q'ã‚­ãƒ¼: ãƒ—ãƒ­ã‚°ãƒ©ãƒ çµ‚äº†\")\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"ã‚¨ãƒ©ãƒ¼: ã‚«ãƒ¡ãƒ©ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸã€‚\")\n",
    "        return None\n",
    "\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = 30.0\n",
    "\n",
    "    video_writer = None\n",
    "    is_recording = False\n",
    "    saved_filepath = None\n",
    "\n",
    "    # ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"ã‚¨ãƒ©ãƒ¼: ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’èª­ã¿å–ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚\")\n",
    "            break\n",
    "\n",
    "        display_frame = frame.copy()\n",
    "        \n",
    "        # éŒ²ç”»ä¸­ã®è¡¨ç¤º\n",
    "        if is_recording:\n",
    "            cv2.circle(display_frame, (40, 40), 15, (0, 0, 255), -1)\n",
    "            cv2.putText(display_frame, 'REC', (70, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            if video_writer:\n",
    "                video_writer.write(frame)\n",
    "\n",
    "        cv2.imshow('Real-time Video Recorder', display_frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == ord('s') and not is_recording:\n",
    "            is_recording = True\n",
    "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"rec_{timestamp}.mp4\"\n",
    "            saved_filepath = os.path.join(save_dir, filename)\n",
    "            \n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            video_writer = cv2.VideoWriter(saved_filepath, fourcc, fps, (frame_width, frame_height))\n",
    "            print(f\"\\n[éŒ²ç”»é–‹å§‹] -> ä¿å­˜å…ˆ: {saved_filepath}\")\n",
    "\n",
    "        elif key == ord('e') and is_recording:\n",
    "            print(\"[éŒ²ç”»çµ‚äº†]\")\n",
    "            is_recording = False\n",
    "            if video_writer:\n",
    "                video_writer.release()\n",
    "                video_writer = None\n",
    "            break # éŒ²ç”»ãŒçµ‚ã‚ã£ãŸã‚‰ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹\n",
    "\n",
    "        elif key == ord('q'):\n",
    "            print(\"ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’çµ‚äº†ã—ã¾ã™ã€‚\")\n",
    "            if video_writer:\n",
    "                video_writer.release()\n",
    "            saved_filepath = None # é€”ä¸­ã§çµ‚äº†ã—ãŸã®ã§ãƒ‘ã‚¹ã‚’ã‚¯ãƒªã‚¢\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return saved_filepath\n",
    "\n",
    "## ------------------------------------------------------------------------------------\n",
    "## --- STEP 2: MediaPipeã«ã‚ˆã‚‹éª¨æ ¼åº§æ¨™ã®æŠ½å‡º (Mediapipesyuwa_OC.ipynb) ---\n",
    "## ------------------------------------------------------------------------------------\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results\n",
    "\n",
    "def extract_keypoints(results):\n",
    "    keypoints = {}\n",
    "    # ä¸¡æ‰‹ã®ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã®ã¿ã‚’æŠ½å‡º\n",
    "    keypoints[\"left_hand\"] = [{\"id\": i, \"x\": res.x, \"y\": res.y, \"z\": res.z} for i, res in enumerate(results.left_hand_landmarks.landmark)] if results.left_hand_landmarks else []\n",
    "    keypoints[\"right_hand\"] = [{\"id\": i, \"x\": res.x, \"y\": res.y, \"z\": res.z} for i, res in enumerate(results.right_hand_landmarks.landmark)] if results.right_hand_landmarks else []\n",
    "    return keypoints\n",
    "\n",
    "def extract_landmarks_from_video(video_path, json_output_dir_base, sequence_length):\n",
    "    \"\"\"\n",
    "    å˜ä¸€ã®å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰MediaPipeã§æ‰‹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’æŠ½å‡ºã—ã€JSONãƒ•ã‚¡ã‚¤ãƒ«ç¾¤ã¨ã—ã¦ä¿å­˜ã™ã‚‹ã€‚\n",
    "    Returns:\n",
    "        str: JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒä¿å­˜ã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ã€‚\n",
    "    \"\"\"\n",
    "    print(\"\\n--- [STEP 2] MediaPipeã«ã‚ˆã‚‹éª¨æ ¼åº§æ¨™ã®æŠ½å‡º ---\")\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"ã‚¨ãƒ©ãƒ¼: å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {video_path}\")\n",
    "        return None\n",
    "\n",
    "    video_filename = os.path.basename(video_path)\n",
    "    video_name_no_ext = os.path.splitext(video_filename)[0]\n",
    "    \n",
    "    # ã“ã®å‹•ç”»ç”¨ã®JSONä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ\n",
    "    video_json_save_path = os.path.join(json_output_dir_base, video_name_no_ext)\n",
    "    os.makedirs(video_json_save_path, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    print(f\"å‡¦ç†ä¸­ã®å‹•ç”»: {video_path}\")\n",
    "\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        for frame_num in range(sequence_length):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(f\"è­¦å‘Š: å‹•ç”»ãŒ{sequence_length}ãƒ•ãƒ¬ãƒ¼ãƒ ã‚ˆã‚Šå‰ã«çµ‚äº†ã—ã¾ã—ãŸã€‚\")\n",
    "                break\n",
    "\n",
    "            _, results = mediapipe_detection(frame, holistic)\n",
    "            \n",
    "            keypoints = extract_keypoints(results)\n",
    "            json_path = os.path.join(video_json_save_path, f'{frame_num}.json')\n",
    "            with open(json_path, 'w') as f:\n",
    "                json.dump(keypoints, f, indent=4)\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ãŒå®Œäº†ã—ã¾ã—ãŸ: {video_json_save_path}\")\n",
    "    return video_json_save_path\n",
    "\n",
    "## ------------------------------------------------------------------------------------\n",
    "## --- STEP 3: JSONã‹ã‚‰å˜ä¸€TXTãƒ•ã‚¡ã‚¤ãƒ«ã¸å¤‰æ› (convert_json_to_text4.ipynb) ---\n",
    "## ------------------------------------------------------------------------------------\n",
    "def convert_json_to_txt(json_frames_dir, txt_output_dir):\n",
    "    \"\"\"\n",
    "    ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ç¾¤ã‚’ã€1è¡Œ1ãƒ•ãƒ¬ãƒ¼ãƒ ã®å˜ä¸€TXTãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›ã™ã‚‹ã€‚\n",
    "    Returns:\n",
    "        str: ç”Ÿæˆã•ã‚ŒãŸTXTãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã€‚\n",
    "    \"\"\"\n",
    "    print(\"\\n--- [STEP 3] JSONã‹ã‚‰å˜ä¸€TXTãƒ•ã‚¡ã‚¤ãƒ«ã¸å¤‰æ› ---\")\n",
    "    if not os.path.isdir(json_frames_dir):\n",
    "        print(f\"ã‚¨ãƒ©ãƒ¼: JSONãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {json_frames_dir}\")\n",
    "        return None\n",
    "\n",
    "    video_folder_name = os.path.basename(json_frames_dir)\n",
    "    os.makedirs(txt_output_dir, exist_ok=True)\n",
    "    \n",
    "    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹\n",
    "    output_txt_path = os.path.join(txt_output_dir, f\"{video_folder_name}.txt\")\n",
    "\n",
    "    NUM_KEYPOINTS_PER_HAND = 21\n",
    "    \n",
    "    kps_all_frames = []\n",
    "    \n",
    "    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ•ãƒ¬ãƒ¼ãƒ é †ï¼ˆ0.json, 1.json, ...ï¼‰ã«ã‚½ãƒ¼ãƒˆã—ã¦å–å¾—\n",
    "    json_files = sorted(\n",
    "        glob.glob(os.path.join(json_frames_dir, \"*.json\")), \n",
    "        key=lambda x: int(os.path.splitext(os.path.basename(x))[0])\n",
    "    )\n",
    "\n",
    "    if not json_files:\n",
    "        print(f\"è­¦å‘Š: JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™: {json_frames_dir}\")\n",
    "        return None\n",
    "        \n",
    "    for json_file_path in json_files:\n",
    "        with open(json_file_path) as data_file:\n",
    "            data = json.load(data_file)\n",
    "            frame_kps_hands = []\n",
    "            \n",
    "            # å·¦æ‰‹ (x, yã®ã¿)\n",
    "            left_hand = data.get(\"left_hand\", [])\n",
    "            if left_hand:\n",
    "                for kp in left_hand:\n",
    "                    frame_kps_hands.extend([kp.get('x', 0.0), kp.get('y', 0.0)])\n",
    "            else:\n",
    "                frame_kps_hands.extend([0.0] * (NUM_KEYPOINTS_PER_HAND * 2))\n",
    "\n",
    "            # å³æ‰‹ (x, yã®ã¿)\n",
    "            right_hand = data.get(\"right_hand\", [])\n",
    "            if right_hand:\n",
    "                for kp in right_hand:\n",
    "                    frame_kps_hands.extend([kp.get('x', 0.0), kp.get('y', 0.0)])\n",
    "            else:\n",
    "                frame_kps_hands.extend([0.0] * (NUM_KEYPOINTS_PER_HAND * 2))\n",
    "                \n",
    "            kps_all_frames.append(frame_kps_hands)\n",
    "\n",
    "    # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿\n",
    "    with open(output_txt_path, \"w\") as text_file:\n",
    "        for frame_data in kps_all_frames:\n",
    "            line = \",\".join(map(str, frame_data))\n",
    "            text_file.write(line + '\\n')\n",
    "            \n",
    "    print(f\"TXTãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®å¤‰æ›ãŒå®Œäº†ã—ã¾ã—ãŸ: {output_txt_path}\")\n",
    "    return output_txt_path\n",
    "\n",
    "## ------------------------------------------------------------------------------------\n",
    "## --- STEP 4: æ¨è«–ç”¨ãƒ‡ãƒ¼ã‚¿(X_val.txt)ã®ä½œæˆ (create_db4_1senkeihokan.ipynb) ---\n",
    "## ------------------------------------------------------------------------------------\n",
    "def prepare_data_for_lstm(source_txt_path, final_output_path, num_steps, overlap=0.8125):\n",
    "    \"\"\"\n",
    "    å˜ä¸€ã®TXTãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ç·šå½¢è£œé–“ã¨ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’é©ç”¨ã—ã¦\n",
    "    LSTMæ¨è«–ç”¨ã®æœ€çµ‚çš„ãªå…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«(X_val.txt)ã‚’ä½œæˆã™ã‚‹ã€‚\n",
    "    Returns:\n",
    "        bool: æˆåŠŸã—ãŸå ´åˆã¯Trueã€å¤±æ•—ã—ãŸå ´åˆã¯Falseã€‚\n",
    "    \"\"\"\n",
    "    print(\"\\n--- [STEP 4] æ¨è«–ç”¨ãƒ‡ãƒ¼ã‚¿(X_val.txt)ã®ä½œæˆ ---\")\n",
    "    if not os.path.exists(source_txt_path):\n",
    "        print(f\"ã‚¨ãƒ©ãƒ¼: ã‚½ãƒ¼ã‚¹TXTãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {source_txt_path}\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€0.0ã‚’NaNã¨ã—ã¦æ‰±ã†\n",
    "        data_df = pd.read_csv(source_txt_path, header=None, na_values=0.0)\n",
    "        \n",
    "        # ç·šå½¢è£œé–“\n",
    "        data_df.interpolate(method='linear', axis=0, inplace=True, limit_direction='both')\n",
    "        # ãã‚Œã§ã‚‚æ®‹ã£ã¦ã„ã‚‹NaNã‚’0.0ã§åŸ‹ã‚ã‚‹\n",
    "        data_df.fillna(0.0, inplace=True)\n",
    "        \n",
    "        num_frames = len(data_df)\n",
    "        if num_frames < num_steps:\n",
    "            print(f\"ã‚¨ãƒ©ãƒ¼: ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™({num_frames}ãƒ•ãƒ¬ãƒ¼ãƒ )ã€‚æœ€ä½{num_steps}ãƒ•ãƒ¬ãƒ¼ãƒ å¿…è¦ã§ã™ã€‚\")\n",
    "            return False\n",
    "\n",
    "        # ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ç”Ÿæˆ\n",
    "        step_size = int(num_steps * (1 - overlap))\n",
    "        if step_size < 1: step_size = 1 # ã‚¼ãƒ­é™¤ç®—ã‚’é¿ã‘ã‚‹\n",
    "        \n",
    "        sequences = []\n",
    "        for start_frame in range(0, num_frames - num_steps + 1, step_size):\n",
    "            end_frame = start_frame + num_steps\n",
    "            sequence = data_df.iloc[start_frame:end_frame].values\n",
    "            sequences.append(sequence) # flattenã—ãªã„\n",
    "        \n",
    "        if not sequences:\n",
    "            print(\"ã‚¨ãƒ©ãƒ¼: ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\")\n",
    "            return False\n",
    "\n",
    "        # æœ€çµ‚çš„ãªãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿\n",
    "        with open(final_output_path, 'w') as f:\n",
    "            for seq in sequences:\n",
    "                np.savetxt(f, seq, delimiter=',')\n",
    "        \n",
    "        print(f\"{len(sequences)}å€‹ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ç”Ÿæˆã—ã€æ¨è«–ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¾ã—ãŸ: {final_output_path}\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ãƒ‡ãƒ¼ã‚¿æº–å‚™ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")\n",
    "        return False\n",
    "\n",
    "## ------------------------------------------------------------------------------------\n",
    "## --- STEP 5: LSTMãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹æ¨è«– (suiron.ipynb) ---\n",
    "## ------------------------------------------------------------------------------------\n",
    "def run_inference(x_val_path, model_path, labels, n_steps, n_hidden):\n",
    "    \"\"\"\n",
    "    æº–å‚™ã•ã‚ŒãŸæ¨è«–ç”¨ãƒ‡ãƒ¼ã‚¿ã¨å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€æ‰‹è©±ã®æ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹ã€‚\n",
    "    \"\"\"\n",
    "    print(\"\\n--- [STEP 5] LSTMãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹æ¨è«– ---\")\n",
    "    \n",
    "    n_classes = len(labels)\n",
    "    \n",
    "    # -- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° --\n",
    "    def load_X(X_path):\n",
    "        try:\n",
    "            X_ = np.loadtxt(X_path, delimiter=',', dtype=np.float32)\n",
    "            blocks = int(len(X_) / n_steps)\n",
    "            X_ = np.array(np.split(X_, blocks))\n",
    "            return X_\n",
    "        except FileNotFoundError:\n",
    "            print(f\"ã‚¨ãƒ©ãƒ¼: æ¨è«–ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ - {X_path}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")\n",
    "            return None\n",
    "\n",
    "    def LSTM_RNN(_X, _weights, _biases, n_input):\n",
    "        _X = tf.transpose(_X, [1, 0, 2])\n",
    "        _X = tf.reshape(_X, [-1, n_input])\n",
    "        _X = tf.nn.relu(tf.matmul(_X, _weights['hidden']) + _biases['hidden'])\n",
    "        _X = tf.split(_X, n_steps, 0)\n",
    "        \n",
    "        lstm_cell_1 = tf.nn.rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
    "        lstm_cell_2 = tf.nn.rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
    "        lstm_cells = tf.nn.rnn_cell.MultiRNNCell([lstm_cell_1, lstm_cell_2], state_is_tuple=True)\n",
    "        \n",
    "        outputs, _ = tf.nn.static_rnn(lstm_cells, _X, dtype=tf.float32)\n",
    "        lstm_last_output = outputs[-1]\n",
    "        return tf.matmul(lstm_last_output, _weights['out']) + _biases['out']\n",
    "\n",
    "    # -- ãƒ¡ã‚¤ãƒ³å‡¦ç† --\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    X_val = load_X(x_val_path)\n",
    "    if X_val is None or len(X_val) == 0:\n",
    "        print(\"æ¨è«–ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ã€å‡¦ç†ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚\")\n",
    "        return\n",
    "\n",
    "    n_input = X_val.shape[2]\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, [None, n_steps, n_input])\n",
    "    \n",
    "    weights = {\n",
    "        'hidden': tf.Variable(tf.random_normal([n_input, n_hidden])),\n",
    "        'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "    }\n",
    "    biases = {\n",
    "        'hidden': tf.Variable(tf.random_normal([n_hidden])),\n",
    "        'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "    }\n",
    "    \n",
    "    pred = LSTM_RNN(x, weights, biases, n_input)\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        try:\n",
    "            saver.restore(sess, model_path)\n",
    "            print(f\"ãƒ¢ãƒ‡ãƒ«ã‚’æ­£å¸¸ã«å¾©å…ƒã—ã¾ã—ãŸ: {model_path}\")\n",
    "\n",
    "            one_hot_predictions = sess.run(pred, feed_dict={x: X_val})\n",
    "            predictions = np.argmax(one_hot_predictions, axis=1)\n",
    "\n",
    "            print(\"\\n--- [æœ€çµ‚æ¨è«–çµæœ] ---\")\n",
    "            \n",
    "            # å„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®äºˆæ¸¬çµæœã‹ã‚‰ã€æœ€ã‚‚å¤šãäºˆæ¸¬ã•ã‚ŒãŸãƒ©ãƒ™ãƒ«ã‚’æœ€çµ‚çµæœã¨ã™ã‚‹\n",
    "            if len(predictions) > 0:\n",
    "                counts = np.bincount(predictions, minlength=n_classes)\n",
    "                final_prediction_index = np.argmax(counts)\n",
    "                final_prediction_label = labels[final_prediction_index]\n",
    "                print(f\"ğŸ‘‰ éŒ²ç”»ã•ã‚ŒãŸæ‰‹è©±ã®å‹•ä½œã¯ã€ {final_prediction_label} ã€ã®å¯èƒ½æ€§ãŒé«˜ã„ã§ã™ã€‚\")\n",
    "            else:\n",
    "                print(\"äºˆæ¸¬å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"ãƒ¢ãƒ‡ãƒ«ã®å¾©å…ƒã¾ãŸã¯æ¨è«–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")\n",
    "            print(\"MODEL_PATHãŒæ­£ã—ã„ã‹ã€å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚\")\n",
    "\n",
    "## ------------------------------------------------------------------------------------\n",
    "## --- ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œãƒ¡ã‚¤ãƒ³å‡¦ç† ---\n",
    "## ------------------------------------------------------------------------------------\n",
    "if __name__ == '__main__':\n",
    "    # å„ã‚¹ãƒ†ãƒƒãƒ—ã§ä½¿ç”¨ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æº–å‚™\n",
    "    video_save_dir = os.path.join(BASE_OUTPUT_DIR, \"recorded_videos\")\n",
    "    json_output_dir = os.path.join(BASE_OUTPUT_DIR, \"json_output\")\n",
    "    txt_output_dir = os.path.join(BASE_OUTPUT_DIR, \"txt_converted\")\n",
    "    final_input_dir = os.path.join(BASE_OUTPUT_DIR, \"final_input\")\n",
    "    final_x_val_path = os.path.join(final_input_dir, \"X_val.txt\")\n",
    "\n",
    "    for d in [video_save_dir, json_output_dir, txt_output_dir, final_input_dir]:\n",
    "        os.makedirs(d, exist_ok=True)\n",
    "    \n",
    "    # STEP 1: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŒ²ç”»\n",
    "    recorded_video_path = record_video(video_save_dir, SEQUENCE_LENGTH)\n",
    "    \n",
    "    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†\n",
    "    if recorded_video_path:\n",
    "        try:\n",
    "            # STEP 2: MediaPipeã«ã‚ˆã‚‹éª¨æ ¼åº§æ¨™ã®æŠ½å‡º\n",
    "            json_frames_dir = extract_landmarks_from_video(recorded_video_path, json_output_dir, SEQUENCE_LENGTH)\n",
    "            if json_frames_dir is None: raise Exception(\"éª¨æ ¼åº§æ¨™ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚\")\n",
    "\n",
    "            # STEP 3: JSONã‹ã‚‰å˜ä¸€TXTãƒ•ã‚¡ã‚¤ãƒ«ã¸å¤‰æ›\n",
    "            converted_txt_path = convert_json_to_txt(json_frames_dir, txt_output_dir)\n",
    "            if converted_txt_path is None: raise Exception(\"TXTãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸã€‚\")\n",
    "            \n",
    "            # STEP 4: æ¨è«–ç”¨ãƒ‡ãƒ¼ã‚¿(X_val.txt)ã®ä½œæˆ\n",
    "            success = prepare_data_for_lstm(converted_txt_path, final_x_val_path, SEQUENCE_LENGTH)\n",
    "            if not success: raise Exception(\"æ¨è«–ç”¨ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚\")\n",
    "\n",
    "            # STEP 5: LSTMãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹æ¨è«–\n",
    "            run_inference(final_x_val_path, MODEL_PATH, LABELS, SEQUENCE_LENGTH, N_HIDDEN)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\nãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")\n",
    "    else:\n",
    "        print(\"\\néŒ²ç”»ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚ŒãŸãŸã‚ã€å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã—ãŸã€‚\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

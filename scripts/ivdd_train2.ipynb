{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bdc0d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF: 2.19.0\n",
      "[INFO] 使用キーポイント実名: ['tail_set', 'right_tarsal', 'right_paw', 'left_tarsal', 'left_paw']\n",
      "X: (420, 60, 10) y: (420,) files: 82\n",
      "train: (349, 60, 10) val: (71, 60, 10)\n",
      "class_weight: {0: 0.9914772727272727, 1: 1.0086705202312138}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ivdd_lstm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ivdd_lstm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ td_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ logits (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m10\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ td_dense (\u001b[38;5;33mTimeDistributed\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m30\u001b[0m)         │           \u001b[38;5;34m330\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm1 (\u001b[38;5;33mLSTM\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m30\u001b[0m)         │         \u001b[38;5;34m7,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm2 (\u001b[38;5;33mLSTM\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │         \u001b[38;5;34m7,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ logits (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m31\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,001</span> (58.60 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,001\u001b[0m (58.60 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,001</span> (58.60 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,001\u001b[0m (58.60 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m 6/12\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4322 - loss: 0.7058\n",
      "Epoch 1: val_accuracy improved from -inf to 0.67606, saving model to c:\\kanno\\vscode\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\data\\train\\train2_model\\ivdd_lstm_20251225-162504_best.keras\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.4601 - loss: 0.7055 - val_accuracy: 0.6761 - val_loss: 0.7131 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m 7/12\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4371 - loss: 0.7020\n",
      "Epoch 2: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4601 - loss: 0.7026 - val_accuracy: 0.6761 - val_loss: 0.7097 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m 7/12\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4371 - loss: 0.7019\n",
      "Epoch 3: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4601 - loss: 0.7021 - val_accuracy: 0.6761 - val_loss: 0.7064 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4564 - loss: 0.7018 \n",
      "Epoch 4: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4601 - loss: 0.7018 - val_accuracy: 0.6761 - val_loss: 0.7038 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4564 - loss: 0.7015\n",
      "Epoch 5: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4601 - loss: 0.7014 - val_accuracy: 0.6761 - val_loss: 0.7020 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4521 - loss: 0.7010\n",
      "Epoch 6: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4601 - loss: 0.7008 - val_accuracy: 0.6761 - val_loss: 0.7008 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m 7/12\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4371 - loss: 0.7007\n",
      "Epoch 7: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4601 - loss: 0.7001 - val_accuracy: 0.6761 - val_loss: 0.7000 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m 7/12\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4371 - loss: 0.6998\n",
      "Epoch 8: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4601 - loss: 0.6991 - val_accuracy: 0.6761 - val_loss: 0.6995 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4521 - loss: 0.6983\n",
      "Epoch 9: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4601 - loss: 0.6980 - val_accuracy: 0.6761 - val_loss: 0.6992 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4564 - loss: 0.6968\n",
      "Epoch 10: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4601 - loss: 0.6967 - val_accuracy: 0.6761 - val_loss: 0.6991 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4521 - loss: 0.6955\n",
      "Epoch 11: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4601 - loss: 0.6952 - val_accuracy: 0.6761 - val_loss: 0.6991 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4488 - loss: 0.6938\n",
      "Epoch 12: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4601 - loss: 0.6934 - val_accuracy: 0.6761 - val_loss: 0.6992 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m 7/12\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4371 - loss: 0.6918\n",
      "Epoch 13: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4601 - loss: 0.6914 - val_accuracy: 0.6761 - val_loss: 0.6994 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4564 - loss: 0.6890\n",
      "Epoch 14: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4601 - loss: 0.6889 - val_accuracy: 0.6761 - val_loss: 0.6997 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m 9/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4449 - loss: 0.6859\n",
      "Epoch 15: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4601 - loss: 0.6859 - val_accuracy: 0.6761 - val_loss: 0.7001 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4521 - loss: 0.6826\n",
      "Epoch 16: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4601 - loss: 0.6825 - val_accuracy: 0.6761 - val_loss: 0.7004 - learning_rate: 5.0000e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m 9/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4449 - loss: 0.6800\n",
      "Epoch 17: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4601 - loss: 0.6803 - val_accuracy: 0.6761 - val_loss: 0.7008 - learning_rate: 5.0000e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4564 - loss: 0.6778\n",
      "Epoch 18: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4601 - loss: 0.6778 - val_accuracy: 0.6761 - val_loss: 0.7013 - learning_rate: 5.0000e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4564 - loss: 0.6750\n",
      "Epoch 19: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4601 - loss: 0.6750 - val_accuracy: 0.6761 - val_loss: 0.7018 - learning_rate: 5.0000e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m10/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4488 - loss: 0.6715\n",
      "Epoch 20: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4601 - loss: 0.6718 - val_accuracy: 0.6761 - val_loss: 0.7025 - learning_rate: 5.0000e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m 7/12\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4371 - loss: 0.6671\n",
      "Epoch 21: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4601 - loss: 0.6685 - val_accuracy: 0.6761 - val_loss: 0.7028 - learning_rate: 2.5000e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m 8/12\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4408 - loss: 0.6652\n",
      "Epoch 22: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4601 - loss: 0.6664 - val_accuracy: 0.6761 - val_loss: 0.7033 - learning_rate: 2.5000e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4521 - loss: 0.6640\n",
      "Epoch 23: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4601 - loss: 0.6643 - val_accuracy: 0.6761 - val_loss: 0.7037 - learning_rate: 2.5000e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m 8/12\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4408 - loss: 0.6605\n",
      "Epoch 24: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4601 - loss: 0.6620 - val_accuracy: 0.6761 - val_loss: 0.7043 - learning_rate: 2.5000e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m 7/12\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4371 - loss: 0.6575\n",
      "Epoch 25: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4601 - loss: 0.6595 - val_accuracy: 0.6761 - val_loss: 0.7048 - learning_rate: 2.5000e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4521 - loss: 0.6567\n",
      "Epoch 26: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4601 - loss: 0.6572 - val_accuracy: 0.6761 - val_loss: 0.7051 - learning_rate: 1.2500e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4521 - loss: 0.6554\n",
      "Epoch 27: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4601 - loss: 0.6558 - val_accuracy: 0.6761 - val_loss: 0.7054 - learning_rate: 1.2500e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m 6/12\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4322 - loss: 0.6518\n",
      "Epoch 28: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4601 - loss: 0.6544 - val_accuracy: 0.6761 - val_loss: 0.7058 - learning_rate: 1.2500e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m 7/12\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4371 - loss: 0.6504\n",
      "Epoch 29: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4601 - loss: 0.6530 - val_accuracy: 0.6761 - val_loss: 0.7061 - learning_rate: 1.2500e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4521 - loss: 0.6510\n",
      "Epoch 30: val_accuracy did not improve from 0.67606\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4601 - loss: 0.6516 - val_accuracy: 0.6761 - val_loss: 0.7065 - learning_rate: 1.2500e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4564 - loss: 0.6499\n",
      "Epoch 31: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4601 - loss: 0.6502 - val_accuracy: 0.6761 - val_loss: 0.7067 - learning_rate: 1.0000e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m 7/12\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4371 - loss: 0.6459\n",
      "Epoch 32: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4601 - loss: 0.6490 - val_accuracy: 0.6620 - val_loss: 0.7071 - learning_rate: 1.0000e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4564 - loss: 0.6475\n",
      "Epoch 33: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4601 - loss: 0.6478 - val_accuracy: 0.6479 - val_loss: 0.7074 - learning_rate: 1.0000e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m 8/12\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4408 - loss: 0.6439 \n",
      "Epoch 34: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4589 - loss: 0.6465 - val_accuracy: 0.6479 - val_loss: 0.7077 - learning_rate: 1.0000e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4546 - loss: 0.6449\n",
      "Epoch 35: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4579 - loss: 0.6453 - val_accuracy: 0.6479 - val_loss: 0.7080 - learning_rate: 1.0000e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4506 - loss: 0.6433\n",
      "Epoch 36: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4579 - loss: 0.6440 - val_accuracy: 0.6479 - val_loss: 0.7084 - learning_rate: 1.0000e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m 7/12\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4371 - loss: 0.6391\n",
      "Epoch 37: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4579 - loss: 0.6427 - val_accuracy: 0.6197 - val_loss: 0.7087 - learning_rate: 1.0000e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m 7/12\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4335 - loss: 0.6377 \n",
      "Epoch 38: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4545 - loss: 0.6413 - val_accuracy: 0.6197 - val_loss: 0.7091 - learning_rate: 1.0000e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4470 - loss: 0.6392\n",
      "Epoch 39: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4545 - loss: 0.6400 - val_accuracy: 0.6197 - val_loss: 0.7095 - learning_rate: 1.0000e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m 8/12\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4371 - loss: 0.6354\n",
      "Epoch 40: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4545 - loss: 0.6386 - val_accuracy: 0.6197 - val_loss: 0.7099 - learning_rate: 1.0000e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m 7/12\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4335 - loss: 0.6332\n",
      "Epoch 41: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4569 - loss: 0.6372 - val_accuracy: 0.6056 - val_loss: 0.7103 - learning_rate: 1.0000e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m 8/12\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4366 - loss: 0.6324\n",
      "Epoch 42: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4539 - loss: 0.6358 - val_accuracy: 0.6056 - val_loss: 0.7108 - learning_rate: 1.0000e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m 7/12\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4356 - loss: 0.6300\n",
      "Epoch 43: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4584 - loss: 0.6343 - val_accuracy: 0.6056 - val_loss: 0.7112 - learning_rate: 1.0000e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4577 - loss: 0.6318\n",
      "Epoch 44: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4653 - loss: 0.6328 - val_accuracy: 0.5775 - val_loss: 0.7117 - learning_rate: 1.0000e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4649 - loss: 0.6303\n",
      "Epoch 45: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4719 - loss: 0.6313 - val_accuracy: 0.5775 - val_loss: 0.7122 - learning_rate: 1.0000e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m 7/12\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4650 - loss: 0.6250\n",
      "Epoch 46: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4825 - loss: 0.6297 - val_accuracy: 0.5775 - val_loss: 0.7127 - learning_rate: 1.0000e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4840 - loss: 0.6276\n",
      "Epoch 47: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4869 - loss: 0.6281 - val_accuracy: 0.5775 - val_loss: 0.7132 - learning_rate: 1.0000e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m 7/12\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4702 - loss: 0.6215 \n",
      "Epoch 48: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4869 - loss: 0.6265 - val_accuracy: 0.5775 - val_loss: 0.7138 - learning_rate: 1.0000e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4806 - loss: 0.6237\n",
      "Epoch 49: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4869 - loss: 0.6248 - val_accuracy: 0.5634 - val_loss: 0.7144 - learning_rate: 1.0000e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4852 - loss: 0.6220\n",
      "Epoch 50: val_accuracy did not improve from 0.67606\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4917 - loss: 0.6232 - val_accuracy: 0.5493 - val_loss: 0.7149 - learning_rate: 1.0000e-05\n",
      "[INFO] saved curve: c:\\kanno\\vscode\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\data\\train\\fig\\curve_20251225-162504.png\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 314ms/step\n",
      "\n",
      "[Window-level] classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal     0.7692    0.4167    0.5405        48\n",
      "        ivdd     0.3778    0.7391    0.5000        23\n",
      "\n",
      "    accuracy                         0.5211        71\n",
      "   macro avg     0.5735    0.5779    0.5203        71\n",
      "weighted avg     0.6424    0.5211    0.5274        71\n",
      "\n",
      "[Window-level] confusion matrix:\n",
      " [[20 28]\n",
      " [ 6 17]]\n",
      "[INFO] saved misclassified windows: c:\\kanno\\vscode\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\data\\train\\val_misclassified\\val_misclassified_20251225-162504.csv  (rows=34)\n",
      "[INFO] saved final model to: c:\\kanno\\vscode\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\data\\train\\train2_model\\ivdd_lstm_20251225-162504_final.keras\n",
      "[INFO] saved TXT log: c:\\kanno\\vscode\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\data\\train\\train_logs\\train2_log_20251225-162504.txt\n",
      "[DONE] training complete.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "IVDD binary training (ivdd vs normal) - train2 (tail_set-centered + per-file min-max)\n",
    "train1 からの反映点:\n",
    "- TXTログ保存: 設定パラメータ / 学習フレーム数 / 各epochの train/val loss & acc / classification report\n",
    "- ラベル判定: one/two を ivdd として扱う（normal は normal）\n",
    "既存の train2 特徴:\n",
    "- プロジェクトルート自動検出（scripts配下にdataが出来ない）\n",
    "- 学習曲線: loss/acc を1枚のPNGで保存 (fig/curve_YYYYMMDD-HHMMSS.png)\n",
    "- 学習モデル: train2_model に YYYYMMDD-HHMMSS ベース名で best/final を保存\n",
    "- Val誤分類ウィンドウ一覧を train/val_misclassified/val_misclassified_YYYYMMDD-HHMMSS.csv で保存\n",
    "- 正規化（tail_set原点 + 各次元min-max）はそのまま維持\n",
    "\"\"\"\n",
    "\n",
    "# ===== 安定運用: GPU無効/ログ控えめ/スレッド抑制（必要なら） =====\n",
    "import os\n",
    "os.environ.setdefault(\"CUDA_VISIBLE_DEVICES\", \"-1\")\n",
    "os.environ.setdefault(\"TF_CPP_MIN_LOG_LEVEL\", \"2\")\n",
    "os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n",
    "\n",
    "import re, glob\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"TF:\", tf.__version__)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# ========= ルート自動検出（scripts直下で実行してもOK） =========\n",
    "def detect_project_root() -> Path:\n",
    "    env = os.environ.get(\"IVDD_PROJECT_ROOT\")\n",
    "    if env:\n",
    "        p = Path(env).expanduser().resolve()\n",
    "        if (p / \"data\").is_dir() or (p / \"scripts\").is_dir():\n",
    "            return p\n",
    "    try:\n",
    "        here = Path(__file__).resolve()\n",
    "        if here.parent.name == \"scripts\":\n",
    "            cand = here.parent.parent\n",
    "            if (cand / \"data\").is_dir() or (cand / \"scripts\").is_dir():\n",
    "                return cand\n",
    "        if (here.parent / \"data\").is_dir() or (here.parent / \"scripts\").is_dir():\n",
    "            return here.parent\n",
    "    except NameError:\n",
    "        pass\n",
    "    cwd = Path.cwd()\n",
    "    for cand in [cwd] + list(cwd.parents):\n",
    "        if (cand / \"data\").is_dir() and (cand / \"scripts\").is_dir():\n",
    "            return cand\n",
    "    return cwd.parent if cwd.name == \"scripts\" else cwd\n",
    "\n",
    "PROJ_ROOT     = detect_project_root()\n",
    "TRAIN_DIR     = PROJ_ROOT / \"data\" / \"train\"\n",
    "TRAIN_CSV_DIR = TRAIN_DIR / \"train_csv\"\n",
    "FIG_DIR       = TRAIN_DIR / \"fig\"\n",
    "MODEL_DIR     = TRAIN_DIR / \"train2_model\"\n",
    "VALERR_DIR    = TRAIN_DIR / \"val_misclassified\"\n",
    "LOG_DIR       = TRAIN_DIR / \"train_logs\"          # ★ 新設: テキストログ置き場\n",
    "for d in [FIG_DIR, MODEL_DIR, VALERR_DIR, LOG_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CSV_GLOB = str(TRAIN_CSV_DIR / \"*.csv\")\n",
    "\n",
    "# ========= パラメータ =========\n",
    "KEYPOINTS = [\n",
    "    \"tail_set\",\n",
    "    \"right_tarsal\",\n",
    "    \"right_paw\",\n",
    "    \"left_tarsal\",\n",
    "    \"left_paw\",\n",
    "]\n",
    "USE_LIKELIHOOD      = False\n",
    "MIN_KEEP_LIKELIHOOD = 0.6\n",
    "\n",
    "SEQ_LEN   = 60\n",
    "STRIDE    = 30\n",
    "DIMS      = len(KEYPOINTS) * 2   # =10\n",
    "N_HIDDEN  = 30\n",
    "\n",
    "BATCH_SIZE = 30\n",
    "EPOCHS     = 50\n",
    "LR         = 1e-4\n",
    "L2_LAMBDA  = 1e-4\n",
    "\n",
    "VAL_SPLIT_BY_FILE = True\n",
    "\n",
    "# バイナリ: 0=normal, 1=ivdd\n",
    "CLASS_NAMES  = [\"normal\", \"ivdd\"]\n",
    "CLASS_TO_IDX = {\"normal\": 0, \"ivdd\": 1}\n",
    "\n",
    "# ランごとユニークID（日時）\n",
    "DATE_STR = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# ========= ラベル推定 =========\n",
    "def infer_label_from_filename(path: str) -> int:\n",
    "    \"\"\"\n",
    "    ファイル名や親ディレクトリからラベルを推定。\n",
    "    - one / two は ivdd として扱う\n",
    "    - ivdd*, normal* などの先頭トークンも許可\n",
    "    - それ以外でも 'ivdd' / 'normal' の厳密一致トークンがあれば採用\n",
    "    \"\"\"\n",
    "    base = os.path.basename(path).lower()\n",
    "    stem = os.path.splitext(base)[0]\n",
    "    tokens = [t for t in re.split(r'[^a-z0-9]+', stem) if t]\n",
    "\n",
    "    if tokens:\n",
    "        head = tokens[0]\n",
    "        if re.fullmatch(r'(ivdd|one|two)\\d*', head):   # 例: ivdd1, one2 もOK\n",
    "            return CLASS_TO_IDX[\"ivdd\"]\n",
    "        if re.fullmatch(r'normal\\d*', head):\n",
    "            return CLASS_TO_IDX[\"normal\"]\n",
    "\n",
    "    # 他トークンに厳密一致（片方のみヒット時）\n",
    "    if ((\"ivdd\" in tokens) or (\"one\" in tokens) or (\"two\" in tokens)) and (\"normal\" not in tokens):\n",
    "        return CLASS_TO_IDX[\"ivdd\"]\n",
    "    if (\"normal\" in tokens) and not ((\"ivdd\" in tokens) or (\"one\" in tokens) or (\"two\" in tokens)):\n",
    "        return CLASS_TO_IDX[\"normal\"]\n",
    "\n",
    "    # 親ディレクトリも確認\n",
    "    parent_tokens = [t for t in re.split(r'[^a-z0-9]+', os.path.dirname(path).lower()) if t]\n",
    "    if ((\"ivdd\" in parent_tokens) or (\"one\" in parent_tokens) or (\"two\" in parent_tokens)) and (\"normal\" not in parent_tokens):\n",
    "        return CLASS_TO_IDX[\"ivdd\"]\n",
    "    if (\"normal\" in parent_tokens) and not ((\"ivdd\" in parent_tokens) or (\"one\" in parent_tokens) or (\"two\" in parent_tokens)):\n",
    "        return CLASS_TO_IDX[\"normal\"]\n",
    "\n",
    "    # 最後の手段: ivdd/normal の直後が数字なら採用\n",
    "    if re.search(r'(?<![a-z])ivdd(?=\\d)', stem) or re.search(r'(?<![a-z])one(?=\\d)', stem) or re.search(r'(?<![a-z])two(?=\\d)', stem):\n",
    "        return CLASS_TO_IDX[\"ivdd\"]\n",
    "    if re.search(r'(?<![a-z])normal(?=\\d)', stem):\n",
    "        return CLASS_TO_IDX[\"normal\"]\n",
    "\n",
    "    raise ValueError(f\"ラベル不明: {base}（先頭を ivdd_/one_/two_/normal_ などにするか、上の規則に合わせてください）\")\n",
    "\n",
    "# ========= DLC 読み取り & 正規化 =========\n",
    "def _norm_key(s: str) -> str:\n",
    "    \"\"\"比較用: 小文字化 + 空白/アンダー/ハイフンを除去\"\"\"\n",
    "    return \"\".join(ch for ch in s.lower() if ch not in \" _-\")\n",
    "\n",
    "def _resolve_keypoints(all_bodyparts, requested):\n",
    "    norm2orig = {}\n",
    "    for bp in all_bodyparts:\n",
    "        k = _norm_key(bp)\n",
    "        if k not in norm2orig:\n",
    "            norm2orig[k] = bp\n",
    "    resolved, missing = [], []\n",
    "    for req in requested:\n",
    "        k = _norm_key(req)\n",
    "        if k in norm2orig:\n",
    "            resolved.append(norm2orig[k])\n",
    "        else:\n",
    "            missing.append(req)\n",
    "    if missing:\n",
    "        raise ValueError(f\"指定キーポイントがCSVに見つかりません: {missing}\\n利用可能: {all_bodyparts}\")\n",
    "    return resolved\n",
    "\n",
    "def read_dlc_5kp_xy(csv_path: str, keypoints, use_likelihood=True, min_keep_likelihood=0.6):\n",
    "    df = pd.read_csv(csv_path, header=[0,1,2], index_col=0)\n",
    "    bodyparts = list({bp for (_, bp, _) in df.columns})\n",
    "    use_kps = _resolve_keypoints(bodyparts, keypoints)\n",
    "\n",
    "    cols = {}\n",
    "    for bp in use_kps:\n",
    "        cols[f\"{bp}_x\"] = df.xs((bp, \"x\"), level=[1,2], axis=1)\n",
    "        cols[f\"{bp}_y\"] = df.xs((bp, \"y\"), level=[1,2], axis=1)\n",
    "    X_df = pd.concat(cols.values(), axis=1)\n",
    "    X_df.columns = list(cols.keys())\n",
    "\n",
    "    if use_likelihood:\n",
    "        for bp in use_kps:\n",
    "            try:\n",
    "                lcol = df.xs((bp, \"likelihood\"), level=[1,2], axis=1).values.flatten()\n",
    "                low = lcol < min_keep_likelihood\n",
    "                for c in [f\"{bp}_x\", f\"{bp}_y\"]:\n",
    "                    v = X_df[c].values\n",
    "                    v[low] = np.nan\n",
    "                    X_df[c] = v\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "    X_df = X_df.interpolate(method=\"linear\", limit_direction=\"both\", axis=0)\n",
    "    X_df = X_df.bfill().ffill().fillna(0.0)\n",
    "    X = X_df.values.astype(np.float32)  # (T, DIMS)\n",
    "    return X, use_kps\n",
    "\n",
    "def normalize_tailset_minmax(X: np.ndarray, used_kps, ref_name: str = \"tail_set\", eps: float = 1e-6) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    1) tail_set を原点に平行移動（各フレーム）\n",
    "    2) その後、各次元で min-max 正規化（ファイル単位）\n",
    "    ※ マッチは _norm_key で行うので 'tail set' / 'tail_set' どちらでもOK\n",
    "    \"\"\"\n",
    "    norm_used = [_norm_key(s) for s in used_kps]\n",
    "    ref_key = _norm_key(ref_name)\n",
    "    if ref_key not in norm_used:\n",
    "        raise ValueError(f\"'{ref_name}' が used_kps に見つかりません: {used_kps}\")\n",
    "    ref_idx = norm_used.index(ref_key)\n",
    "\n",
    "    # 原点平行移動\n",
    "    cx = X[:, 2*ref_idx]\n",
    "    cy = X[:, 2*ref_idx + 1]\n",
    "    Xc = X.copy()\n",
    "    for i in range(len(used_kps)):\n",
    "        Xc[:, 2*i]   -= cx\n",
    "        Xc[:, 2*i+1] -= cy\n",
    "\n",
    "    # min-max\n",
    "    x_min = Xc.min(axis=0, keepdims=True)\n",
    "    x_max = Xc.max(axis=0, keepdims=True)\n",
    "    Xn = (Xc - x_min) / (x_max - x_min + eps)\n",
    "    return Xn\n",
    "\n",
    "def make_windows(X: np.ndarray, seq_len: int, stride: int):\n",
    "    n = X.shape[0]\n",
    "    if n < seq_len:\n",
    "        return np.empty((0, seq_len, X.shape[1]), dtype=X.dtype), []\n",
    "    starts = list(range(0, n - seq_len + 1, stride))\n",
    "    Xw = np.stack([X[s:s+seq_len] for s in starts], axis=0) if starts \\\n",
    "         else np.empty((0, seq_len, X.shape[1]), dtype=X.dtype)\n",
    "    return Xw, starts\n",
    "\n",
    "def build_dataset(csv_paths, seq_len=SEQ_LEN, stride=STRIDE):\n",
    "    \"\"\"\n",
    "    戻り:\n",
    "      X: (N, T, D)\n",
    "      y: (N,) 0/1\n",
    "      file_ids: (N,) 元CSVファイル名\n",
    "      starts: (N,) ウィンドウ開始フレーム\n",
    "    \"\"\"\n",
    "    X_list, y_list, file_ids, starts_all = [], [], [], []\n",
    "    used_kps_any = None\n",
    "\n",
    "    for p in csv_paths:\n",
    "        y_lab = infer_label_from_filename(p)\n",
    "        X_raw, used_kps = read_dlc_5kp_xy(p, keypoints=KEYPOINTS,\n",
    "                                          use_likelihood=USE_LIKELIHOOD,\n",
    "                                          min_keep_likelihood=MIN_KEEP_LIKELIHOOD)\n",
    "        if used_kps_any is None:\n",
    "            used_kps_any = used_kps\n",
    "        if X_raw.shape[1] != DIMS:\n",
    "            raise ValueError(f\"{Path(p).name}: 次元 {X_raw.shape[1]} != 期待 {DIMS}\")\n",
    "\n",
    "        # ★ tail_set中心 + min-max 正規化\n",
    "        X_norm = normalize_tailset_minmax(X_raw, used_kps, ref_name=\"tail_set\")\n",
    "\n",
    "        X_win, starts = make_windows(X_norm, seq_len, stride)\n",
    "        if X_win.shape[0] == 0:\n",
    "            print(f\"[WARN] {Path(p).name}: フレーム不足（{seq_len}未満）でスキップ\")\n",
    "            continue\n",
    "\n",
    "        X_list.append(X_win)\n",
    "        y_list.append(np.full((X_win.shape[0],), y_lab, dtype=np.int64))\n",
    "        file_ids += [Path(p).name] * X_win.shape[0]\n",
    "        starts_all += starts\n",
    "\n",
    "    if not X_list:\n",
    "        raise RuntimeError(\"データが作れませんでした。CSV名に normal/ivdd/one/two を含めてください。\")\n",
    "\n",
    "    X = np.concatenate(X_list, axis=0)\n",
    "    y = np.concatenate(y_list, axis=0)\n",
    "    file_ids  = np.array(file_ids)\n",
    "    starts_all = np.array(starts_all, dtype=int)\n",
    "    print(f\"[INFO] 使用キーポイント実名: {used_kps_any}\")\n",
    "    return X, y, file_ids, starts_all\n",
    "\n",
    "# ========= モデル =========\n",
    "def build_lstm_model(seq_len: int, dims: int, n_hidden: int, l2_lambda: float = 1e-4) -> keras.Model:\n",
    "    reg = keras.regularizers.l2(l2_lambda)\n",
    "    inp = keras.Input(shape=(seq_len, dims), name=\"input\")\n",
    "    td  = keras.layers.TimeDistributed(\n",
    "        keras.layers.Dense(n_hidden, activation=\"relu\", kernel_regularizer=reg),\n",
    "        name=\"td_dense\"\n",
    "    )(inp)\n",
    "    x   = keras.layers.LSTM(n_hidden, return_sequences=True, kernel_regularizer=reg, name=\"lstm1\")(td)\n",
    "    x   = keras.layers.LSTM(n_hidden, kernel_regularizer=reg, name=\"lstm2\")(x)\n",
    "    out = keras.layers.Dense(1, kernel_regularizer=reg, name=\"logits\")(x)  # from_logits=True\n",
    "    return keras.Model(inp, out, name=\"ivdd_lstm\")\n",
    "\n",
    "# ========= データ読み込み =========\n",
    "csv_files = sorted(glob.glob(CSV_GLOB))\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(f\"CSV が見つかりません: {CSV_GLOB}\")\n",
    "\n",
    "X, y, file_ids, starts = build_dataset(csv_files, SEQ_LEN, STRIDE)\n",
    "print(\"X:\", X.shape, \"y:\", y.shape, \"files:\", len(np.unique(file_ids)))\n",
    "\n",
    "# ========= 分割（ファイル単位推奨） =========\n",
    "if VAL_SPLIT_BY_FILE:\n",
    "    uniq = np.unique(file_ids)\n",
    "    tr_files, va_files = train_test_split(uniq, test_size=0.2, random_state=42, shuffle=True)\n",
    "    tr_mask = np.isin(file_ids, tr_files)\n",
    "    va_mask = np.isin(file_ids, va_files)\n",
    "    X_train, y_train = X[tr_mask], y[tr_mask]\n",
    "    X_val,   y_val   = X[va_mask], y[va_mask]\n",
    "    val_file_ids     = file_ids[va_mask]\n",
    "    val_starts       = starts[va_mask]\n",
    "else:\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    val_file_ids = np.array([\"unknown.csv\"]*len(y_val))\n",
    "    val_starts   = np.arange(len(y_val))\n",
    "\n",
    "print(\"train:\", X_train.shape, \"val:\", X_val.shape)\n",
    "\n",
    "# ========= クラス不均衡対策 =========\n",
    "unique_classes = np.unique(y_train)\n",
    "if set(unique_classes) == {0, 1}:\n",
    "    cls_w = compute_class_weight(class_weight=\"balanced\", classes=np.array([0,1]), y=y_train)\n",
    "    class_weight = {0: float(cls_w[0]), 1: float(cls_w[1])}\n",
    "else:\n",
    "    class_weight = None\n",
    "print(\"class_weight:\", class_weight)\n",
    "\n",
    "# ========= 学習（EarlyStoppingなし） =========\n",
    "model = build_lstm_model(SEQ_LEN, DIMS, N_HIDDEN, L2_LAMBDA)\n",
    "model.summary()\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=LR)\n",
    "loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "metrics = [keras.metrics.BinaryAccuracy(name=\"accuracy\")]\n",
    "model.compile(optimizer=opt, loss=loss_fn, metrics=metrics)\n",
    "\n",
    "best_model_path  = MODEL_DIR / f\"ivdd_lstm_{DATE_STR}_best.keras\"\n",
    "final_model_path = MODEL_DIR / f\"ivdd_lstm_{DATE_STR}_final.keras\"\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        str(best_model_path), monitor=\"val_accuracy\",\n",
    "        save_best_only=True, save_weights_only=False, mode=\"max\", verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", mode=\"min\",\n",
    "        factor=0.5, patience=5, min_lr=1e-5, verbose=1\n",
    "    ),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_weight=class_weight,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# ========= 学習曲線（loss/acc を1枚で保存） =========\n",
    "curve_png = FIG_DIR / f\"curve_{DATE_STR}.png\"\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1); plt.plot(history.history[\"loss\"], label=\"train\"); plt.plot(history.history[\"val_loss\"], label=\"val\")\n",
    "plt.title(\"Loss\"); plt.legend()\n",
    "plt.subplot(1,2,2); plt.plot(history.history[\"accuracy\"], label=\"train\"); plt.plot(history.history[\"val_accuracy\"], label=\"val\")\n",
    "plt.title(\"Accuracy\"); plt.legend()\n",
    "plt.tight_layout(); plt.savefig(curve_png, dpi=150); plt.close()\n",
    "print(f\"[INFO] saved curve: {curve_png}\")\n",
    "\n",
    "# ========= Val評価 & 誤分類CSV =========\n",
    "logits_val = model.predict(X_val, batch_size=64)\n",
    "p_ivdd = tf.math.sigmoid(logits_val).numpy().ravel()   # ivdd=1 の確率\n",
    "y_pred = (p_ivdd >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\n[Window-level] classification_report:\")\n",
    "cls_report_str = classification_report(y_val, y_pred, target_names=CLASS_NAMES, digits=4)\n",
    "print(cls_report_str)\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "print(\"[Window-level] confusion matrix:\\n\", cm)\n",
    "\n",
    "# 誤分類ウィンドウを書き出し\n",
    "val_df = pd.DataFrame({\n",
    "    \"file\": val_file_ids,\n",
    "    \"win_start\": val_starts,           # ウィンドウ開始フレーム\n",
    "    \"true\": y_val,\n",
    "    \"pred\": y_pred,\n",
    "    \"p_ivdd\": p_ivdd,\n",
    "    \"p_normal\": 1.0 - p_ivdd,\n",
    "})\n",
    "errors_df = val_df[val_df[\"true\"] != val_df[\"pred\"]].copy()\n",
    "err_csv = VALERR_DIR / f\"val_misclassified_{DATE_STR}.csv\"\n",
    "errors_df.to_csv(err_csv, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"[INFO] saved misclassified windows: {err_csv}  (rows={len(errors_df)})\")\n",
    "\n",
    "# ========= 最終モデル保存 =========\n",
    "model.save(str(final_model_path))\n",
    "print(f\"[INFO] saved final model to: {final_model_path}\")\n",
    "\n",
    "# ========= TXTログ保存（train1の拡張を反映） =========\n",
    "log_txt = LOG_DIR / f\"train2_log_{DATE_STR}.txt\"\n",
    "try:\n",
    "    with open(log_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        # 1) 設定パラメータ\n",
    "        f.write(\"[PARAMS]\\n\")\n",
    "        f.write(f\"DATE_STR     : {DATE_STR}\\n\")\n",
    "        f.write(f\"PROJ_ROOT    : {PROJ_ROOT}\\n\")\n",
    "        f.write(f\"TRAIN_CSV_DIR: {TRAIN_CSV_DIR}\\n\")\n",
    "        f.write(f\"KEYPOINTS    : {KEYPOINTS}\\n\")\n",
    "        f.write(f\"USE_LIKELIHOOD/MIN_KEEP : {USE_LIKELIHOOD}/{MIN_KEEP_LIKELIHOOD}\\n\")\n",
    "        f.write(f\"SEQ_LEN/STRIDE: {SEQ_LEN}/{STRIDE}\\n\")\n",
    "        f.write(f\"N_HIDDEN/L2   : {N_HIDDEN}/{L2_LAMBDA}\\n\")\n",
    "        f.write(f\"BATCH_SIZE/EPOCHS/LR: {BATCH_SIZE}/{EPOCHS}/{LR}\\n\")\n",
    "        f.write(f\"VAL_SPLIT_BY_FILE: {VAL_SPLIT_BY_FILE}\\n\")\n",
    "        f.write(f\"CLASS_NAMES      : {CLASS_NAMES}\\n\")\n",
    "        f.write(f\"class_weight     : {class_weight}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "        # 2) データ統計 & 学習フレーム数\n",
    "        n_train_win = int(X_train.shape[0])\n",
    "        n_val_win   = int(X_val.shape[0])\n",
    "        approx_train_frames = n_train_win * SEQ_LEN\n",
    "        approx_val_frames   = n_val_win * SEQ_LEN\n",
    "        f.write(\"[DATA]\\n\")\n",
    "        f.write(f\"#CSV files        : {len(csv_files)}\\n\")\n",
    "        f.write(f\"#train windows    : {n_train_win}\\n\")\n",
    "        f.write(f\"#val windows      : {n_val_win}\\n\")\n",
    "        f.write(f\"approx train frames (windows*SEQ_LEN): {approx_train_frames}\\n\")\n",
    "        f.write(f\"approx val frames   (windows*SEQ_LEN): {approx_val_frames}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "        # 3) 各エポックのメトリクス\n",
    "        f.write(\"[EPOCH METRICS]\\n\")\n",
    "        keys = list(history.history.keys())  # ['loss','accuracy','val_loss','val_accuracy',...]\n",
    "        f.write(f\"keys: {keys}\\n\")\n",
    "        f.write(\"epoch,loss,accuracy,val_loss,val_accuracy\\n\")\n",
    "        for i in range(EPOCHS):\n",
    "            loss = history.history.get(\"loss\", [None]*EPOCHS)[i]\n",
    "            acc  = history.history.get(\"accuracy\", [None]*EPOCHS)[i]\n",
    "            vls  = history.history.get(\"val_loss\", [None]*EPOCHS)[i]\n",
    "            vacc = history.history.get(\"val_accuracy\", [None]*EPOCHS)[i]\n",
    "            f.write(f\"{i+1},{loss},{acc},{vls},{vacc}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "        # 4) 最終 classification report\n",
    "        f.write(\"[WINDOW-LEVEL CLASSIFICATION REPORT]\\n\")\n",
    "        f.write(cls_report_str + \"\\n\\n\")\n",
    "\n",
    "        # 5) 混同行列\n",
    "        f.write(\"[WINDOW-LEVEL CONFUSION MATRIX]\\n\")\n",
    "        f.write(np.array2string(cm, threshold=10000) + \"\\n\")\n",
    "\n",
    "        # 6) 生成物のパス\n",
    "        f.write(\"\\n[ARTIFACTS]\\n\")\n",
    "        f.write(f\"curve_png       : {curve_png}\\n\")\n",
    "        f.write(f\"best_model_path : {best_model_path}\\n\")\n",
    "        f.write(f\"final_model_path: {final_model_path}\\n\")\n",
    "        f.write(f\"val_errors_csv  : {err_csv}\\n\")\n",
    "    print(f\"[INFO] saved TXT log: {log_txt}\")\n",
    "except Exception as e:\n",
    "    print(f\"[WARN] TXTログの保存に失敗しました: {e}\")\n",
    "\n",
    "print(\"[DONE] training complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLya",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

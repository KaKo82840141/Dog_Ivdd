{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33d4f637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(X shape, y shape, every X's mean, every X's standard deviation)\n",
      "(553, 30, 84) (60, 1) 0.6000094 0.17044733\n",
      "\n",
      "The dataset has not been preprocessed, is not normalised etc\n",
      "Iter #16:  Learning rate = 0.000100:  Batch Loss = 18.724197, Accuracy = 0.3125\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 18.793787002563477, Accuracy = 0.25\n",
      "Iter #320:  Learning rate = 0.000100:  Batch Loss = 17.912468, Accuracy = 0.4375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 17.92675018310547, Accuracy = 0.4000000059604645\n",
      "Iter #640:  Learning rate = 0.000100:  Batch Loss = 17.534573, Accuracy = 0.75\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 17.50627899169922, Accuracy = 0.7333333492279053\n",
      "Iter #960:  Learning rate = 0.000100:  Batch Loss = 17.349821, Accuracy = 0.625\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 17.290063858032227, Accuracy = 0.6166666746139526\n",
      "Iter #1280:  Learning rate = 0.000100:  Batch Loss = 17.050915, Accuracy = 0.75\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 17.108173370361328, Accuracy = 0.6833333373069763\n",
      "Iter #1600:  Learning rate = 0.000100:  Batch Loss = 16.900440, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 16.942899703979492, Accuracy = 0.8999999761581421\n",
      "Iter #1920:  Learning rate = 0.000100:  Batch Loss = 16.708080, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 16.790164947509766, Accuracy = 0.9666666388511658\n",
      "Iter #2240:  Learning rate = 0.000100:  Batch Loss = 16.666910, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 16.660503387451172, Accuracy = 0.8999999761581421\n",
      "Iter #2560:  Learning rate = 0.000100:  Batch Loss = 16.456106, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 16.519365310668945, Accuracy = 0.9833333492279053\n",
      "Iter #2880:  Learning rate = 0.000100:  Batch Loss = 16.386328, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 16.42585563659668, Accuracy = 0.9333333373069763\n",
      "Iter #3200:  Learning rate = 0.000100:  Batch Loss = 16.381577, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 16.30863380432129, Accuracy = 1.0\n",
      "Iter #3520:  Learning rate = 0.000100:  Batch Loss = 16.290979, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 16.225448608398438, Accuracy = 1.0\n",
      "Iter #3840:  Learning rate = 0.000100:  Batch Loss = 16.157049, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 16.160137176513672, Accuracy = 1.0\n",
      "Iter #4160:  Learning rate = 0.000100:  Batch Loss = 16.094505, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 16.069644927978516, Accuracy = 1.0\n",
      "Iter #4480:  Learning rate = 0.000100:  Batch Loss = 16.185215, Accuracy = 0.875\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 16.003320693969727, Accuracy = 1.0\n",
      "Iter #4800:  Learning rate = 0.000100:  Batch Loss = 16.198387, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 15.95573902130127, Accuracy = 1.0\n",
      "Iter #5120:  Learning rate = 0.000100:  Batch Loss = 15.910331, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 15.906966209411621, Accuracy = 1.0\n",
      "Iter #5440:  Learning rate = 0.000100:  Batch Loss = 15.855137, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 15.851977348327637, Accuracy = 1.0\n",
      "Iter #5760:  Learning rate = 0.000100:  Batch Loss = 15.812417, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 15.807286262512207, Accuracy = 1.0\n",
      "Iter #6080:  Learning rate = 0.000100:  Batch Loss = 15.764869, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 15.766761779785156, Accuracy = 1.0\n",
      "Iter #6400:  Learning rate = 0.000100:  Batch Loss = 15.995990, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 15.720781326293945, Accuracy = 1.0\n",
      "Iter #6720:  Learning rate = 0.000100:  Batch Loss = 15.680017, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 15.679611206054688, Accuracy = 1.0\n",
      "Iter #7040:  Learning rate = 0.000100:  Batch Loss = 15.645413, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 15.639252662658691, Accuracy = 1.0\n",
      "Iter #7360:  Learning rate = 0.000100:  Batch Loss = 15.612803, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 15.601893424987793, Accuracy = 1.0\n",
      "Iter #7680:  Learning rate = 0.000100:  Batch Loss = 15.823551, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 15.562911987304688, Accuracy = 1.0\n",
      "Iter #8000:  Learning rate = 0.000100:  Batch Loss = 15.525403, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 15.523024559020996, Accuracy = 1.0\n",
      "Iter #8320:  Learning rate = 0.000100:  Batch Loss = 15.494982, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 15.480767250061035, Accuracy = 1.0\n",
      "Iter #8640:  Learning rate = 0.000100:  Batch Loss = 15.707073, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 15.443300247192383, Accuracy = 1.0\n",
      "Iter #8960:  Learning rate = 0.000100:  Batch Loss = 15.412689, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 15.406096458435059, Accuracy = 1.0\n",
      "Iter #9280:  Learning rate = 0.000100:  Batch Loss = 15.373090, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 15.369704246520996, Accuracy = 1.0\n",
      "Iter #9600:  Learning rate = 0.000100:  Batch Loss = 15.330846, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 15.356240272521973, Accuracy = 1.0\n",
      "Iter #9920:  Learning rate = 0.000100:  Batch Loss = 15.337666, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 15.294882774353027, Accuracy = 1.0\n",
      "Iter #10240:  Learning rate = 0.000100:  Batch Loss = 15.266584, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 15.260380744934082, Accuracy = 1.0\n",
      "Iter #10560:  Learning rate = 0.000100:  Batch Loss = 15.217430, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 15.220361709594727, Accuracy = 1.0\n",
      "Iter #10880:  Learning rate = 0.000100:  Batch Loss = 15.185947, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 15.185439109802246, Accuracy = 1.0\n",
      "Iter #11200:  Learning rate = 0.000100:  Batch Loss = 15.151327, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 15.149429321289062, Accuracy = 1.0\n",
      "Iter #11520:  Learning rate = 0.000100:  Batch Loss = 15.111752, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 15.112504959106445, Accuracy = 1.0\n",
      "Iter #11840:  Learning rate = 0.000100:  Batch Loss = 15.085646, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 15.077435493469238, Accuracy = 1.0\n",
      "Iter #12160:  Learning rate = 0.000100:  Batch Loss = 15.036557, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 15.042726516723633, Accuracy = 1.0\n",
      "Iter #12480:  Learning rate = 0.000100:  Batch Loss = 15.002748, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 15.005257606506348, Accuracy = 1.0\n",
      "Iter #12800:  Learning rate = 0.000100:  Batch Loss = 14.965671, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 14.970715522766113, Accuracy = 1.0\n",
      "Iter #13120:  Learning rate = 0.000100:  Batch Loss = 14.930723, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 14.932388305664062, Accuracy = 1.0\n",
      "Iter #13440:  Learning rate = 0.000100:  Batch Loss = 14.918094, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 14.900065422058105, Accuracy = 1.0\n",
      "Iter #13760:  Learning rate = 0.000100:  Batch Loss = 14.860945, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 14.862135887145996, Accuracy = 1.0\n",
      "Iter #14080:  Learning rate = 0.000100:  Batch Loss = 14.834028, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 14.827530860900879, Accuracy = 1.0\n",
      "Iter #14400:  Learning rate = 0.000100:  Batch Loss = 14.787601, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 14.789756774902344, Accuracy = 1.0\n",
      "Iter #14720:  Learning rate = 0.000100:  Batch Loss = 14.748396, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 14.756250381469727, Accuracy = 1.0\n",
      "Iter #15040:  Learning rate = 0.000100:  Batch Loss = 14.714617, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 14.721067428588867, Accuracy = 1.0\n",
      "Iter #15360:  Learning rate = 0.000100:  Batch Loss = 14.860497, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 14.686767578125, Accuracy = 1.0\n",
      "Iter #15680:  Learning rate = 0.000100:  Batch Loss = 14.652129, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 14.652079582214355, Accuracy = 1.0\n",
      "Iter #16000:  Learning rate = 0.000100:  Batch Loss = 14.607187, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 14.609699249267578, Accuracy = 1.0\n",
      "Iter #16320:  Learning rate = 0.000100:  Batch Loss = 14.572871, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 14.58163833618164, Accuracy = 1.0\n",
      "Iter #16640:  Learning rate = 0.000100:  Batch Loss = 14.540181, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 14.546091079711914, Accuracy = 1.0\n",
      "Iter #16960:  Learning rate = 0.000100:  Batch Loss = 14.498944, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 14.504156112670898, Accuracy = 1.0\n",
      "Iter #17280:  Learning rate = 0.000100:  Batch Loss = 14.468898, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 14.473346710205078, Accuracy = 1.0\n",
      "Iter #17600:  Learning rate = 0.000100:  Batch Loss = 14.433201, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 14.443131446838379, Accuracy = 1.0\n",
      "Iter #17920:  Learning rate = 0.000100:  Batch Loss = 14.396399, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 14.40360164642334, Accuracy = 1.0\n",
      "Iter #18240:  Learning rate = 0.000100:  Batch Loss = 14.358894, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 14.371512413024902, Accuracy = 1.0\n",
      "Iter #18560:  Learning rate = 0.000100:  Batch Loss = 14.329529, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 14.330910682678223, Accuracy = 1.0\n",
      "Iter #18880:  Learning rate = 0.000100:  Batch Loss = 14.299008, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 14.301467895507812, Accuracy = 1.0\n",
      "Iter #19200:  Learning rate = 0.000100:  Batch Loss = 14.409052, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 14.264471054077148, Accuracy = 1.0\n",
      "Iter #19520:  Learning rate = 0.000100:  Batch Loss = 14.222157, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 14.232911109924316, Accuracy = 1.0\n",
      "Iter #19840:  Learning rate = 0.000100:  Batch Loss = 14.184762, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 14.195230484008789, Accuracy = 1.0\n",
      "Iter #20160:  Learning rate = 0.000100:  Batch Loss = 14.154477, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 14.16189956665039, Accuracy = 1.0\n",
      "Iter #20480:  Learning rate = 0.000100:  Batch Loss = 14.114959, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 14.127429962158203, Accuracy = 1.0\n",
      "Iter #20800:  Learning rate = 0.000100:  Batch Loss = 14.087010, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 14.094063758850098, Accuracy = 1.0\n",
      "Iter #21120:  Learning rate = 0.000100:  Batch Loss = 14.177511, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 14.063729286193848, Accuracy = 1.0\n",
      "Iter #21440:  Learning rate = 0.000100:  Batch Loss = 14.021142, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 14.022028923034668, Accuracy = 1.0\n",
      "Iter #21760:  Learning rate = 0.000100:  Batch Loss = 13.977404, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 13.992813110351562, Accuracy = 1.0\n",
      "Iter #22080:  Learning rate = 0.000100:  Batch Loss = 13.943372, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 13.96109390258789, Accuracy = 1.0\n",
      "Iter #22400:  Learning rate = 0.000100:  Batch Loss = 13.906668, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 13.920621871948242, Accuracy = 1.0\n",
      "Iter #22720:  Learning rate = 0.000100:  Batch Loss = 13.886463, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 13.89167308807373, Accuracy = 1.0\n",
      "Iter #23040:  Learning rate = 0.000100:  Batch Loss = 13.837631, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 13.852994918823242, Accuracy = 1.0\n",
      "Iter #23360:  Learning rate = 0.000100:  Batch Loss = 13.804501, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 13.8300199508667, Accuracy = 1.0\n",
      "Iter #23680:  Learning rate = 0.000100:  Batch Loss = 13.770759, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 13.783759117126465, Accuracy = 1.0\n",
      "Iter #24000:  Learning rate = 0.000100:  Batch Loss = 13.734776, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 13.752549171447754, Accuracy = 1.0\n",
      "Iter #24320:  Learning rate = 0.000100:  Batch Loss = 13.699945, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 13.711974143981934, Accuracy = 1.0\n",
      "Iter #24640:  Learning rate = 0.000100:  Batch Loss = 13.669547, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 13.683116912841797, Accuracy = 1.0\n",
      "Iter #24960:  Learning rate = 0.000100:  Batch Loss = 13.639442, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 13.657021522521973, Accuracy = 1.0\n",
      "Iter #25280:  Learning rate = 0.000100:  Batch Loss = 13.601193, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 13.616941452026367, Accuracy = 1.0\n",
      "Iter #25600:  Learning rate = 0.000100:  Batch Loss = 13.692637, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 13.58691120147705, Accuracy = 1.0\n",
      "Iter #25920:  Learning rate = 0.000100:  Batch Loss = 13.549673, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 13.553966522216797, Accuracy = 1.0\n",
      "Iter #26240:  Learning rate = 0.000100:  Batch Loss = 13.498304, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 13.507878303527832, Accuracy = 1.0\n",
      "Iter #26560:  Learning rate = 0.000100:  Batch Loss = 13.474015, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 13.489593505859375, Accuracy = 1.0\n",
      "Iter #26880:  Learning rate = 0.000100:  Batch Loss = 13.434286, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 13.455509185791016, Accuracy = 1.0\n",
      "Iter #27200:  Learning rate = 0.000100:  Batch Loss = 13.397350, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 13.4029541015625, Accuracy = 1.0\n",
      "Iter #27520:  Learning rate = 0.000100:  Batch Loss = 13.370937, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 13.376194953918457, Accuracy = 1.0\n",
      "Iter #27840:  Learning rate = 0.000100:  Batch Loss = 13.332774, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 13.361187934875488, Accuracy = 1.0\n",
      "Iter #28160:  Learning rate = 0.000100:  Batch Loss = 13.440670, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 13.30948543548584, Accuracy = 1.0\n",
      "Iter #28480:  Learning rate = 0.000100:  Batch Loss = 13.276258, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 13.286937713623047, Accuracy = 1.0\n",
      "Iter #28800:  Learning rate = 0.000100:  Batch Loss = 13.260390, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 13.248763084411621, Accuracy = 1.0\n",
      "Iter #29120:  Learning rate = 0.000100:  Batch Loss = 13.197270, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 13.209661483764648, Accuracy = 1.0\n",
      "Iter #29440:  Learning rate = 0.000100:  Batch Loss = 13.165931, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 13.187685012817383, Accuracy = 1.0\n",
      "Iter #29760:  Learning rate = 0.000100:  Batch Loss = 13.138689, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 13.141962051391602, Accuracy = 1.0\n",
      "Iter #30080:  Learning rate = 0.000100:  Batch Loss = 13.098160, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 13.128788948059082, Accuracy = 1.0\n",
      "Iter #30400:  Learning rate = 0.000100:  Batch Loss = 13.074801, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 13.087089538574219, Accuracy = 1.0\n",
      "Iter #30720:  Learning rate = 0.000100:  Batch Loss = 13.044287, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 13.046399116516113, Accuracy = 1.0\n",
      "Iter #31040:  Learning rate = 0.000100:  Batch Loss = 13.002480, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 13.027632713317871, Accuracy = 1.0\n",
      "Iter #31360:  Learning rate = 0.000100:  Batch Loss = 12.967305, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.995170593261719, Accuracy = 1.0\n",
      "Iter #31680:  Learning rate = 0.000100:  Batch Loss = 13.054338, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.9456787109375, Accuracy = 1.0\n",
      "Iter #32000:  Learning rate = 0.000100:  Batch Loss = 12.907314, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.924668312072754, Accuracy = 1.0\n",
      "Iter #32320:  Learning rate = 0.000100:  Batch Loss = 12.872586, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.883525848388672, Accuracy = 1.0\n",
      "Iter #32640:  Learning rate = 0.000100:  Batch Loss = 12.838274, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.853759765625, Accuracy = 1.0\n",
      "Iter #32960:  Learning rate = 0.000100:  Batch Loss = 12.809021, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.823938369750977, Accuracy = 1.0\n",
      "Iter #33280:  Learning rate = 0.000100:  Batch Loss = 12.773717, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.799901008605957, Accuracy = 1.0\n",
      "Iter #33600:  Learning rate = 0.000100:  Batch Loss = 12.741980, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.758401870727539, Accuracy = 1.0\n",
      "Iter #33920:  Learning rate = 0.000100:  Batch Loss = 12.709148, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.7302827835083, Accuracy = 1.0\n",
      "Iter #34240:  Learning rate = 0.000100:  Batch Loss = 12.676940, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.697495460510254, Accuracy = 1.0\n",
      "Iter #34560:  Learning rate = 0.000100:  Batch Loss = 12.649257, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.683843612670898, Accuracy = 1.0\n",
      "Iter #34880:  Learning rate = 0.000100:  Batch Loss = 12.613075, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.620967864990234, Accuracy = 1.0\n",
      "Iter #35200:  Learning rate = 0.000100:  Batch Loss = 12.582815, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.615403175354004, Accuracy = 1.0\n",
      "Iter #35520:  Learning rate = 0.000100:  Batch Loss = 12.668961, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.570320129394531, Accuracy = 1.0\n",
      "Iter #35840:  Learning rate = 0.000100:  Batch Loss = 12.527350, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.531767845153809, Accuracy = 1.0\n",
      "Iter #36160:  Learning rate = 0.000100:  Batch Loss = 12.489239, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.505398750305176, Accuracy = 1.0\n",
      "Iter #36480:  Learning rate = 0.000100:  Batch Loss = 12.462453, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.471831321716309, Accuracy = 1.0\n",
      "Iter #36800:  Learning rate = 0.000100:  Batch Loss = 12.423113, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.43675422668457, Accuracy = 1.0\n",
      "Iter #37120:  Learning rate = 0.000100:  Batch Loss = 12.392811, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.416101455688477, Accuracy = 1.0\n",
      "Iter #37440:  Learning rate = 0.000100:  Batch Loss = 12.360394, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.377185821533203, Accuracy = 1.0\n",
      "Iter #37760:  Learning rate = 0.000100:  Batch Loss = 12.335003, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.353401184082031, Accuracy = 1.0\n",
      "Iter #38080:  Learning rate = 0.000100:  Batch Loss = 12.303070, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.31628704071045, Accuracy = 1.0\n",
      "Iter #38400:  Learning rate = 0.000100:  Batch Loss = 12.269219, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.270979881286621, Accuracy = 1.0\n",
      "Iter #38720:  Learning rate = 0.000100:  Batch Loss = 12.266289, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.269923210144043, Accuracy = 1.0\n",
      "Iter #39040:  Learning rate = 0.000100:  Batch Loss = 12.208115, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.216717720031738, Accuracy = 1.0\n",
      "Iter #39360:  Learning rate = 0.000100:  Batch Loss = 12.173757, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.205992698669434, Accuracy = 1.0\n",
      "Iter #39680:  Learning rate = 0.000100:  Batch Loss = 12.142776, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.156489372253418, Accuracy = 1.0\n",
      "Iter #40000:  Learning rate = 0.000100:  Batch Loss = 12.125316, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.13642406463623, Accuracy = 1.0\n",
      "Iter #40320:  Learning rate = 0.000100:  Batch Loss = 12.085810, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.087660789489746, Accuracy = 1.0\n",
      "Iter #40640:  Learning rate = 0.000100:  Batch Loss = 12.050572, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.069707870483398, Accuracy = 1.0\n",
      "Iter #40960:  Learning rate = 0.000100:  Batch Loss = 12.032893, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 12.03030776977539, Accuracy = 1.0\n",
      "Iter #41280:  Learning rate = 0.000100:  Batch Loss = 11.996159, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.99519157409668, Accuracy = 1.0\n",
      "Iter #41600:  Learning rate = 0.000100:  Batch Loss = 11.964746, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.971784591674805, Accuracy = 1.0\n",
      "Iter #41920:  Learning rate = 0.000100:  Batch Loss = 11.933052, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.93911075592041, Accuracy = 1.0\n",
      "Iter #42240:  Learning rate = 0.000100:  Batch Loss = 11.903177, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.910576820373535, Accuracy = 1.0\n",
      "Iter #42560:  Learning rate = 0.000100:  Batch Loss = 11.871033, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.89046573638916, Accuracy = 1.0\n",
      "Iter #42880:  Learning rate = 0.000100:  Batch Loss = 11.845021, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.857166290283203, Accuracy = 1.0\n",
      "Iter #43200:  Learning rate = 0.000100:  Batch Loss = 11.811482, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.828935623168945, Accuracy = 1.0\n",
      "Iter #43520:  Learning rate = 0.000100:  Batch Loss = 11.780798, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.796202659606934, Accuracy = 1.0\n",
      "Iter #43840:  Learning rate = 0.000100:  Batch Loss = 11.751987, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.774778366088867, Accuracy = 1.0\n",
      "Iter #44160:  Learning rate = 0.000100:  Batch Loss = 11.819053, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.737509727478027, Accuracy = 1.0\n",
      "Iter #44480:  Learning rate = 0.000100:  Batch Loss = 11.702188, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.712498664855957, Accuracy = 1.0\n",
      "Iter #44800:  Learning rate = 0.000100:  Batch Loss = 11.662323, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.677778244018555, Accuracy = 1.0\n",
      "Iter #45120:  Learning rate = 0.000100:  Batch Loss = 11.632266, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.649955749511719, Accuracy = 1.0\n",
      "Iter #45440:  Learning rate = 0.000100:  Batch Loss = 11.602567, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.627264976501465, Accuracy = 1.0\n",
      "Iter #45760:  Learning rate = 0.000100:  Batch Loss = 11.586365, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.589488983154297, Accuracy = 1.0\n",
      "Iter #46080:  Learning rate = 0.000100:  Batch Loss = 11.543011, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.565117835998535, Accuracy = 1.0\n",
      "Iter #46400:  Learning rate = 0.000100:  Batch Loss = 11.521477, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.530170440673828, Accuracy = 1.0\n",
      "Iter #46720:  Learning rate = 0.000100:  Batch Loss = 11.485856, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.502015113830566, Accuracy = 1.0\n",
      "Iter #47040:  Learning rate = 0.000100:  Batch Loss = 11.460698, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.48198127746582, Accuracy = 1.0\n",
      "Iter #47360:  Learning rate = 0.000100:  Batch Loss = 11.426909, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.443842887878418, Accuracy = 1.0\n",
      "Iter #47680:  Learning rate = 0.000100:  Batch Loss = 11.397755, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.424993515014648, Accuracy = 1.0\n",
      "Iter #48000:  Learning rate = 0.000100:  Batch Loss = 11.368670, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.374780654907227, Accuracy = 1.0\n",
      "Iter #48320:  Learning rate = 0.000100:  Batch Loss = 11.341316, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.358924865722656, Accuracy = 1.0\n",
      "Iter #48640:  Learning rate = 0.000100:  Batch Loss = 11.311681, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.334038734436035, Accuracy = 1.0\n",
      "Iter #48960:  Learning rate = 0.000100:  Batch Loss = 11.282092, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.292191505432129, Accuracy = 1.0\n",
      "Iter #49280:  Learning rate = 0.000100:  Batch Loss = 11.252948, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.257179260253906, Accuracy = 1.0\n",
      "Iter #49600:  Learning rate = 0.000100:  Batch Loss = 11.234159, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.258986473083496, Accuracy = 1.0\n",
      "Iter #49920:  Learning rate = 0.000100:  Batch Loss = 11.198167, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.217721939086914, Accuracy = 1.0\n",
      "Iter #50240:  Learning rate = 0.000100:  Batch Loss = 11.168746, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.186017990112305, Accuracy = 1.0\n",
      "Iter #50560:  Learning rate = 0.000100:  Batch Loss = 11.273366, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.14976692199707, Accuracy = 1.0\n",
      "Iter #50880:  Learning rate = 0.000100:  Batch Loss = 11.124537, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.135004043579102, Accuracy = 1.0\n",
      "Iter #51200:  Learning rate = 0.000100:  Batch Loss = 11.092505, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.096752166748047, Accuracy = 1.0\n",
      "Iter #51520:  Learning rate = 0.000100:  Batch Loss = 11.065382, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.084358215332031, Accuracy = 1.0\n",
      "Iter #51840:  Learning rate = 0.000100:  Batch Loss = 11.037581, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.05111312866211, Accuracy = 1.0\n",
      "Iter #52160:  Learning rate = 0.000100:  Batch Loss = 11.000051, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 11.012533187866211, Accuracy = 1.0\n",
      "Iter #52480:  Learning rate = 0.000100:  Batch Loss = 10.975500, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.977004051208496, Accuracy = 1.0\n",
      "Iter #52800:  Learning rate = 0.000100:  Batch Loss = 10.960223, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.984142303466797, Accuracy = 1.0\n",
      "Iter #53120:  Learning rate = 0.000100:  Batch Loss = 10.917089, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.938541412353516, Accuracy = 1.0\n",
      "Iter #53440:  Learning rate = 0.000100:  Batch Loss = 10.889536, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.894594192504883, Accuracy = 1.0\n",
      "Iter #53760:  Learning rate = 0.000100:  Batch Loss = 10.879468, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.886926651000977, Accuracy = 1.0\n",
      "Iter #54080:  Learning rate = 0.000100:  Batch Loss = 10.845687, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.847379684448242, Accuracy = 1.0\n",
      "Iter #54400:  Learning rate = 0.000100:  Batch Loss = 10.808212, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.82991886138916, Accuracy = 1.0\n",
      "Iter #54720:  Learning rate = 0.000100:  Batch Loss = 10.780534, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.794927597045898, Accuracy = 1.0\n",
      "Iter #55040:  Learning rate = 0.000100:  Batch Loss = 10.753826, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.782316207885742, Accuracy = 1.0\n",
      "Iter #55360:  Learning rate = 0.000100:  Batch Loss = 10.726403, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.757951736450195, Accuracy = 1.0\n",
      "Iter #55680:  Learning rate = 0.000100:  Batch Loss = 10.699480, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.709807395935059, Accuracy = 1.0\n",
      "Iter #56000:  Learning rate = 0.000100:  Batch Loss = 10.673100, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.70859432220459, Accuracy = 1.0\n",
      "Iter #56320:  Learning rate = 0.000100:  Batch Loss = 10.649415, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.649967193603516, Accuracy = 1.0\n",
      "Iter #56640:  Learning rate = 0.000100:  Batch Loss = 10.619504, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.66459846496582, Accuracy = 1.0\n",
      "Iter #56960:  Learning rate = 0.000100:  Batch Loss = 10.593590, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.602299690246582, Accuracy = 1.0\n",
      "Iter #57280:  Learning rate = 0.000100:  Batch Loss = 10.566629, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.5837984085083, Accuracy = 1.0\n",
      "Iter #57600:  Learning rate = 0.000100:  Batch Loss = 10.543935, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.552873611450195, Accuracy = 1.0\n",
      "Iter #57920:  Learning rate = 0.000100:  Batch Loss = 10.516061, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.517542839050293, Accuracy = 1.0\n",
      "Iter #58240:  Learning rate = 0.000100:  Batch Loss = 10.516726, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.522048950195312, Accuracy = 1.0\n",
      "Iter #58560:  Learning rate = 0.000100:  Batch Loss = 10.463138, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.481955528259277, Accuracy = 1.0\n",
      "Iter #58880:  Learning rate = 0.000100:  Batch Loss = 10.440025, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.452997207641602, Accuracy = 1.0\n",
      "Iter #59200:  Learning rate = 0.000100:  Batch Loss = 10.412389, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.42818546295166, Accuracy = 1.0\n",
      "Iter #59520:  Learning rate = 0.000100:  Batch Loss = 10.386286, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.402535438537598, Accuracy = 1.0\n",
      "Iter #59840:  Learning rate = 0.000100:  Batch Loss = 10.398663, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.391300201416016, Accuracy = 1.0\n",
      "Iter #60160:  Learning rate = 0.000100:  Batch Loss = 10.351492, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.356483459472656, Accuracy = 1.0\n",
      "Iter #60480:  Learning rate = 0.000100:  Batch Loss = 10.329037, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.336514472961426, Accuracy = 1.0\n",
      "Iter #60800:  Learning rate = 0.000100:  Batch Loss = 10.303685, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.314395904541016, Accuracy = 1.0\n",
      "Iter #61120:  Learning rate = 0.000100:  Batch Loss = 10.410249, Accuracy = 0.875\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.297098159790039, Accuracy = 1.0\n",
      "Iter #61440:  Learning rate = 0.000100:  Batch Loss = 10.251867, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.266826629638672, Accuracy = 1.0\n",
      "Iter #61760:  Learning rate = 0.000100:  Batch Loss = 10.233797, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.23728084564209, Accuracy = 1.0\n",
      "Iter #62080:  Learning rate = 0.000100:  Batch Loss = 10.235873, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.245246887207031, Accuracy = 1.0\n",
      "Iter #62400:  Learning rate = 0.000100:  Batch Loss = 10.187432, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.204522132873535, Accuracy = 1.0\n",
      "Iter #62720:  Learning rate = 0.000100:  Batch Loss = 10.165669, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.170319557189941, Accuracy = 1.0\n",
      "Iter #63040:  Learning rate = 0.000100:  Batch Loss = 10.151735, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.18351936340332, Accuracy = 1.0\n",
      "Iter #63360:  Learning rate = 0.000100:  Batch Loss = 10.125851, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.14909553527832, Accuracy = 1.0\n",
      "Iter #63680:  Learning rate = 0.000100:  Batch Loss = 10.109262, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.111164093017578, Accuracy = 1.0\n",
      "Iter #64000:  Learning rate = 0.000100:  Batch Loss = 10.082013, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.103253364562988, Accuracy = 1.0\n",
      "Iter #64320:  Learning rate = 0.000100:  Batch Loss = 10.060688, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.071272850036621, Accuracy = 1.0\n",
      "Iter #64640:  Learning rate = 0.000100:  Batch Loss = 10.041877, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.050501823425293, Accuracy = 1.0\n",
      "Iter #64960:  Learning rate = 0.000100:  Batch Loss = 10.017589, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.043383598327637, Accuracy = 1.0\n",
      "Iter #65280:  Learning rate = 0.000100:  Batch Loss = 10.170118, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.00283145904541, Accuracy = 1.0\n",
      "Iter #65600:  Learning rate = 0.000100:  Batch Loss = 9.976295, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 10.008462905883789, Accuracy = 1.0\n",
      "Iter #65920:  Learning rate = 0.000100:  Batch Loss = 9.953222, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.959026336669922, Accuracy = 1.0\n",
      "Iter #66240:  Learning rate = 0.000100:  Batch Loss = 9.932538, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.957451820373535, Accuracy = 1.0\n",
      "Iter #66560:  Learning rate = 0.000100:  Batch Loss = 9.910769, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.915120124816895, Accuracy = 1.0\n",
      "Iter #66880:  Learning rate = 0.000100:  Batch Loss = 9.892877, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.919353485107422, Accuracy = 1.0\n",
      "Iter #67200:  Learning rate = 0.000100:  Batch Loss = 9.869311, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.878203392028809, Accuracy = 1.0\n",
      "Iter #67520:  Learning rate = 0.000100:  Batch Loss = 9.849277, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.874135971069336, Accuracy = 1.0\n",
      "Iter #67840:  Learning rate = 0.000100:  Batch Loss = 9.827669, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.839850425720215, Accuracy = 1.0\n",
      "Iter #68160:  Learning rate = 0.000100:  Batch Loss = 9.806410, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.832671165466309, Accuracy = 1.0\n",
      "Iter #68480:  Learning rate = 0.000100:  Batch Loss = 9.786031, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.793407440185547, Accuracy = 1.0\n",
      "Iter #68800:  Learning rate = 0.000100:  Batch Loss = 9.788420, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.796539306640625, Accuracy = 1.0\n",
      "Iter #69120:  Learning rate = 0.000100:  Batch Loss = 9.743813, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.76347827911377, Accuracy = 1.0\n",
      "Iter #69440:  Learning rate = 0.000100:  Batch Loss = 9.724421, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.732251167297363, Accuracy = 1.0\n",
      "Iter #69760:  Learning rate = 0.000100:  Batch Loss = 9.735728, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.741533279418945, Accuracy = 1.0\n",
      "Iter #70080:  Learning rate = 0.000100:  Batch Loss = 9.786302, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.69465446472168, Accuracy = 1.0\n",
      "Iter #70400:  Learning rate = 0.000100:  Batch Loss = 9.672008, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.69767951965332, Accuracy = 1.0\n",
      "Iter #70720:  Learning rate = 0.000100:  Batch Loss = 9.641215, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.642132759094238, Accuracy = 1.0\n",
      "Iter #71040:  Learning rate = 0.000100:  Batch Loss = 9.622973, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.627664566040039, Accuracy = 1.0\n",
      "Iter #71360:  Learning rate = 0.000100:  Batch Loss = 9.602235, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.62645149230957, Accuracy = 1.0\n",
      "Iter #71680:  Learning rate = 0.000100:  Batch Loss = 9.577959, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.590846061706543, Accuracy = 1.0\n",
      "Iter #72000:  Learning rate = 0.000100:  Batch Loss = 9.563787, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.594954490661621, Accuracy = 1.0\n",
      "Iter #72320:  Learning rate = 0.000100:  Batch Loss = 9.537599, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.54643726348877, Accuracy = 1.0\n",
      "Iter #72640:  Learning rate = 0.000100:  Batch Loss = 9.516836, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.52951717376709, Accuracy = 1.0\n",
      "Iter #72960:  Learning rate = 0.000100:  Batch Loss = 9.496872, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.529547691345215, Accuracy = 1.0\n",
      "Iter #73280:  Learning rate = 0.000100:  Batch Loss = 9.481267, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.479024887084961, Accuracy = 1.0\n",
      "Iter #73600:  Learning rate = 0.000100:  Batch Loss = 9.488237, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.520649909973145, Accuracy = 0.9833333492279053\n",
      "Iter #73920:  Learning rate = 0.000100:  Batch Loss = 9.439631, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.44847297668457, Accuracy = 1.0\n",
      "Iter #74240:  Learning rate = 0.000100:  Batch Loss = 9.431522, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.447768211364746, Accuracy = 1.0\n",
      "Iter #74560:  Learning rate = 0.000100:  Batch Loss = 9.392962, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.395267486572266, Accuracy = 1.0\n",
      "Iter #74880:  Learning rate = 0.000100:  Batch Loss = 9.395413, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.404434204101562, Accuracy = 1.0\n",
      "Iter #75200:  Learning rate = 0.000100:  Batch Loss = 9.352055, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.364130973815918, Accuracy = 1.0\n",
      "Iter #75520:  Learning rate = 0.000100:  Batch Loss = 9.346822, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.394981384277344, Accuracy = 1.0\n",
      "Iter #75840:  Learning rate = 0.000100:  Batch Loss = 9.312933, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.336458206176758, Accuracy = 1.0\n",
      "Iter #76160:  Learning rate = 0.000100:  Batch Loss = 9.297150, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.30048942565918, Accuracy = 1.0\n",
      "Iter #76480:  Learning rate = 0.000100:  Batch Loss = 9.273885, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.274259567260742, Accuracy = 1.0\n",
      "Iter #76800:  Learning rate = 0.000100:  Batch Loss = 9.254416, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.301417350769043, Accuracy = 1.0\n",
      "Iter #77120:  Learning rate = 0.000100:  Batch Loss = 9.233200, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.246288299560547, Accuracy = 1.0\n",
      "Iter #77440:  Learning rate = 0.000100:  Batch Loss = 9.211225, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.220209121704102, Accuracy = 1.0\n",
      "Iter #77760:  Learning rate = 0.000100:  Batch Loss = 9.192636, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.232198715209961, Accuracy = 1.0\n",
      "Iter #78080:  Learning rate = 0.000100:  Batch Loss = 9.170353, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.173480987548828, Accuracy = 1.0\n",
      "Iter #78400:  Learning rate = 0.000100:  Batch Loss = 9.153393, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.177392959594727, Accuracy = 1.0\n",
      "Iter #78720:  Learning rate = 0.000100:  Batch Loss = 9.130683, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.146878242492676, Accuracy = 1.0\n",
      "Iter #79040:  Learning rate = 0.000100:  Batch Loss = 9.170251, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.130887031555176, Accuracy = 1.0\n",
      "Iter #79360:  Learning rate = 0.000100:  Batch Loss = 9.103100, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.11326789855957, Accuracy = 1.0\n",
      "Iter #79680:  Learning rate = 0.000100:  Batch Loss = 9.114632, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.087244033813477, Accuracy = 1.0\n",
      "Iter #80000:  Learning rate = 0.000100:  Batch Loss = 9.112940, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.067269325256348, Accuracy = 1.0\n",
      "Iter #80320:  Learning rate = 0.000100:  Batch Loss = 9.031495, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.07082748413086, Accuracy = 1.0\n",
      "Iter #80640:  Learning rate = 0.000100:  Batch Loss = 9.191661, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.024435043334961, Accuracy = 1.0\n",
      "Iter #80960:  Learning rate = 0.000100:  Batch Loss = 8.991555, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.998936653137207, Accuracy = 1.0\n",
      "Iter #81280:  Learning rate = 0.000100:  Batch Loss = 8.971779, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 9.003640174865723, Accuracy = 1.0\n",
      "Iter #81600:  Learning rate = 0.000100:  Batch Loss = 8.951894, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.963239669799805, Accuracy = 1.0\n",
      "Iter #81920:  Learning rate = 0.000100:  Batch Loss = 8.972880, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.958728790283203, Accuracy = 1.0\n",
      "Iter #82240:  Learning rate = 0.000100:  Batch Loss = 8.968848, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.936546325683594, Accuracy = 1.0\n",
      "Iter #82560:  Learning rate = 0.000100:  Batch Loss = 8.893892, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.904950141906738, Accuracy = 1.0\n",
      "Iter #82880:  Learning rate = 0.000100:  Batch Loss = 8.873573, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.888762474060059, Accuracy = 1.0\n",
      "Iter #83200:  Learning rate = 0.000100:  Batch Loss = 8.889485, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.881752014160156, Accuracy = 1.0\n",
      "Iter #83520:  Learning rate = 0.000100:  Batch Loss = 8.835295, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.848761558532715, Accuracy = 1.0\n",
      "Iter #83840:  Learning rate = 0.000100:  Batch Loss = 8.816813, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.82638168334961, Accuracy = 1.0\n",
      "Iter #84160:  Learning rate = 0.000100:  Batch Loss = 8.796211, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.815756797790527, Accuracy = 1.0\n",
      "Iter #84480:  Learning rate = 0.000100:  Batch Loss = 8.787842, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.8150634765625, Accuracy = 1.0\n",
      "Iter #84800:  Learning rate = 0.000100:  Batch Loss = 8.757278, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.763144493103027, Accuracy = 1.0\n",
      "Iter #85120:  Learning rate = 0.000100:  Batch Loss = 8.738349, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.764168739318848, Accuracy = 1.0\n",
      "Iter #85440:  Learning rate = 0.000100:  Batch Loss = 8.719170, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.735946655273438, Accuracy = 1.0\n",
      "Iter #85760:  Learning rate = 0.000100:  Batch Loss = 8.699536, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.721951484680176, Accuracy = 1.0\n",
      "Iter #86080:  Learning rate = 0.000100:  Batch Loss = 8.688593, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.69986629486084, Accuracy = 1.0\n",
      "Iter #86400:  Learning rate = 0.000100:  Batch Loss = 8.665417, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.670381546020508, Accuracy = 1.0\n",
      "Iter #86720:  Learning rate = 0.000100:  Batch Loss = 8.659897, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.704069137573242, Accuracy = 0.9833333492279053\n",
      "Iter #87040:  Learning rate = 0.000100:  Batch Loss = 8.623968, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.630901336669922, Accuracy = 1.0\n",
      "Iter #87360:  Learning rate = 0.000100:  Batch Loss = 8.605859, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.612476348876953, Accuracy = 1.0\n",
      "Iter #87680:  Learning rate = 0.000100:  Batch Loss = 8.615235, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.640665054321289, Accuracy = 0.9833333492279053\n",
      "Iter #88000:  Learning rate = 0.000100:  Batch Loss = 8.566683, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.581079483032227, Accuracy = 1.0\n",
      "Iter #88320:  Learning rate = 0.000100:  Batch Loss = 8.575074, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.567157745361328, Accuracy = 1.0\n",
      "Iter #88640:  Learning rate = 0.000100:  Batch Loss = 8.534945, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.546239852905273, Accuracy = 1.0\n",
      "Iter #88960:  Learning rate = 0.000100:  Batch Loss = 8.646243, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.514745712280273, Accuracy = 1.0\n",
      "Iter #89280:  Learning rate = 0.000100:  Batch Loss = 8.543547, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.556222915649414, Accuracy = 1.0\n",
      "Iter #89600:  Learning rate = 0.000100:  Batch Loss = 8.473844, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.485045433044434, Accuracy = 1.0\n",
      "Iter #89920:  Learning rate = 0.000100:  Batch Loss = 8.455379, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.47283935546875, Accuracy = 1.0\n",
      "Iter #90240:  Learning rate = 0.000100:  Batch Loss = 8.501881, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.462576866149902, Accuracy = 0.9833333492279053\n",
      "Iter #90560:  Learning rate = 0.000100:  Batch Loss = 8.417725, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.423502922058105, Accuracy = 1.0\n",
      "Iter #90880:  Learning rate = 0.000100:  Batch Loss = 8.400363, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.412568092346191, Accuracy = 1.0\n",
      "Iter #91200:  Learning rate = 0.000100:  Batch Loss = 8.394671, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.418648719787598, Accuracy = 1.0\n",
      "Iter #91520:  Learning rate = 0.000100:  Batch Loss = 8.363615, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.363129615783691, Accuracy = 1.0\n",
      "Iter #91840:  Learning rate = 0.000100:  Batch Loss = 8.344030, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.347075462341309, Accuracy = 1.0\n",
      "Iter #92160:  Learning rate = 0.000100:  Batch Loss = 8.326889, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.363354682922363, Accuracy = 1.0\n",
      "Iter #92480:  Learning rate = 0.000100:  Batch Loss = 8.308037, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.312782287597656, Accuracy = 1.0\n",
      "Iter #92800:  Learning rate = 0.000100:  Batch Loss = 8.297174, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.3773193359375, Accuracy = 0.949999988079071\n",
      "Iter #93120:  Learning rate = 0.000100:  Batch Loss = 8.273179, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.280869483947754, Accuracy = 1.0\n",
      "Iter #93440:  Learning rate = 0.000100:  Batch Loss = 8.277569, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.288631439208984, Accuracy = 1.0\n",
      "Iter #93760:  Learning rate = 0.000100:  Batch Loss = 8.237168, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.246525764465332, Accuracy = 1.0\n",
      "Iter #94080:  Learning rate = 0.000100:  Batch Loss = 8.218593, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.231971740722656, Accuracy = 1.0\n",
      "Iter #94400:  Learning rate = 0.000100:  Batch Loss = 8.220848, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.230846405029297, Accuracy = 1.0\n",
      "Iter #94720:  Learning rate = 0.000100:  Batch Loss = 8.182961, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.18906307220459, Accuracy = 1.0\n",
      "Iter #95040:  Learning rate = 0.000100:  Batch Loss = 8.166165, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.192445755004883, Accuracy = 1.0\n",
      "Iter #95360:  Learning rate = 0.000100:  Batch Loss = 8.154626, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.174993515014648, Accuracy = 1.0\n",
      "Iter #95680:  Learning rate = 0.000100:  Batch Loss = 8.130137, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.136190414428711, Accuracy = 1.0\n",
      "Iter #96000:  Learning rate = 0.000100:  Batch Loss = 8.180030, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.156466484069824, Accuracy = 1.0\n",
      "Iter #96320:  Learning rate = 0.000100:  Batch Loss = 8.094998, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.103438377380371, Accuracy = 1.0\n",
      "Iter #96640:  Learning rate = 0.000100:  Batch Loss = 8.079429, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.089164733886719, Accuracy = 1.0\n",
      "Iter #96960:  Learning rate = 0.000100:  Batch Loss = 8.059200, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.099434852600098, Accuracy = 0.9833333492279053\n",
      "Iter #97280:  Learning rate = 0.000100:  Batch Loss = 8.042262, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.059886932373047, Accuracy = 1.0\n",
      "Iter #97600:  Learning rate = 0.000100:  Batch Loss = 8.027029, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.042540550231934, Accuracy = 1.0\n",
      "Iter #97920:  Learning rate = 0.000100:  Batch Loss = 8.006952, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.018646240234375, Accuracy = 1.0\n",
      "Iter #98240:  Learning rate = 0.000100:  Batch Loss = 7.992371, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.012589454650879, Accuracy = 1.0\n",
      "Iter #98560:  Learning rate = 0.000100:  Batch Loss = 7.971974, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.989950180053711, Accuracy = 1.0\n",
      "Iter #98880:  Learning rate = 0.000100:  Batch Loss = 8.036377, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.966653347015381, Accuracy = 1.0\n",
      "Iter #99200:  Learning rate = 0.000100:  Batch Loss = 8.004446, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.951160430908203, Accuracy = 1.0\n",
      "Iter #99520:  Learning rate = 0.000100:  Batch Loss = 7.920004, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.940235614776611, Accuracy = 1.0\n",
      "Iter #99840:  Learning rate = 0.000100:  Batch Loss = 7.960571, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 8.036209106445312, Accuracy = 0.9166666865348816\n",
      "Iter #100160:  Learning rate = 0.000096:  Batch Loss = 7.884625, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.887149810791016, Accuracy = 1.0\n",
      "Iter #100480:  Learning rate = 0.000096:  Batch Loss = 7.869920, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.905667781829834, Accuracy = 1.0\n",
      "Iter #100800:  Learning rate = 0.000096:  Batch Loss = 7.852058, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.873912334442139, Accuracy = 1.0\n",
      "Iter #101120:  Learning rate = 0.000096:  Batch Loss = 7.836493, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.842501640319824, Accuracy = 1.0\n",
      "Iter #101440:  Learning rate = 0.000096:  Batch Loss = 7.819075, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.8215789794921875, Accuracy = 1.0\n",
      "Iter #101760:  Learning rate = 0.000096:  Batch Loss = 7.815949, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.818809509277344, Accuracy = 1.0\n",
      "Iter #102080:  Learning rate = 0.000096:  Batch Loss = 7.789882, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.8059186935424805, Accuracy = 1.0\n",
      "Iter #102400:  Learning rate = 0.000096:  Batch Loss = 7.769540, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.781538486480713, Accuracy = 1.0\n",
      "Iter #102720:  Learning rate = 0.000096:  Batch Loss = 7.753260, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.765010356903076, Accuracy = 1.0\n",
      "Iter #103040:  Learning rate = 0.000096:  Batch Loss = 7.756870, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.792104244232178, Accuracy = 0.9833333492279053\n",
      "Iter #103360:  Learning rate = 0.000096:  Batch Loss = 7.720431, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.723473072052002, Accuracy = 1.0\n",
      "Iter #103680:  Learning rate = 0.000096:  Batch Loss = 7.704107, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.707826614379883, Accuracy = 1.0\n",
      "Iter #104000:  Learning rate = 0.000096:  Batch Loss = 7.689417, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.7241010665893555, Accuracy = 0.9833333492279053\n",
      "Iter #104320:  Learning rate = 0.000096:  Batch Loss = 7.672101, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.6848649978637695, Accuracy = 1.0\n",
      "Iter #104640:  Learning rate = 0.000096:  Batch Loss = 7.722950, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.675625801086426, Accuracy = 1.0\n",
      "Iter #104960:  Learning rate = 0.000096:  Batch Loss = 7.640086, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.6485066413879395, Accuracy = 1.0\n",
      "Iter #105280:  Learning rate = 0.000096:  Batch Loss = 7.623673, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.624965667724609, Accuracy = 1.0\n",
      "Iter #105600:  Learning rate = 0.000096:  Batch Loss = 7.613905, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.665708541870117, Accuracy = 1.0\n",
      "Iter #105920:  Learning rate = 0.000096:  Batch Loss = 7.596121, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.597867488861084, Accuracy = 1.0\n",
      "Iter #106240:  Learning rate = 0.000096:  Batch Loss = 7.580740, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.6246771812438965, Accuracy = 0.9833333492279053\n",
      "Iter #106560:  Learning rate = 0.000096:  Batch Loss = 7.560597, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.5695061683654785, Accuracy = 1.0\n",
      "Iter #106880:  Learning rate = 0.000096:  Batch Loss = 7.547558, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.561875820159912, Accuracy = 1.0\n",
      "Iter #107200:  Learning rate = 0.000096:  Batch Loss = 7.531537, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.567415237426758, Accuracy = 1.0\n",
      "Iter #107520:  Learning rate = 0.000096:  Batch Loss = 7.518538, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.521399974822998, Accuracy = 1.0\n",
      "Iter #107840:  Learning rate = 0.000096:  Batch Loss = 7.499171, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.499669551849365, Accuracy = 1.0\n",
      "Iter #108160:  Learning rate = 0.000096:  Batch Loss = 7.483750, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.5031352043151855, Accuracy = 1.0\n",
      "Iter #108480:  Learning rate = 0.000096:  Batch Loss = 7.471816, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.485808849334717, Accuracy = 1.0\n",
      "Iter #108800:  Learning rate = 0.000096:  Batch Loss = 7.555861, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.464188098907471, Accuracy = 1.0\n",
      "Iter #109120:  Learning rate = 0.000096:  Batch Loss = 7.437643, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.466142177581787, Accuracy = 0.9833333492279053\n",
      "Iter #109440:  Learning rate = 0.000096:  Batch Loss = 7.420276, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.422053337097168, Accuracy = 1.0\n",
      "Iter #109760:  Learning rate = 0.000096:  Batch Loss = 7.417879, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.420220375061035, Accuracy = 1.0\n",
      "Iter #110080:  Learning rate = 0.000096:  Batch Loss = 7.392094, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.402562618255615, Accuracy = 1.0\n",
      "Iter #110400:  Learning rate = 0.000096:  Batch Loss = 7.375733, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.419144153594971, Accuracy = 0.9833333492279053\n",
      "Iter #110720:  Learning rate = 0.000096:  Batch Loss = 7.358666, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.365303993225098, Accuracy = 1.0\n",
      "Iter #111040:  Learning rate = 0.000096:  Batch Loss = 7.344544, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.411799907684326, Accuracy = 1.0\n",
      "Iter #111360:  Learning rate = 0.000096:  Batch Loss = 7.330375, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.3367228507995605, Accuracy = 1.0\n",
      "Iter #111680:  Learning rate = 0.000096:  Batch Loss = 7.313109, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.315063953399658, Accuracy = 1.0\n",
      "Iter #112000:  Learning rate = 0.000096:  Batch Loss = 7.314461, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.347482681274414, Accuracy = 0.9833333492279053\n",
      "Iter #112320:  Learning rate = 0.000096:  Batch Loss = 7.294576, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.289664268493652, Accuracy = 1.0\n",
      "Iter #112640:  Learning rate = 0.000096:  Batch Loss = 7.272262, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.30251932144165, Accuracy = 1.0\n",
      "Iter #112960:  Learning rate = 0.000096:  Batch Loss = 7.252324, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.267631530761719, Accuracy = 1.0\n",
      "Iter #113280:  Learning rate = 0.000096:  Batch Loss = 7.237537, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.281743049621582, Accuracy = 0.9833333492279053\n",
      "Iter #113600:  Learning rate = 0.000096:  Batch Loss = 7.230061, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.233664512634277, Accuracy = 1.0\n",
      "Iter #113920:  Learning rate = 0.000096:  Batch Loss = 7.208016, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.236462116241455, Accuracy = 1.0\n",
      "Iter #114240:  Learning rate = 0.000096:  Batch Loss = 7.192672, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.19830322265625, Accuracy = 1.0\n",
      "Iter #114560:  Learning rate = 0.000096:  Batch Loss = 7.181515, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.181199073791504, Accuracy = 1.0\n",
      "Iter #114880:  Learning rate = 0.000096:  Batch Loss = 7.192552, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.204470634460449, Accuracy = 0.9833333492279053\n",
      "Iter #115200:  Learning rate = 0.000096:  Batch Loss = 7.148187, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.151103496551514, Accuracy = 1.0\n",
      "Iter #115520:  Learning rate = 0.000096:  Batch Loss = 7.151646, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.178709506988525, Accuracy = 0.9833333492279053\n",
      "Iter #115840:  Learning rate = 0.000096:  Batch Loss = 7.118360, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.123289585113525, Accuracy = 1.0\n",
      "Iter #116160:  Learning rate = 0.000096:  Batch Loss = 7.104380, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.151092529296875, Accuracy = 0.9833333492279053\n",
      "Iter #116480:  Learning rate = 0.000096:  Batch Loss = 7.090242, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.108662128448486, Accuracy = 1.0\n",
      "Iter #116800:  Learning rate = 0.000096:  Batch Loss = 7.076637, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.091833591461182, Accuracy = 1.0\n",
      "Iter #117120:  Learning rate = 0.000096:  Batch Loss = 7.087725, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.080421447753906, Accuracy = 1.0\n",
      "Iter #117440:  Learning rate = 0.000096:  Batch Loss = 7.046661, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.04870080947876, Accuracy = 1.0\n",
      "Iter #117760:  Learning rate = 0.000096:  Batch Loss = 7.046470, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.073582649230957, Accuracy = 1.0\n",
      "Iter #118080:  Learning rate = 0.000096:  Batch Loss = 7.015533, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.021206855773926, Accuracy = 1.0\n",
      "Iter #118400:  Learning rate = 0.000096:  Batch Loss = 7.001674, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.020707607269287, Accuracy = 1.0\n",
      "Iter #118720:  Learning rate = 0.000096:  Batch Loss = 6.986321, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.010689735412598, Accuracy = 1.0\n",
      "Iter #119040:  Learning rate = 0.000096:  Batch Loss = 6.979901, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.989057540893555, Accuracy = 1.0\n",
      "Iter #119360:  Learning rate = 0.000096:  Batch Loss = 6.960733, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.960065841674805, Accuracy = 1.0\n",
      "Iter #119680:  Learning rate = 0.000096:  Batch Loss = 6.945550, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 7.041741371154785, Accuracy = 0.9333333373069763\n",
      "Iter #120000:  Learning rate = 0.000096:  Batch Loss = 6.966422, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.974729061126709, Accuracy = 0.9833333492279053\n",
      "Iter #120320:  Learning rate = 0.000096:  Batch Loss = 6.920781, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.9387407302856445, Accuracy = 1.0\n",
      "Iter #120640:  Learning rate = 0.000096:  Batch Loss = 6.990789, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.924230575561523, Accuracy = 1.0\n",
      "Iter #120960:  Learning rate = 0.000096:  Batch Loss = 6.906820, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.909974575042725, Accuracy = 1.0\n",
      "Iter #121280:  Learning rate = 0.000096:  Batch Loss = 6.886162, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.909130096435547, Accuracy = 1.0\n",
      "Iter #121600:  Learning rate = 0.000096:  Batch Loss = 6.873187, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.879726886749268, Accuracy = 1.0\n",
      "Iter #121920:  Learning rate = 0.000096:  Batch Loss = 6.877755, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.8974432945251465, Accuracy = 1.0\n",
      "Iter #122240:  Learning rate = 0.000096:  Batch Loss = 6.852890, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.8512959480285645, Accuracy = 1.0\n",
      "Iter #122560:  Learning rate = 0.000096:  Batch Loss = 7.119303, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.841096878051758, Accuracy = 1.0\n",
      "Iter #122880:  Learning rate = 0.000096:  Batch Loss = 6.871301, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.845364093780518, Accuracy = 1.0\n",
      "Iter #123200:  Learning rate = 0.000096:  Batch Loss = 6.816579, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.826984882354736, Accuracy = 1.0\n",
      "Iter #123520:  Learning rate = 0.000096:  Batch Loss = 6.807436, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.839261531829834, Accuracy = 1.0\n",
      "Iter #123840:  Learning rate = 0.000096:  Batch Loss = 6.814820, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.8188629150390625, Accuracy = 1.0\n",
      "Iter #124160:  Learning rate = 0.000096:  Batch Loss = 6.783559, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.7975993156433105, Accuracy = 1.0\n",
      "Iter #124480:  Learning rate = 0.000096:  Batch Loss = 6.775821, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.783208847045898, Accuracy = 1.0\n",
      "Iter #124800:  Learning rate = 0.000096:  Batch Loss = 6.793238, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.7819037437438965, Accuracy = 1.0\n",
      "Iter #125120:  Learning rate = 0.000096:  Batch Loss = 6.755462, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.764130592346191, Accuracy = 1.0\n",
      "Iter #125440:  Learning rate = 0.000096:  Batch Loss = 6.750903, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.759209156036377, Accuracy = 1.0\n",
      "Iter #125760:  Learning rate = 0.000096:  Batch Loss = 6.729512, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.746950626373291, Accuracy = 1.0\n",
      "Iter #126080:  Learning rate = 0.000096:  Batch Loss = 6.717166, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.7404351234436035, Accuracy = 1.0\n",
      "Iter #126400:  Learning rate = 0.000096:  Batch Loss = 6.719301, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.726280212402344, Accuracy = 1.0\n",
      "Iter #126720:  Learning rate = 0.000096:  Batch Loss = 6.695225, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.705113887786865, Accuracy = 1.0\n",
      "Iter #127040:  Learning rate = 0.000096:  Batch Loss = 6.740407, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.7025041580200195, Accuracy = 1.0\n",
      "Iter #127360:  Learning rate = 0.000096:  Batch Loss = 6.672468, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.680909633636475, Accuracy = 1.0\n",
      "Iter #127680:  Learning rate = 0.000096:  Batch Loss = 6.661911, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.66472864151001, Accuracy = 1.0\n",
      "Iter #128000:  Learning rate = 0.000096:  Batch Loss = 6.652750, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.696022033691406, Accuracy = 1.0\n",
      "Iter #128320:  Learning rate = 0.000096:  Batch Loss = 6.643583, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.654385089874268, Accuracy = 1.0\n",
      "Iter #128640:  Learning rate = 0.000096:  Batch Loss = 6.627781, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.661767482757568, Accuracy = 1.0\n",
      "Iter #128960:  Learning rate = 0.000096:  Batch Loss = 6.616713, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.624927520751953, Accuracy = 1.0\n",
      "Iter #129280:  Learning rate = 0.000096:  Batch Loss = 6.608078, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.679886817932129, Accuracy = 0.949999988079071\n",
      "Iter #129600:  Learning rate = 0.000096:  Batch Loss = 6.594799, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.598015785217285, Accuracy = 1.0\n",
      "Iter #129920:  Learning rate = 0.000096:  Batch Loss = 6.601371, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.616072177886963, Accuracy = 0.9833333492279053\n",
      "Iter #130240:  Learning rate = 0.000096:  Batch Loss = 6.572689, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.5875091552734375, Accuracy = 1.0\n",
      "Iter #130560:  Learning rate = 0.000096:  Batch Loss = 6.560908, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.582170009613037, Accuracy = 1.0\n",
      "Iter #130880:  Learning rate = 0.000096:  Batch Loss = 6.565130, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.56714391708374, Accuracy = 1.0\n",
      "Iter #131200:  Learning rate = 0.000096:  Batch Loss = 6.580844, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.549505233764648, Accuracy = 1.0\n",
      "Iter #131520:  Learning rate = 0.000096:  Batch Loss = 6.528219, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.550177097320557, Accuracy = 1.0\n",
      "Iter #131840:  Learning rate = 0.000096:  Batch Loss = 6.526279, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.540466785430908, Accuracy = 1.0\n",
      "Iter #132160:  Learning rate = 0.000096:  Batch Loss = 6.508014, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.52773904800415, Accuracy = 1.0\n",
      "Iter #132480:  Learning rate = 0.000096:  Batch Loss = 6.494812, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.50123405456543, Accuracy = 1.0\n",
      "Iter #132800:  Learning rate = 0.000096:  Batch Loss = 6.483120, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.485403537750244, Accuracy = 1.0\n",
      "Iter #133120:  Learning rate = 0.000096:  Batch Loss = 6.473214, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.498437881469727, Accuracy = 1.0\n",
      "Iter #133440:  Learning rate = 0.000096:  Batch Loss = 6.461965, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.474382400512695, Accuracy = 1.0\n",
      "Iter #133760:  Learning rate = 0.000096:  Batch Loss = 6.451868, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.555445671081543, Accuracy = 0.949999988079071\n",
      "Iter #134080:  Learning rate = 0.000096:  Batch Loss = 6.440911, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.441325664520264, Accuracy = 1.0\n",
      "Iter #134400:  Learning rate = 0.000096:  Batch Loss = 6.428440, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.428999423980713, Accuracy = 1.0\n",
      "Iter #134720:  Learning rate = 0.000096:  Batch Loss = 6.589001, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.42005729675293, Accuracy = 1.0\n",
      "Iter #135040:  Learning rate = 0.000096:  Batch Loss = 6.408309, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.4297194480896, Accuracy = 1.0\n",
      "Iter #135360:  Learning rate = 0.000096:  Batch Loss = 6.398322, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.402300834655762, Accuracy = 1.0\n",
      "Iter #135680:  Learning rate = 0.000096:  Batch Loss = 6.385948, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.431674003601074, Accuracy = 1.0\n",
      "Iter #136000:  Learning rate = 0.000096:  Batch Loss = 6.373422, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.38427734375, Accuracy = 1.0\n",
      "Iter #136320:  Learning rate = 0.000096:  Batch Loss = 6.366591, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.374731540679932, Accuracy = 1.0\n",
      "Iter #136640:  Learning rate = 0.000096:  Batch Loss = 6.352074, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.471920490264893, Accuracy = 0.9166666865348816\n",
      "Iter #136960:  Learning rate = 0.000096:  Batch Loss = 6.340867, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.344817161560059, Accuracy = 1.0\n",
      "Iter #137280:  Learning rate = 0.000096:  Batch Loss = 6.331451, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.3328375816345215, Accuracy = 1.0\n",
      "Iter #137600:  Learning rate = 0.000096:  Batch Loss = 6.322419, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.332541465759277, Accuracy = 1.0\n",
      "Iter #137920:  Learning rate = 0.000096:  Batch Loss = 6.382932, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.316717147827148, Accuracy = 1.0\n",
      "Iter #138240:  Learning rate = 0.000096:  Batch Loss = 6.297579, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.3282294273376465, Accuracy = 1.0\n",
      "Iter #138560:  Learning rate = 0.000096:  Batch Loss = 6.303460, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.3042755126953125, Accuracy = 1.0\n",
      "Iter #138880:  Learning rate = 0.000096:  Batch Loss = 6.281178, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.298410415649414, Accuracy = 1.0\n",
      "Iter #139200:  Learning rate = 0.000096:  Batch Loss = 6.265338, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.28053617477417, Accuracy = 1.0\n",
      "Iter #139520:  Learning rate = 0.000096:  Batch Loss = 6.254662, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.256268501281738, Accuracy = 1.0\n",
      "Iter #139840:  Learning rate = 0.000096:  Batch Loss = 6.255793, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.283547878265381, Accuracy = 1.0\n",
      "Iter #140160:  Learning rate = 0.000096:  Batch Loss = 6.234742, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.2434821128845215, Accuracy = 1.0\n",
      "Iter #140480:  Learning rate = 0.000096:  Batch Loss = 6.222624, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.233379364013672, Accuracy = 1.0\n",
      "Iter #140800:  Learning rate = 0.000096:  Batch Loss = 6.409681, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.213171005249023, Accuracy = 1.0\n",
      "Iter #141120:  Learning rate = 0.000096:  Batch Loss = 6.199084, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.207513809204102, Accuracy = 1.0\n",
      "Iter #141440:  Learning rate = 0.000096:  Batch Loss = 6.192010, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.203702926635742, Accuracy = 1.0\n",
      "Iter #141760:  Learning rate = 0.000096:  Batch Loss = 6.178177, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.205657958984375, Accuracy = 1.0\n",
      "Iter #142080:  Learning rate = 0.000096:  Batch Loss = 6.170983, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.177491664886475, Accuracy = 1.0\n",
      "Iter #142400:  Learning rate = 0.000096:  Batch Loss = 6.156573, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.171117782592773, Accuracy = 1.0\n",
      "Iter #142720:  Learning rate = 0.000096:  Batch Loss = 6.145499, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.1701979637146, Accuracy = 1.0\n",
      "Iter #143040:  Learning rate = 0.000096:  Batch Loss = 6.136479, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.147792339324951, Accuracy = 1.0\n",
      "Iter #143360:  Learning rate = 0.000096:  Batch Loss = 6.126473, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.156325340270996, Accuracy = 0.9833333492279053\n",
      "Iter #143680:  Learning rate = 0.000096:  Batch Loss = 6.114964, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.122120380401611, Accuracy = 1.0\n",
      "Iter #144000:  Learning rate = 0.000096:  Batch Loss = 6.105061, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.153384685516357, Accuracy = 0.9833333492279053\n",
      "Iter #144320:  Learning rate = 0.000096:  Batch Loss = 6.098536, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.103036880493164, Accuracy = 1.0\n",
      "Iter #144640:  Learning rate = 0.000096:  Batch Loss = 6.081627, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.098695755004883, Accuracy = 1.0\n",
      "Iter #144960:  Learning rate = 0.000096:  Batch Loss = 6.108592, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.087768077850342, Accuracy = 1.0\n",
      "Iter #145280:  Learning rate = 0.000096:  Batch Loss = 6.061095, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.079461574554443, Accuracy = 1.0\n",
      "Iter #145600:  Learning rate = 0.000096:  Batch Loss = 6.072663, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.079818248748779, Accuracy = 0.9833333492279053\n",
      "Iter #145920:  Learning rate = 0.000096:  Batch Loss = 6.038384, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.051722049713135, Accuracy = 1.0\n",
      "Iter #146240:  Learning rate = 0.000096:  Batch Loss = 6.027588, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.032323837280273, Accuracy = 1.0\n",
      "Iter #146560:  Learning rate = 0.000096:  Batch Loss = 6.029661, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.055868148803711, Accuracy = 0.9833333492279053\n",
      "Iter #146880:  Learning rate = 0.000096:  Batch Loss = 6.008538, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.012975215911865, Accuracy = 1.0\n",
      "Iter #147200:  Learning rate = 0.000096:  Batch Loss = 5.996530, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.01817512512207, Accuracy = 1.0\n",
      "Iter #147520:  Learning rate = 0.000096:  Batch Loss = 5.995107, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.994340896606445, Accuracy = 1.0\n",
      "Iter #147840:  Learning rate = 0.000096:  Batch Loss = 5.975000, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 6.017817974090576, Accuracy = 0.9833333492279053\n",
      "Iter #148160:  Learning rate = 0.000096:  Batch Loss = 5.972795, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.993028163909912, Accuracy = 0.9833333492279053\n",
      "Iter #148480:  Learning rate = 0.000096:  Batch Loss = 5.952584, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.957356929779053, Accuracy = 1.0\n",
      "Iter #148800:  Learning rate = 0.000096:  Batch Loss = 5.942382, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.950866222381592, Accuracy = 1.0\n",
      "Iter #149120:  Learning rate = 0.000096:  Batch Loss = 5.931473, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.938240051269531, Accuracy = 1.0\n",
      "Iter #149440:  Learning rate = 0.000096:  Batch Loss = 5.920522, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.9417805671691895, Accuracy = 1.0\n",
      "Iter #149760:  Learning rate = 0.000096:  Batch Loss = 5.918872, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.998219966888428, Accuracy = 0.949999988079071\n",
      "Iter #150080:  Learning rate = 0.000096:  Batch Loss = 5.905061, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.902647018432617, Accuracy = 1.0\n",
      "Iter #150400:  Learning rate = 0.000096:  Batch Loss = 5.895152, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.941515922546387, Accuracy = 0.9833333492279053\n",
      "Iter #150720:  Learning rate = 0.000096:  Batch Loss = 5.878413, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.89124870300293, Accuracy = 1.0\n",
      "Iter #151040:  Learning rate = 0.000096:  Batch Loss = 5.878881, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.88386344909668, Accuracy = 1.0\n",
      "Iter #151360:  Learning rate = 0.000096:  Batch Loss = 5.861072, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.877475261688232, Accuracy = 1.0\n",
      "Iter #151680:  Learning rate = 0.000096:  Batch Loss = 5.852180, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.85648250579834, Accuracy = 1.0\n",
      "Iter #152000:  Learning rate = 0.000096:  Batch Loss = 5.837021, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.857953071594238, Accuracy = 1.0\n",
      "Iter #152320:  Learning rate = 0.000096:  Batch Loss = 5.827508, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.84435510635376, Accuracy = 1.0\n",
      "Iter #152640:  Learning rate = 0.000096:  Batch Loss = 5.819664, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.849057674407959, Accuracy = 0.9833333492279053\n",
      "Iter #152960:  Learning rate = 0.000096:  Batch Loss = 5.806103, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.809482574462891, Accuracy = 1.0\n",
      "Iter #153280:  Learning rate = 0.000096:  Batch Loss = 5.815246, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.99001932144165, Accuracy = 0.8666666746139526\n",
      "Iter #153600:  Learning rate = 0.000096:  Batch Loss = 5.784709, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.785908222198486, Accuracy = 1.0\n",
      "Iter #153920:  Learning rate = 0.000096:  Batch Loss = 5.774117, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.786855220794678, Accuracy = 1.0\n",
      "Iter #154240:  Learning rate = 0.000096:  Batch Loss = 5.764930, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.782068729400635, Accuracy = 1.0\n",
      "Iter #154560:  Learning rate = 0.000096:  Batch Loss = 5.767321, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.781345844268799, Accuracy = 1.0\n",
      "Iter #154880:  Learning rate = 0.000096:  Batch Loss = 5.746510, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.76476526260376, Accuracy = 1.0\n",
      "Iter #155200:  Learning rate = 0.000096:  Batch Loss = 5.738226, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.744977951049805, Accuracy = 1.0\n",
      "Iter #155520:  Learning rate = 0.000096:  Batch Loss = 5.722822, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.7462687492370605, Accuracy = 1.0\n",
      "Iter #155840:  Learning rate = 0.000096:  Batch Loss = 5.712902, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.727924346923828, Accuracy = 1.0\n",
      "Iter #156160:  Learning rate = 0.000096:  Batch Loss = 5.704487, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.725280284881592, Accuracy = 1.0\n",
      "Iter #156480:  Learning rate = 0.000096:  Batch Loss = 5.742227, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.723527908325195, Accuracy = 0.9833333492279053\n",
      "Iter #156800:  Learning rate = 0.000096:  Batch Loss = 5.682397, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.694611549377441, Accuracy = 1.0\n",
      "Iter #157120:  Learning rate = 0.000096:  Batch Loss = 5.673434, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.687821865081787, Accuracy = 1.0\n",
      "Iter #157440:  Learning rate = 0.000096:  Batch Loss = 5.663362, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.679022789001465, Accuracy = 1.0\n",
      "Iter #157760:  Learning rate = 0.000096:  Batch Loss = 5.652451, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.671740531921387, Accuracy = 1.0\n",
      "Iter #158080:  Learning rate = 0.000096:  Batch Loss = 5.643071, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.660264492034912, Accuracy = 1.0\n",
      "Iter #158400:  Learning rate = 0.000096:  Batch Loss = 5.634548, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.634811878204346, Accuracy = 1.0\n",
      "Iter #158720:  Learning rate = 0.000096:  Batch Loss = 5.623033, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.66519832611084, Accuracy = 1.0\n",
      "Iter #159040:  Learning rate = 0.000096:  Batch Loss = 5.612106, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.617467403411865, Accuracy = 1.0\n",
      "Iter #159360:  Learning rate = 0.000096:  Batch Loss = 5.600275, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.618434906005859, Accuracy = 1.0\n",
      "Iter #159680:  Learning rate = 0.000096:  Batch Loss = 5.590609, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.6083526611328125, Accuracy = 1.0\n",
      "Iter #160000:  Learning rate = 0.000096:  Batch Loss = 5.581167, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.586620807647705, Accuracy = 1.0\n",
      "Iter #160320:  Learning rate = 0.000096:  Batch Loss = 5.572218, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.58074951171875, Accuracy = 1.0\n",
      "Iter #160640:  Learning rate = 0.000096:  Batch Loss = 5.560834, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.583113670349121, Accuracy = 1.0\n",
      "Iter #160960:  Learning rate = 0.000096:  Batch Loss = 5.549978, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.569201946258545, Accuracy = 1.0\n",
      "Iter #161280:  Learning rate = 0.000096:  Batch Loss = 5.567575, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.552245616912842, Accuracy = 1.0\n",
      "Iter #161600:  Learning rate = 0.000096:  Batch Loss = 5.529908, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.553539752960205, Accuracy = 1.0\n",
      "Iter #161920:  Learning rate = 0.000096:  Batch Loss = 5.521109, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.535302639007568, Accuracy = 1.0\n",
      "Iter #162240:  Learning rate = 0.000096:  Batch Loss = 5.537320, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.5545477867126465, Accuracy = 0.9833333492279053\n",
      "Iter #162560:  Learning rate = 0.000096:  Batch Loss = 5.501592, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.505608558654785, Accuracy = 1.0\n",
      "Iter #162880:  Learning rate = 0.000096:  Batch Loss = 5.489729, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.4992995262146, Accuracy = 1.0\n",
      "Iter #163200:  Learning rate = 0.000096:  Batch Loss = 5.517299, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.5008649826049805, Accuracy = 1.0\n",
      "Iter #163520:  Learning rate = 0.000096:  Batch Loss = 5.470009, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.4767351150512695, Accuracy = 1.0\n",
      "Iter #163840:  Learning rate = 0.000096:  Batch Loss = 5.466443, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.480175971984863, Accuracy = 1.0\n",
      "Iter #164160:  Learning rate = 0.000096:  Batch Loss = 5.450375, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.462400436401367, Accuracy = 1.0\n",
      "Iter #164480:  Learning rate = 0.000096:  Batch Loss = 5.441132, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.448049068450928, Accuracy = 1.0\n",
      "Iter #164800:  Learning rate = 0.000096:  Batch Loss = 5.429805, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.439874172210693, Accuracy = 1.0\n",
      "Iter #165120:  Learning rate = 0.000096:  Batch Loss = 5.424698, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.574563026428223, Accuracy = 0.8999999761581421\n",
      "Iter #165440:  Learning rate = 0.000096:  Batch Loss = 5.412190, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.412784576416016, Accuracy = 1.0\n",
      "Iter #165760:  Learning rate = 0.000096:  Batch Loss = 5.401855, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.4065985679626465, Accuracy = 1.0\n",
      "Iter #166080:  Learning rate = 0.000096:  Batch Loss = 5.390350, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.449306011199951, Accuracy = 0.9833333492279053\n",
      "Iter #166400:  Learning rate = 0.000096:  Batch Loss = 5.402045, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.404171943664551, Accuracy = 1.0\n",
      "Iter #166720:  Learning rate = 0.000096:  Batch Loss = 5.371891, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.380401134490967, Accuracy = 1.0\n",
      "Iter #167040:  Learning rate = 0.000096:  Batch Loss = 5.398586, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.408168315887451, Accuracy = 0.9833333492279053\n",
      "Iter #167360:  Learning rate = 0.000096:  Batch Loss = 5.351915, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.370419502258301, Accuracy = 1.0\n",
      "Iter #167680:  Learning rate = 0.000096:  Batch Loss = 5.342046, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.351006984710693, Accuracy = 1.0\n",
      "Iter #168000:  Learning rate = 0.000096:  Batch Loss = 5.341577, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.353488922119141, Accuracy = 1.0\n",
      "Iter #168320:  Learning rate = 0.000096:  Batch Loss = 5.322544, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.3561882972717285, Accuracy = 0.9833333492279053\n",
      "Iter #168640:  Learning rate = 0.000096:  Batch Loss = 5.312684, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.320057392120361, Accuracy = 1.0\n",
      "Iter #168960:  Learning rate = 0.000096:  Batch Loss = 5.303008, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.318203926086426, Accuracy = 1.0\n",
      "Iter #169280:  Learning rate = 0.000096:  Batch Loss = 5.295238, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.328922271728516, Accuracy = 1.0\n",
      "Iter #169600:  Learning rate = 0.000096:  Batch Loss = 5.283250, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.2951788902282715, Accuracy = 1.0\n",
      "Iter #169920:  Learning rate = 0.000096:  Batch Loss = 5.274258, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.323667049407959, Accuracy = 0.9666666388511658\n",
      "Iter #170240:  Learning rate = 0.000096:  Batch Loss = 5.266804, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.277218818664551, Accuracy = 1.0\n",
      "Iter #170560:  Learning rate = 0.000096:  Batch Loss = 5.256043, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.2704339027404785, Accuracy = 1.0\n",
      "Iter #170880:  Learning rate = 0.000096:  Batch Loss = 5.291394, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.26255464553833, Accuracy = 1.0\n",
      "Iter #171200:  Learning rate = 0.000096:  Batch Loss = 5.234901, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.264693260192871, Accuracy = 0.9833333492279053\n",
      "Iter #171520:  Learning rate = 0.000096:  Batch Loss = 5.225983, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.22906494140625, Accuracy = 1.0\n",
      "Iter #171840:  Learning rate = 0.000096:  Batch Loss = 5.225581, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.274760723114014, Accuracy = 1.0\n",
      "Iter #172160:  Learning rate = 0.000096:  Batch Loss = 5.206250, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.228530406951904, Accuracy = 1.0\n",
      "Iter #172480:  Learning rate = 0.000096:  Batch Loss = 5.200442, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.212723255157471, Accuracy = 1.0\n",
      "Iter #172800:  Learning rate = 0.000096:  Batch Loss = 5.206695, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.2385573387146, Accuracy = 0.9833333492279053\n",
      "Iter #173120:  Learning rate = 0.000096:  Batch Loss = 5.177896, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.1932783126831055, Accuracy = 1.0\n",
      "Iter #173440:  Learning rate = 0.000096:  Batch Loss = 5.181501, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.2045817375183105, Accuracy = 0.9833333492279053\n",
      "Iter #173760:  Learning rate = 0.000096:  Batch Loss = 5.159679, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.16677188873291, Accuracy = 1.0\n",
      "Iter #174080:  Learning rate = 0.000096:  Batch Loss = 5.151388, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.19267463684082, Accuracy = 0.9833333492279053\n",
      "Iter #174400:  Learning rate = 0.000096:  Batch Loss = 5.140939, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.181557655334473, Accuracy = 0.9833333492279053\n",
      "Iter #174720:  Learning rate = 0.000096:  Batch Loss = 5.135892, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.151496410369873, Accuracy = 1.0\n",
      "Iter #175040:  Learning rate = 0.000096:  Batch Loss = 5.120488, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.12959098815918, Accuracy = 1.0\n",
      "Iter #175360:  Learning rate = 0.000096:  Batch Loss = 5.111692, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.127163887023926, Accuracy = 1.0\n",
      "Iter #175680:  Learning rate = 0.000096:  Batch Loss = 5.153672, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.11873722076416, Accuracy = 1.0\n",
      "Iter #176000:  Learning rate = 0.000096:  Batch Loss = 5.092639, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.109979629516602, Accuracy = 1.0\n",
      "Iter #176320:  Learning rate = 0.000096:  Batch Loss = 5.085396, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.090942859649658, Accuracy = 1.0\n",
      "Iter #176640:  Learning rate = 0.000096:  Batch Loss = 5.073929, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.107043266296387, Accuracy = 0.9833333492279053\n",
      "Iter #176960:  Learning rate = 0.000096:  Batch Loss = 5.064711, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.0674920082092285, Accuracy = 1.0\n",
      "Iter #177280:  Learning rate = 0.000096:  Batch Loss = 5.069430, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.183218479156494, Accuracy = 0.9166666865348816\n",
      "Iter #177600:  Learning rate = 0.000096:  Batch Loss = 5.087363, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.064399719238281, Accuracy = 1.0\n",
      "Iter #177920:  Learning rate = 0.000096:  Batch Loss = 5.038552, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.044281959533691, Accuracy = 1.0\n",
      "Iter #178240:  Learning rate = 0.000096:  Batch Loss = 5.031383, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.042375087738037, Accuracy = 1.0\n",
      "Iter #178560:  Learning rate = 0.000096:  Batch Loss = 5.020365, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.056223392486572, Accuracy = 0.9833333492279053\n",
      "Iter #178880:  Learning rate = 0.000096:  Batch Loss = 5.014974, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.021756649017334, Accuracy = 1.0\n",
      "Iter #179200:  Learning rate = 0.000096:  Batch Loss = 5.001763, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.016181468963623, Accuracy = 1.0\n",
      "Iter #179520:  Learning rate = 0.000096:  Batch Loss = 4.994709, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.039450645446777, Accuracy = 0.9833333492279053\n",
      "Iter #179840:  Learning rate = 0.000096:  Batch Loss = 4.986610, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.9930500984191895, Accuracy = 1.0\n",
      "Iter #180160:  Learning rate = 0.000096:  Batch Loss = 4.980204, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 5.0056352615356445, Accuracy = 1.0\n",
      "Iter #180480:  Learning rate = 0.000096:  Batch Loss = 4.974624, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.9808502197265625, Accuracy = 1.0\n",
      "Iter #180800:  Learning rate = 0.000096:  Batch Loss = 4.992888, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.994013786315918, Accuracy = 0.9833333492279053\n",
      "Iter #181120:  Learning rate = 0.000096:  Batch Loss = 4.949681, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.965597152709961, Accuracy = 1.0\n",
      "Iter #181440:  Learning rate = 0.000096:  Batch Loss = 4.938061, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.951727390289307, Accuracy = 1.0\n",
      "Iter #181760:  Learning rate = 0.000096:  Batch Loss = 4.935316, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.970938682556152, Accuracy = 0.9833333492279053\n",
      "Iter #182080:  Learning rate = 0.000096:  Batch Loss = 4.920304, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.924968719482422, Accuracy = 1.0\n",
      "Iter #182400:  Learning rate = 0.000096:  Batch Loss = 4.913537, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.925933837890625, Accuracy = 1.0\n",
      "Iter #182720:  Learning rate = 0.000096:  Batch Loss = 4.902477, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.919609546661377, Accuracy = 1.0\n",
      "Iter #183040:  Learning rate = 0.000096:  Batch Loss = 4.893434, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.942173480987549, Accuracy = 0.9666666388511658\n",
      "Iter #183360:  Learning rate = 0.000096:  Batch Loss = 4.884084, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.889277458190918, Accuracy = 1.0\n",
      "Iter #183680:  Learning rate = 0.000096:  Batch Loss = 4.876171, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.88115119934082, Accuracy = 1.0\n",
      "Iter #184000:  Learning rate = 0.000096:  Batch Loss = 4.866947, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.922788143157959, Accuracy = 0.9666666388511658\n",
      "Iter #184320:  Learning rate = 0.000096:  Batch Loss = 5.291268, Accuracy = 0.875\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.881711006164551, Accuracy = 1.0\n",
      "Iter #184640:  Learning rate = 0.000096:  Batch Loss = 4.859428, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.887656211853027, Accuracy = 1.0\n",
      "Iter #184960:  Learning rate = 0.000096:  Batch Loss = 4.847637, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.86618709564209, Accuracy = 1.0\n",
      "Iter #185280:  Learning rate = 0.000096:  Batch Loss = 4.843078, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.886267185211182, Accuracy = 0.9666666388511658\n",
      "Iter #185600:  Learning rate = 0.000096:  Batch Loss = 4.840225, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.84329080581665, Accuracy = 1.0\n",
      "Iter #185920:  Learning rate = 0.000096:  Batch Loss = 4.856763, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.848630428314209, Accuracy = 1.0\n",
      "Iter #186240:  Learning rate = 0.000096:  Batch Loss = 4.825589, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.837945461273193, Accuracy = 1.0\n",
      "Iter #186560:  Learning rate = 0.000096:  Batch Loss = 4.867016, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.850099563598633, Accuracy = 1.0\n",
      "Iter #186880:  Learning rate = 0.000096:  Batch Loss = 4.813082, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.82391881942749, Accuracy = 1.0\n",
      "Iter #187200:  Learning rate = 0.000096:  Batch Loss = 4.811024, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.833644866943359, Accuracy = 1.0\n",
      "Iter #187520:  Learning rate = 0.000096:  Batch Loss = 4.800919, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.82103967666626, Accuracy = 1.0\n",
      "Iter #187840:  Learning rate = 0.000096:  Batch Loss = 4.799738, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.8083600997924805, Accuracy = 1.0\n",
      "Iter #188160:  Learning rate = 0.000096:  Batch Loss = 4.798505, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.820062160491943, Accuracy = 0.9833333492279053\n",
      "Iter #188480:  Learning rate = 0.000096:  Batch Loss = 4.783015, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.7952070236206055, Accuracy = 1.0\n",
      "Iter #188800:  Learning rate = 0.000096:  Batch Loss = 4.777018, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.810446262359619, Accuracy = 1.0\n",
      "Iter #189120:  Learning rate = 0.000096:  Batch Loss = 4.771702, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.77902364730835, Accuracy = 1.0\n",
      "Iter #189440:  Learning rate = 0.000096:  Batch Loss = 4.765222, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.790219306945801, Accuracy = 1.0\n",
      "Iter #189760:  Learning rate = 0.000096:  Batch Loss = 4.759781, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.781686305999756, Accuracy = 1.0\n",
      "Iter #190080:  Learning rate = 0.000096:  Batch Loss = 4.753150, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.759958744049072, Accuracy = 1.0\n",
      "Iter #190400:  Learning rate = 0.000096:  Batch Loss = 4.755519, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.795993804931641, Accuracy = 0.9833333492279053\n",
      "Iter #190720:  Learning rate = 0.000096:  Batch Loss = 4.741242, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.756764888763428, Accuracy = 1.0\n",
      "Iter #191040:  Learning rate = 0.000096:  Batch Loss = 4.736594, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.747307777404785, Accuracy = 1.0\n",
      "Iter #191360:  Learning rate = 0.000096:  Batch Loss = 4.732279, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.795827388763428, Accuracy = 0.9833333492279053\n",
      "Iter #191680:  Learning rate = 0.000096:  Batch Loss = 4.922628, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.727849960327148, Accuracy = 1.0\n",
      "Iter #192000:  Learning rate = 0.000096:  Batch Loss = 4.718391, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.72119665145874, Accuracy = 1.0\n",
      "Iter #192320:  Learning rate = 0.000096:  Batch Loss = 4.740159, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.7706379890441895, Accuracy = 0.9833333492279053\n",
      "Iter #192640:  Learning rate = 0.000096:  Batch Loss = 4.706698, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.716734409332275, Accuracy = 1.0\n",
      "Iter #192960:  Learning rate = 0.000096:  Batch Loss = 4.699807, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.725729465484619, Accuracy = 1.0\n",
      "Iter #193280:  Learning rate = 0.000096:  Batch Loss = 4.693879, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.726471424102783, Accuracy = 0.9833333492279053\n",
      "Iter #193600:  Learning rate = 0.000096:  Batch Loss = 4.690119, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.70287561416626, Accuracy = 1.0\n",
      "Iter #193920:  Learning rate = 0.000096:  Batch Loss = 4.682578, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.68889856338501, Accuracy = 1.0\n",
      "Iter #194240:  Learning rate = 0.000096:  Batch Loss = 4.677407, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.6987433433532715, Accuracy = 1.0\n",
      "Iter #194560:  Learning rate = 0.000096:  Batch Loss = 4.685372, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.708093643188477, Accuracy = 0.9833333492279053\n",
      "Iter #194880:  Learning rate = 0.000096:  Batch Loss = 4.664932, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.674820899963379, Accuracy = 1.0\n",
      "Iter #195200:  Learning rate = 0.000096:  Batch Loss = 4.660053, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.738238334655762, Accuracy = 0.949999988079071\n",
      "Iter #195520:  Learning rate = 0.000096:  Batch Loss = 4.652639, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.664484024047852, Accuracy = 1.0\n",
      "Iter #195840:  Learning rate = 0.000096:  Batch Loss = 4.647747, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.662904262542725, Accuracy = 1.0\n",
      "Iter #196160:  Learning rate = 0.000096:  Batch Loss = 4.640948, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.668424606323242, Accuracy = 0.9833333492279053\n",
      "Iter #196480:  Learning rate = 0.000096:  Batch Loss = 4.642832, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.6496968269348145, Accuracy = 1.0\n",
      "Iter #196800:  Learning rate = 0.000096:  Batch Loss = 4.633479, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.653290748596191, Accuracy = 1.0\n",
      "Iter #197120:  Learning rate = 0.000096:  Batch Loss = 4.624714, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.643289566040039, Accuracy = 1.0\n",
      "Iter #197440:  Learning rate = 0.000096:  Batch Loss = 4.620409, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.635612964630127, Accuracy = 1.0\n",
      "Iter #197760:  Learning rate = 0.000096:  Batch Loss = 4.611271, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.61677885055542, Accuracy = 1.0\n",
      "Iter #198080:  Learning rate = 0.000096:  Batch Loss = 4.606703, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.628139972686768, Accuracy = 1.0\n",
      "Iter #198400:  Learning rate = 0.000096:  Batch Loss = 4.610661, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.6283793449401855, Accuracy = 0.9833333492279053\n",
      "Iter #198720:  Learning rate = 0.000096:  Batch Loss = 4.593279, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.602540969848633, Accuracy = 1.0\n",
      "Iter #199040:  Learning rate = 0.000096:  Batch Loss = 4.589902, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.635353088378906, Accuracy = 0.9833333492279053\n",
      "Iter #199360:  Learning rate = 0.000096:  Batch Loss = 4.581298, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.607163906097412, Accuracy = 0.9833333492279053\n",
      "Iter #199680:  Learning rate = 0.000096:  Batch Loss = 4.575408, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.581445693969727, Accuracy = 1.0\n",
      "Iter #200000:  Learning rate = 0.000092:  Batch Loss = 4.569283, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.604325294494629, Accuracy = 0.9833333492279053\n",
      "Iter #200320:  Learning rate = 0.000092:  Batch Loss = 4.577364, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.609456539154053, Accuracy = 0.9666666388511658\n",
      "Iter #200640:  Learning rate = 0.000092:  Batch Loss = 4.561826, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.592352867126465, Accuracy = 1.0\n",
      "Iter #200960:  Learning rate = 0.000092:  Batch Loss = 4.556730, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.557076930999756, Accuracy = 1.0\n",
      "Iter #201280:  Learning rate = 0.000092:  Batch Loss = 4.547351, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.595954895019531, Accuracy = 0.9833333492279053\n",
      "Iter #201600:  Learning rate = 0.000092:  Batch Loss = 4.541286, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.550042152404785, Accuracy = 1.0\n",
      "Iter #201920:  Learning rate = 0.000092:  Batch Loss = 4.534737, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.549880504608154, Accuracy = 1.0\n",
      "Iter #202240:  Learning rate = 0.000092:  Batch Loss = 4.528221, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.568416595458984, Accuracy = 0.9833333492279053\n",
      "Iter #202560:  Learning rate = 0.000092:  Batch Loss = 4.522797, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.529290676116943, Accuracy = 1.0\n",
      "Iter #202880:  Learning rate = 0.000092:  Batch Loss = 4.518399, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.519974231719971, Accuracy = 1.0\n",
      "Iter #203200:  Learning rate = 0.000092:  Batch Loss = 4.511900, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.547192096710205, Accuracy = 0.9833333492279053\n",
      "Iter #203520:  Learning rate = 0.000092:  Batch Loss = 4.507169, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.510429382324219, Accuracy = 1.0\n",
      "Iter #203840:  Learning rate = 0.000092:  Batch Loss = 4.498777, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.501285552978516, Accuracy = 1.0\n",
      "Iter #204160:  Learning rate = 0.000092:  Batch Loss = 4.500567, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.625949859619141, Accuracy = 0.9166666865348816\n",
      "Iter #204480:  Learning rate = 0.000092:  Batch Loss = 4.578424, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.533408164978027, Accuracy = 0.9833333492279053\n",
      "Iter #204800:  Learning rate = 0.000092:  Batch Loss = 4.509939, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.491689682006836, Accuracy = 1.0\n",
      "Iter #205120:  Learning rate = 0.000092:  Batch Loss = 4.475867, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.4904327392578125, Accuracy = 1.0\n",
      "Iter #205440:  Learning rate = 0.000092:  Batch Loss = 4.469728, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.479745388031006, Accuracy = 1.0\n",
      "Iter #205760:  Learning rate = 0.000092:  Batch Loss = 4.464158, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.476294994354248, Accuracy = 1.0\n",
      "Iter #206080:  Learning rate = 0.000092:  Batch Loss = 4.490589, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.503577709197998, Accuracy = 0.9833333492279053\n",
      "Iter #206400:  Learning rate = 0.000092:  Batch Loss = 4.452466, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.465146064758301, Accuracy = 1.0\n",
      "Iter #206720:  Learning rate = 0.000092:  Batch Loss = 4.461267, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.468472480773926, Accuracy = 1.0\n",
      "Iter #207040:  Learning rate = 0.000092:  Batch Loss = 4.440645, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.458807468414307, Accuracy = 1.0\n",
      "Iter #207360:  Learning rate = 0.000092:  Batch Loss = 4.436349, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.448090553283691, Accuracy = 1.0\n",
      "Iter #207680:  Learning rate = 0.000092:  Batch Loss = 4.431378, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.4730544090271, Accuracy = 0.9833333492279053\n",
      "Iter #208000:  Learning rate = 0.000092:  Batch Loss = 4.423278, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.492982387542725, Accuracy = 0.9666666388511658\n",
      "Iter #208320:  Learning rate = 0.000092:  Batch Loss = 4.449066, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.4268293380737305, Accuracy = 1.0\n",
      "Iter #208640:  Learning rate = 0.000092:  Batch Loss = 4.411948, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.421265602111816, Accuracy = 1.0\n",
      "Iter #208960:  Learning rate = 0.000092:  Batch Loss = 4.406271, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.425557613372803, Accuracy = 1.0\n",
      "Iter #209280:  Learning rate = 0.000092:  Batch Loss = 4.399814, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.417728900909424, Accuracy = 1.0\n",
      "Iter #209600:  Learning rate = 0.000092:  Batch Loss = 4.393637, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.422244071960449, Accuracy = 0.9833333492279053\n",
      "Iter #209920:  Learning rate = 0.000092:  Batch Loss = 4.388904, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.408346652984619, Accuracy = 1.0\n",
      "Iter #210240:  Learning rate = 0.000092:  Batch Loss = 4.384323, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.390927791595459, Accuracy = 1.0\n",
      "Iter #210560:  Learning rate = 0.000092:  Batch Loss = 4.376578, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.379830837249756, Accuracy = 1.0\n",
      "Iter #210880:  Learning rate = 0.000092:  Batch Loss = 4.407030, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.386569499969482, Accuracy = 1.0\n",
      "Iter #211200:  Learning rate = 0.000092:  Batch Loss = 4.364480, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.387516021728516, Accuracy = 1.0\n",
      "Iter #211520:  Learning rate = 0.000092:  Batch Loss = 4.359744, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.3716254234313965, Accuracy = 1.0\n",
      "Iter #211840:  Learning rate = 0.000092:  Batch Loss = 4.352905, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.400493621826172, Accuracy = 0.9833333492279053\n",
      "Iter #212160:  Learning rate = 0.000092:  Batch Loss = 4.349187, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.363574028015137, Accuracy = 1.0\n",
      "Iter #212480:  Learning rate = 0.000092:  Batch Loss = 4.340975, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.345678806304932, Accuracy = 1.0\n",
      "Iter #212800:  Learning rate = 0.000092:  Batch Loss = 4.345145, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.372247219085693, Accuracy = 1.0\n",
      "Iter #213120:  Learning rate = 0.000092:  Batch Loss = 4.329414, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.335414886474609, Accuracy = 1.0\n",
      "Iter #213440:  Learning rate = 0.000092:  Batch Loss = 4.324812, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.328588008880615, Accuracy = 1.0\n",
      "Iter #213760:  Learning rate = 0.000092:  Batch Loss = 4.317523, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.342589855194092, Accuracy = 1.0\n",
      "Iter #214080:  Learning rate = 0.000092:  Batch Loss = 4.311934, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.333427429199219, Accuracy = 1.0\n",
      "Iter #214400:  Learning rate = 0.000092:  Batch Loss = 4.307919, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.318873882293701, Accuracy = 1.0\n",
      "Iter #214720:  Learning rate = 0.000092:  Batch Loss = 4.301950, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.30808687210083, Accuracy = 1.0\n",
      "Iter #215040:  Learning rate = 0.000092:  Batch Loss = 4.295934, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.331404209136963, Accuracy = 0.9833333492279053\n",
      "Iter #215360:  Learning rate = 0.000092:  Batch Loss = 4.288247, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.296934127807617, Accuracy = 1.0\n",
      "Iter #215680:  Learning rate = 0.000092:  Batch Loss = 4.288332, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.300816059112549, Accuracy = 1.0\n",
      "Iter #216000:  Learning rate = 0.000092:  Batch Loss = 4.276985, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.301141738891602, Accuracy = 1.0\n",
      "Iter #216320:  Learning rate = 0.000092:  Batch Loss = 4.289198, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.288886070251465, Accuracy = 1.0\n",
      "Iter #216640:  Learning rate = 0.000092:  Batch Loss = 4.269375, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.272000789642334, Accuracy = 1.0\n",
      "Iter #216960:  Learning rate = 0.000092:  Batch Loss = 4.264979, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.291320323944092, Accuracy = 0.9833333492279053\n",
      "Iter #217280:  Learning rate = 0.000092:  Batch Loss = 4.255058, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.262111186981201, Accuracy = 1.0\n",
      "Iter #217600:  Learning rate = 0.000092:  Batch Loss = 4.287635, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.25616979598999, Accuracy = 1.0\n",
      "Iter #217920:  Learning rate = 0.000092:  Batch Loss = 4.246502, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.249119758605957, Accuracy = 1.0\n",
      "Iter #218240:  Learning rate = 0.000092:  Batch Loss = 4.267354, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.27304744720459, Accuracy = 0.9833333492279053\n",
      "Iter #218560:  Learning rate = 0.000092:  Batch Loss = 4.230017, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.237233638763428, Accuracy = 1.0\n",
      "Iter #218880:  Learning rate = 0.000092:  Batch Loss = 4.226856, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.258523464202881, Accuracy = 1.0\n",
      "Iter #219200:  Learning rate = 0.000092:  Batch Loss = 4.217748, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.228742599487305, Accuracy = 1.0\n",
      "Iter #219520:  Learning rate = 0.000092:  Batch Loss = 4.210969, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.228546142578125, Accuracy = 1.0\n",
      "Iter #219840:  Learning rate = 0.000092:  Batch Loss = 4.205446, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.219534397125244, Accuracy = 1.0\n",
      "Iter #220160:  Learning rate = 0.000092:  Batch Loss = 4.203239, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.20512580871582, Accuracy = 1.0\n",
      "Iter #220480:  Learning rate = 0.000092:  Batch Loss = 4.251023, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.196970462799072, Accuracy = 1.0\n",
      "Iter #220800:  Learning rate = 0.000092:  Batch Loss = 4.311681, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.2626824378967285, Accuracy = 0.9666666388511658\n",
      "Iter #221120:  Learning rate = 0.000092:  Batch Loss = 4.181396, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.245609283447266, Accuracy = 0.9666666388511658\n",
      "Iter #221440:  Learning rate = 0.000092:  Batch Loss = 4.176384, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.177678108215332, Accuracy = 1.0\n",
      "Iter #221760:  Learning rate = 0.000092:  Batch Loss = 4.195401, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.257508277893066, Accuracy = 0.949999988079071\n",
      "Iter #222080:  Learning rate = 0.000092:  Batch Loss = 4.166694, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.165596961975098, Accuracy = 1.0\n",
      "Iter #222400:  Learning rate = 0.000092:  Batch Loss = 4.157506, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.161708354949951, Accuracy = 1.0\n",
      "Iter #222720:  Learning rate = 0.000092:  Batch Loss = 4.152403, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.159309387207031, Accuracy = 1.0\n",
      "Iter #223040:  Learning rate = 0.000092:  Batch Loss = 4.150568, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.201066970825195, Accuracy = 0.9666666388511658\n",
      "Iter #223360:  Learning rate = 0.000092:  Batch Loss = 4.140367, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.180051326751709, Accuracy = 0.9666666388511658\n",
      "Iter #223680:  Learning rate = 0.000092:  Batch Loss = 4.135477, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.138571262359619, Accuracy = 1.0\n",
      "Iter #224000:  Learning rate = 0.000092:  Batch Loss = 4.128515, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.133383274078369, Accuracy = 1.0\n",
      "Iter #224320:  Learning rate = 0.000092:  Batch Loss = 4.123374, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.169130802154541, Accuracy = 0.9833333492279053\n",
      "Iter #224640:  Learning rate = 0.000092:  Batch Loss = 4.115897, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.139171600341797, Accuracy = 1.0\n",
      "Iter #224960:  Learning rate = 0.000092:  Batch Loss = 4.110578, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.1230340003967285, Accuracy = 1.0\n",
      "Iter #225280:  Learning rate = 0.000092:  Batch Loss = 4.119210, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.167596340179443, Accuracy = 0.9833333492279053\n",
      "Iter #225600:  Learning rate = 0.000092:  Batch Loss = 4.100077, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.111467361450195, Accuracy = 1.0\n",
      "Iter #225920:  Learning rate = 0.000092:  Batch Loss = 4.092269, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.135414123535156, Accuracy = 0.9833333492279053\n",
      "Iter #226240:  Learning rate = 0.000092:  Batch Loss = 4.086573, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.113261699676514, Accuracy = 0.9833333492279053\n",
      "Iter #226560:  Learning rate = 0.000092:  Batch Loss = 4.080360, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.103650093078613, Accuracy = 1.0\n",
      "Iter #226880:  Learning rate = 0.000092:  Batch Loss = 4.086549, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.165556907653809, Accuracy = 0.9666666388511658\n",
      "Iter #227200:  Learning rate = 0.000092:  Batch Loss = 4.069610, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.076418876647949, Accuracy = 1.0\n",
      "Iter #227520:  Learning rate = 0.000092:  Batch Loss = 4.064373, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.067842483520508, Accuracy = 1.0\n",
      "Iter #227840:  Learning rate = 0.000092:  Batch Loss = 4.108848, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.091198444366455, Accuracy = 0.9666666388511658\n",
      "Iter #228160:  Learning rate = 0.000092:  Batch Loss = 4.067747, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.111884593963623, Accuracy = 0.9833333492279053\n",
      "Iter #228480:  Learning rate = 0.000092:  Batch Loss = 4.046541, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.050209999084473, Accuracy = 1.0\n",
      "Iter #228800:  Learning rate = 0.000092:  Batch Loss = 4.038072, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.043402671813965, Accuracy = 1.0\n",
      "Iter #229120:  Learning rate = 0.000092:  Batch Loss = 4.032623, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.0587568283081055, Accuracy = 1.0\n",
      "Iter #229440:  Learning rate = 0.000092:  Batch Loss = 4.027296, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.051589488983154, Accuracy = 0.9833333492279053\n",
      "Iter #229760:  Learning rate = 0.000092:  Batch Loss = 4.024293, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.042954444885254, Accuracy = 1.0\n",
      "Iter #230080:  Learning rate = 0.000092:  Batch Loss = 4.019464, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.05752420425415, Accuracy = 0.9666666388511658\n",
      "Iter #230400:  Learning rate = 0.000092:  Batch Loss = 4.009059, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.016608238220215, Accuracy = 1.0\n",
      "Iter #230720:  Learning rate = 0.000092:  Batch Loss = 4.004246, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.017037391662598, Accuracy = 1.0\n",
      "Iter #231040:  Learning rate = 0.000092:  Batch Loss = 3.998531, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.031885623931885, Accuracy = 1.0\n",
      "Iter #231360:  Learning rate = 0.000092:  Batch Loss = 3.991950, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.0087690353393555, Accuracy = 1.0\n",
      "Iter #231680:  Learning rate = 0.000092:  Batch Loss = 3.986206, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.019749641418457, Accuracy = 1.0\n",
      "Iter #232000:  Learning rate = 0.000092:  Batch Loss = 3.980113, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.00774621963501, Accuracy = 0.9833333492279053\n",
      "Iter #232320:  Learning rate = 0.000092:  Batch Loss = 3.974271, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.982689619064331, Accuracy = 1.0\n",
      "Iter #232640:  Learning rate = 0.000092:  Batch Loss = 3.967550, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.975982666015625, Accuracy = 1.0\n",
      "Iter #232960:  Learning rate = 0.000092:  Batch Loss = 3.962574, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.9726152420043945, Accuracy = 1.0\n",
      "Iter #233280:  Learning rate = 0.000092:  Batch Loss = 3.956980, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.011303424835205, Accuracy = 0.9833333492279053\n",
      "Iter #233600:  Learning rate = 0.000092:  Batch Loss = 3.950833, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.9676244258880615, Accuracy = 1.0\n",
      "Iter #233920:  Learning rate = 0.000092:  Batch Loss = 3.944063, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.974775552749634, Accuracy = 0.9833333492279053\n",
      "Iter #234240:  Learning rate = 0.000092:  Batch Loss = 3.941047, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 4.003666877746582, Accuracy = 0.9666666388511658\n",
      "Iter #234560:  Learning rate = 0.000092:  Batch Loss = 3.931807, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.9437739849090576, Accuracy = 1.0\n",
      "Iter #234880:  Learning rate = 0.000092:  Batch Loss = 3.928660, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.9859189987182617, Accuracy = 0.9833333492279053\n",
      "Iter #235200:  Learning rate = 0.000092:  Batch Loss = 3.920410, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.9249839782714844, Accuracy = 1.0\n",
      "Iter #235520:  Learning rate = 0.000092:  Batch Loss = 3.921674, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.952409505844116, Accuracy = 0.9833333492279053\n",
      "Iter #235840:  Learning rate = 0.000092:  Batch Loss = 3.911052, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.9343228340148926, Accuracy = 0.9833333492279053\n",
      "Iter #236160:  Learning rate = 0.000092:  Batch Loss = 3.906969, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.9155547618865967, Accuracy = 1.0\n",
      "Iter #236480:  Learning rate = 0.000092:  Batch Loss = 3.897389, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.9301750659942627, Accuracy = 0.9833333492279053\n",
      "Iter #236800:  Learning rate = 0.000092:  Batch Loss = 3.893404, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.8992180824279785, Accuracy = 1.0\n",
      "Iter #237120:  Learning rate = 0.000092:  Batch Loss = 3.885622, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.9210128784179688, Accuracy = 0.9833333492279053\n",
      "Iter #237440:  Learning rate = 0.000092:  Batch Loss = 3.882493, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.894500255584717, Accuracy = 1.0\n",
      "Iter #237760:  Learning rate = 0.000092:  Batch Loss = 3.895957, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.952346086502075, Accuracy = 0.9333333373069763\n",
      "Iter #238080:  Learning rate = 0.000092:  Batch Loss = 3.868751, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.8998239040374756, Accuracy = 0.9833333492279053\n",
      "Iter #238400:  Learning rate = 0.000092:  Batch Loss = 3.862429, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.8830771446228027, Accuracy = 1.0\n",
      "Iter #238720:  Learning rate = 0.000092:  Batch Loss = 3.856084, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.8982629776000977, Accuracy = 0.9833333492279053\n",
      "Iter #239040:  Learning rate = 0.000092:  Batch Loss = 3.851998, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.8837196826934814, Accuracy = 0.9833333492279053\n",
      "Iter #239360:  Learning rate = 0.000092:  Batch Loss = 3.851243, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.85494327545166, Accuracy = 1.0\n",
      "Iter #239680:  Learning rate = 0.000092:  Batch Loss = 3.840848, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.8707289695739746, Accuracy = 1.0\n",
      "Iter #240000:  Learning rate = 0.000092:  Batch Loss = 4.073975, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.841249704360962, Accuracy = 1.0\n",
      "Iter #240320:  Learning rate = 0.000092:  Batch Loss = 3.827502, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.872199296951294, Accuracy = 1.0\n",
      "Iter #240640:  Learning rate = 0.000092:  Batch Loss = 3.821863, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.8286898136138916, Accuracy = 1.0\n",
      "Iter #240960:  Learning rate = 0.000092:  Batch Loss = 3.815731, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.8708298206329346, Accuracy = 0.9666666388511658\n",
      "Iter #241280:  Learning rate = 0.000092:  Batch Loss = 3.809869, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.813793897628784, Accuracy = 1.0\n",
      "Iter #241600:  Learning rate = 0.000092:  Batch Loss = 3.806452, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.858877658843994, Accuracy = 0.9833333492279053\n",
      "Iter #241920:  Learning rate = 0.000092:  Batch Loss = 3.799885, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.823911428451538, Accuracy = 1.0\n",
      "Iter #242240:  Learning rate = 0.000092:  Batch Loss = 3.793328, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.827117919921875, Accuracy = 0.9833333492279053\n",
      "Iter #242560:  Learning rate = 0.000092:  Batch Loss = 3.789779, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.7948341369628906, Accuracy = 1.0\n",
      "Iter #242880:  Learning rate = 0.000092:  Batch Loss = 4.387135, Accuracy = 0.875\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.8402438163757324, Accuracy = 0.9666666388511658\n",
      "Iter #243200:  Learning rate = 0.000092:  Batch Loss = 3.781814, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.8152081966400146, Accuracy = 0.9833333492279053\n",
      "Iter #243520:  Learning rate = 0.000092:  Batch Loss = 3.784542, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.778855800628662, Accuracy = 1.0\n",
      "Iter #243840:  Learning rate = 0.000092:  Batch Loss = 3.774623, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.8316051959991455, Accuracy = 0.9666666388511658\n",
      "Iter #244160:  Learning rate = 0.000092:  Batch Loss = 3.827983, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.813547134399414, Accuracy = 0.9666666388511658\n",
      "Iter #244480:  Learning rate = 0.000092:  Batch Loss = 3.764678, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.787982702255249, Accuracy = 1.0\n",
      "Iter #244800:  Learning rate = 0.000092:  Batch Loss = 3.813269, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.771324872970581, Accuracy = 1.0\n",
      "Iter #245120:  Learning rate = 0.000092:  Batch Loss = 3.772697, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.785098075866699, Accuracy = 1.0\n",
      "Iter #245440:  Learning rate = 0.000092:  Batch Loss = 3.752671, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.759274959564209, Accuracy = 1.0\n",
      "Iter #245760:  Learning rate = 0.000092:  Batch Loss = 3.749775, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.792384624481201, Accuracy = 0.9833333492279053\n",
      "Iter #246080:  Learning rate = 0.000092:  Batch Loss = 3.745883, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.780115842819214, Accuracy = 0.9833333492279053\n",
      "Iter #246400:  Learning rate = 0.000092:  Batch Loss = 3.742501, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.754376173019409, Accuracy = 1.0\n",
      "Iter #246720:  Learning rate = 0.000092:  Batch Loss = 3.737984, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.74464750289917, Accuracy = 1.0\n",
      "Iter #247040:  Learning rate = 0.000092:  Batch Loss = 3.733973, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.7542364597320557, Accuracy = 1.0\n",
      "Iter #247360:  Learning rate = 0.000092:  Batch Loss = 3.729662, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.746689796447754, Accuracy = 1.0\n",
      "Iter #247680:  Learning rate = 0.000092:  Batch Loss = 3.726174, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.7377820014953613, Accuracy = 1.0\n",
      "Iter #248000:  Learning rate = 0.000092:  Batch Loss = 3.724342, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.726635694503784, Accuracy = 1.0\n",
      "Iter #248320:  Learning rate = 0.000092:  Batch Loss = 3.721766, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.746408462524414, Accuracy = 0.9833333492279053\n",
      "Iter #248640:  Learning rate = 0.000092:  Batch Loss = 3.715131, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.7320401668548584, Accuracy = 1.0\n",
      "Iter #248960:  Learning rate = 0.000092:  Batch Loss = 3.711952, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.7203798294067383, Accuracy = 1.0\n",
      "Iter #249280:  Learning rate = 0.000092:  Batch Loss = 3.713804, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.720076084136963, Accuracy = 1.0\n",
      "Iter #249600:  Learning rate = 0.000092:  Batch Loss = 3.703602, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.7093207836151123, Accuracy = 1.0\n",
      "Iter #249920:  Learning rate = 0.000092:  Batch Loss = 3.700533, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.714574098587036, Accuracy = 1.0\n",
      "Iter #250240:  Learning rate = 0.000092:  Batch Loss = 3.734113, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.712583541870117, Accuracy = 1.0\n",
      "Iter #250560:  Learning rate = 0.000092:  Batch Loss = 3.691502, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.7027227878570557, Accuracy = 1.0\n",
      "Iter #250880:  Learning rate = 0.000092:  Batch Loss = 3.687605, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.7053604125976562, Accuracy = 1.0\n",
      "Iter #251200:  Learning rate = 0.000092:  Batch Loss = 3.683841, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.7041752338409424, Accuracy = 1.0\n",
      "Iter #251520:  Learning rate = 0.000092:  Batch Loss = 3.681445, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.6840686798095703, Accuracy = 1.0\n",
      "Iter #251840:  Learning rate = 0.000092:  Batch Loss = 3.677199, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.7227132320404053, Accuracy = 0.9666666388511658\n",
      "Iter #252160:  Learning rate = 0.000092:  Batch Loss = 3.674252, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.6928608417510986, Accuracy = 1.0\n",
      "Iter #252480:  Learning rate = 0.000092:  Batch Loss = 3.669491, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.761537790298462, Accuracy = 0.9333333373069763\n",
      "Iter #252800:  Learning rate = 0.000092:  Batch Loss = 3.671661, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.6666526794433594, Accuracy = 1.0\n",
      "Iter #253120:  Learning rate = 0.000092:  Batch Loss = 3.665047, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.663649559020996, Accuracy = 1.0\n",
      "Iter #253440:  Learning rate = 0.000092:  Batch Loss = 3.666339, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.6934657096862793, Accuracy = 1.0\n",
      "Iter #253760:  Learning rate = 0.000092:  Batch Loss = 3.652159, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.65704607963562, Accuracy = 1.0\n",
      "Iter #254080:  Learning rate = 0.000092:  Batch Loss = 3.650489, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.6549112796783447, Accuracy = 1.0\n",
      "Iter #254400:  Learning rate = 0.000092:  Batch Loss = 3.645887, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.6509249210357666, Accuracy = 1.0\n",
      "Iter #254720:  Learning rate = 0.000092:  Batch Loss = 3.648390, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.649289131164551, Accuracy = 1.0\n",
      "Iter #255040:  Learning rate = 0.000092:  Batch Loss = 3.679906, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.678684949874878, Accuracy = 0.9833333492279053\n",
      "Iter #255360:  Learning rate = 0.000092:  Batch Loss = 3.633932, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.6433117389678955, Accuracy = 1.0\n",
      "Iter #255680:  Learning rate = 0.000092:  Batch Loss = 3.631529, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.6542739868164062, Accuracy = 1.0\n",
      "Iter #256000:  Learning rate = 0.000092:  Batch Loss = 3.627764, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.6397852897644043, Accuracy = 1.0\n",
      "Iter #256320:  Learning rate = 0.000092:  Batch Loss = 3.624755, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.637296676635742, Accuracy = 1.0\n",
      "Iter #256640:  Learning rate = 0.000092:  Batch Loss = 3.619799, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.632261037826538, Accuracy = 1.0\n",
      "Iter #256960:  Learning rate = 0.000092:  Batch Loss = 3.615245, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.619685173034668, Accuracy = 1.0\n",
      "Iter #257280:  Learning rate = 0.000092:  Batch Loss = 3.622709, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.6434953212738037, Accuracy = 0.9833333492279053\n",
      "Iter #257600:  Learning rate = 0.000092:  Batch Loss = 3.608794, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.6110942363739014, Accuracy = 1.0\n",
      "Iter #257920:  Learning rate = 0.000092:  Batch Loss = 3.611383, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.8349075317382812, Accuracy = 0.8666666746139526\n",
      "Iter #258240:  Learning rate = 0.000092:  Batch Loss = 3.599664, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.6118643283843994, Accuracy = 1.0\n",
      "Iter #258560:  Learning rate = 0.000092:  Batch Loss = 3.595531, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.623915910720825, Accuracy = 1.0\n",
      "Iter #258880:  Learning rate = 0.000092:  Batch Loss = 3.593283, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.596951484680176, Accuracy = 1.0\n",
      "Iter #259200:  Learning rate = 0.000092:  Batch Loss = 3.589431, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.616286277770996, Accuracy = 1.0\n",
      "Iter #259520:  Learning rate = 0.000092:  Batch Loss = 3.584946, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.587843418121338, Accuracy = 1.0\n",
      "Iter #259840:  Learning rate = 0.000092:  Batch Loss = 3.582189, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.5933401584625244, Accuracy = 1.0\n",
      "Iter #260160:  Learning rate = 0.000092:  Batch Loss = 3.584216, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.595715284347534, Accuracy = 1.0\n",
      "Iter #260480:  Learning rate = 0.000092:  Batch Loss = 3.613965, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.5850324630737305, Accuracy = 1.0\n",
      "Iter #260800:  Learning rate = 0.000092:  Batch Loss = 3.579496, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.5866122245788574, Accuracy = 1.0\n",
      "Iter #261120:  Learning rate = 0.000092:  Batch Loss = 3.565757, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.58746337890625, Accuracy = 1.0\n",
      "Iter #261440:  Learning rate = 0.000092:  Batch Loss = 3.564044, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.6041207313537598, Accuracy = 0.9666666388511658\n",
      "Iter #261760:  Learning rate = 0.000092:  Batch Loss = 3.559125, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.562009572982788, Accuracy = 1.0\n",
      "Iter #262080:  Learning rate = 0.000092:  Batch Loss = 3.555543, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.5715415477752686, Accuracy = 1.0\n",
      "Iter #262400:  Learning rate = 0.000092:  Batch Loss = 3.550822, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.6729941368103027, Accuracy = 0.9333333373069763\n",
      "Iter #262720:  Learning rate = 0.000092:  Batch Loss = 3.545762, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.5480754375457764, Accuracy = 1.0\n",
      "Iter #263040:  Learning rate = 0.000092:  Batch Loss = 3.541652, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.543992280960083, Accuracy = 1.0\n",
      "Iter #263360:  Learning rate = 0.000092:  Batch Loss = 3.542644, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.544630289077759, Accuracy = 1.0\n",
      "Iter #263680:  Learning rate = 0.000092:  Batch Loss = 3.538243, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.615752935409546, Accuracy = 0.949999988079071\n",
      "Iter #264000:  Learning rate = 0.000092:  Batch Loss = 3.530718, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.540894031524658, Accuracy = 1.0\n",
      "Iter #264320:  Learning rate = 0.000092:  Batch Loss = 3.548289, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.547361135482788, Accuracy = 1.0\n",
      "Iter #264640:  Learning rate = 0.000092:  Batch Loss = 3.523740, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.5537149906158447, Accuracy = 0.9833333492279053\n",
      "Iter #264960:  Learning rate = 0.000092:  Batch Loss = 3.519299, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.557546377182007, Accuracy = 0.9833333492279053\n",
      "Iter #265280:  Learning rate = 0.000092:  Batch Loss = 3.515417, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.5306973457336426, Accuracy = 1.0\n",
      "Iter #265600:  Learning rate = 0.000092:  Batch Loss = 3.515548, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.524937152862549, Accuracy = 1.0\n",
      "Iter #265920:  Learning rate = 0.000092:  Batch Loss = 3.516156, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.5226941108703613, Accuracy = 1.0\n",
      "Iter #266240:  Learning rate = 0.000092:  Batch Loss = 3.505741, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.5216217041015625, Accuracy = 1.0\n",
      "Iter #266560:  Learning rate = 0.000092:  Batch Loss = 3.499481, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.507887840270996, Accuracy = 1.0\n",
      "Iter #266880:  Learning rate = 0.000092:  Batch Loss = 3.496267, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.5263376235961914, Accuracy = 0.9833333492279053\n",
      "Iter #267200:  Learning rate = 0.000092:  Batch Loss = 3.497194, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.527482271194458, Accuracy = 1.0\n",
      "Iter #267520:  Learning rate = 0.000092:  Batch Loss = 3.489685, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.4915781021118164, Accuracy = 1.0\n",
      "Iter #267840:  Learning rate = 0.000092:  Batch Loss = 3.484331, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.5312163829803467, Accuracy = 0.9666666388511658\n",
      "Iter #268160:  Learning rate = 0.000092:  Batch Loss = 3.479803, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.484567642211914, Accuracy = 1.0\n",
      "Iter #268480:  Learning rate = 0.000092:  Batch Loss = 3.476655, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.4835281372070312, Accuracy = 1.0\n",
      "Iter #268800:  Learning rate = 0.000092:  Batch Loss = 3.474588, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.4824140071868896, Accuracy = 1.0\n",
      "Iter #269120:  Learning rate = 0.000092:  Batch Loss = 3.472824, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.4919273853302, Accuracy = 1.0\n",
      "Iter #269440:  Learning rate = 0.000092:  Batch Loss = 3.466502, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.4995059967041016, Accuracy = 0.9833333492279053\n",
      "Iter #269760:  Learning rate = 0.000092:  Batch Loss = 3.461238, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.4996907711029053, Accuracy = 0.9833333492279053\n",
      "Iter #270080:  Learning rate = 0.000092:  Batch Loss = 3.456155, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.464548349380493, Accuracy = 1.0\n",
      "Iter #270400:  Learning rate = 0.000092:  Batch Loss = 3.451596, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.4839677810668945, Accuracy = 0.9833333492279053\n",
      "Iter #270720:  Learning rate = 0.000092:  Batch Loss = 3.450141, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.469762086868286, Accuracy = 1.0\n",
      "Iter #271040:  Learning rate = 0.000092:  Batch Loss = 3.445396, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.472975969314575, Accuracy = 0.9833333492279053\n",
      "Iter #271360:  Learning rate = 0.000092:  Batch Loss = 3.442079, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.4655144214630127, Accuracy = 1.0\n",
      "Iter #271680:  Learning rate = 0.000092:  Batch Loss = 3.440137, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.4726338386535645, Accuracy = 0.9833333492279053\n",
      "Iter #272000:  Learning rate = 0.000092:  Batch Loss = 3.433030, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.443345546722412, Accuracy = 1.0\n",
      "Iter #272320:  Learning rate = 0.000092:  Batch Loss = 3.428835, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.4537391662597656, Accuracy = 1.0\n",
      "Iter #272640:  Learning rate = 0.000092:  Batch Loss = 3.424301, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.4424259662628174, Accuracy = 1.0\n",
      "Iter #272960:  Learning rate = 0.000092:  Batch Loss = 3.425073, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.438448667526245, Accuracy = 1.0\n",
      "Iter #273280:  Learning rate = 0.000092:  Batch Loss = 3.416326, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.445848226547241, Accuracy = 0.9833333492279053\n",
      "Iter #273600:  Learning rate = 0.000092:  Batch Loss = 3.413162, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.418912172317505, Accuracy = 1.0\n",
      "Iter #273920:  Learning rate = 0.000092:  Batch Loss = 3.411722, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.461117744445801, Accuracy = 1.0\n",
      "Iter #274240:  Learning rate = 0.000092:  Batch Loss = 3.406771, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.4132239818573, Accuracy = 1.0\n",
      "Iter #274560:  Learning rate = 0.000092:  Batch Loss = 3.400157, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.4041998386383057, Accuracy = 1.0\n",
      "Iter #274880:  Learning rate = 0.000092:  Batch Loss = 3.419853, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.4123849868774414, Accuracy = 1.0\n",
      "Iter #275200:  Learning rate = 0.000092:  Batch Loss = 3.393978, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.399817705154419, Accuracy = 1.0\n",
      "Iter #275520:  Learning rate = 0.000092:  Batch Loss = 3.387783, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.3908841609954834, Accuracy = 1.0\n",
      "Iter #275840:  Learning rate = 0.000092:  Batch Loss = 3.389216, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.4138314723968506, Accuracy = 1.0\n",
      "Iter #276160:  Learning rate = 0.000092:  Batch Loss = 3.380775, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.4041495323181152, Accuracy = 1.0\n",
      "Iter #276480:  Learning rate = 0.000092:  Batch Loss = 3.378846, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.395411252975464, Accuracy = 1.0\n",
      "Iter #276800:  Learning rate = 0.000092:  Batch Loss = 3.399444, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.435973882675171, Accuracy = 0.9666666388511658\n",
      "Iter #277120:  Learning rate = 0.000092:  Batch Loss = 3.368014, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.4018642902374268, Accuracy = 0.9833333492279053\n",
      "Iter #277440:  Learning rate = 0.000092:  Batch Loss = 3.363310, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.3724210262298584, Accuracy = 1.0\n",
      "Iter #277760:  Learning rate = 0.000092:  Batch Loss = 3.366203, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.4000589847564697, Accuracy = 0.9833333492279053\n",
      "Iter #278080:  Learning rate = 0.000092:  Batch Loss = 3.356455, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.372419595718384, Accuracy = 1.0\n",
      "Iter #278400:  Learning rate = 0.000092:  Batch Loss = 3.356158, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.3767778873443604, Accuracy = 1.0\n",
      "Iter #278720:  Learning rate = 0.000092:  Batch Loss = 3.349498, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.3616247177124023, Accuracy = 1.0\n",
      "Iter #279040:  Learning rate = 0.000092:  Batch Loss = 3.344666, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.353942632675171, Accuracy = 1.0\n",
      "Iter #279360:  Learning rate = 0.000092:  Batch Loss = 3.340083, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.356046676635742, Accuracy = 1.0\n",
      "Iter #279680:  Learning rate = 0.000092:  Batch Loss = 3.337744, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.342650890350342, Accuracy = 1.0\n",
      "Iter #280000:  Learning rate = 0.000092:  Batch Loss = 3.333196, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.370394706726074, Accuracy = 1.0\n",
      "Iter #280320:  Learning rate = 0.000092:  Batch Loss = 3.328213, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.334264039993286, Accuracy = 1.0\n",
      "Iter #280640:  Learning rate = 0.000092:  Batch Loss = 3.325310, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.360903263092041, Accuracy = 1.0\n",
      "Iter #280960:  Learning rate = 0.000092:  Batch Loss = 3.326260, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.334355592727661, Accuracy = 1.0\n",
      "Iter #281280:  Learning rate = 0.000092:  Batch Loss = 3.322525, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.3523948192596436, Accuracy = 0.9833333492279053\n",
      "Iter #281600:  Learning rate = 0.000092:  Batch Loss = 3.315489, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.330618381500244, Accuracy = 1.0\n",
      "Iter #281920:  Learning rate = 0.000092:  Batch Loss = 3.307313, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.3366315364837646, Accuracy = 1.0\n",
      "Iter #282240:  Learning rate = 0.000092:  Batch Loss = 3.342968, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.3212997913360596, Accuracy = 1.0\n",
      "Iter #282560:  Learning rate = 0.000092:  Batch Loss = 3.313034, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.3379220962524414, Accuracy = 1.0\n",
      "Iter #282880:  Learning rate = 0.000092:  Batch Loss = 3.299876, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.3049490451812744, Accuracy = 1.0\n",
      "Iter #283200:  Learning rate = 0.000092:  Batch Loss = 3.293004, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.317519426345825, Accuracy = 0.9833333492279053\n",
      "Iter #283520:  Learning rate = 0.000092:  Batch Loss = 3.289097, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.301830291748047, Accuracy = 1.0\n",
      "Iter #283840:  Learning rate = 0.000092:  Batch Loss = 3.285797, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.2982285022735596, Accuracy = 1.0\n",
      "Iter #284160:  Learning rate = 0.000092:  Batch Loss = 3.280632, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.295591354370117, Accuracy = 1.0\n",
      "Iter #284480:  Learning rate = 0.000092:  Batch Loss = 3.276348, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.282113552093506, Accuracy = 1.0\n",
      "Iter #284800:  Learning rate = 0.000092:  Batch Loss = 3.349731, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.335737943649292, Accuracy = 0.9666666388511658\n",
      "Iter #285120:  Learning rate = 0.000092:  Batch Loss = 3.269826, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.28165864944458, Accuracy = 1.0\n",
      "Iter #285440:  Learning rate = 0.000092:  Batch Loss = 3.264196, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.280236005783081, Accuracy = 1.0\n",
      "Iter #285760:  Learning rate = 0.000092:  Batch Loss = 3.261577, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.267357110977173, Accuracy = 1.0\n",
      "Iter #286080:  Learning rate = 0.000092:  Batch Loss = 3.255049, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.2645065784454346, Accuracy = 1.0\n",
      "Iter #286400:  Learning rate = 0.000092:  Batch Loss = 3.255253, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.2603089809417725, Accuracy = 1.0\n",
      "Iter #286720:  Learning rate = 0.000092:  Batch Loss = 3.246972, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.2627453804016113, Accuracy = 1.0\n",
      "Iter #287040:  Learning rate = 0.000092:  Batch Loss = 3.243003, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.250225305557251, Accuracy = 1.0\n",
      "Iter #287360:  Learning rate = 0.000092:  Batch Loss = 3.241887, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.2668299674987793, Accuracy = 1.0\n",
      "Iter #287680:  Learning rate = 0.000092:  Batch Loss = 3.239595, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.2409183979034424, Accuracy = 1.0\n",
      "Iter #288000:  Learning rate = 0.000092:  Batch Loss = 3.232328, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.2459604740142822, Accuracy = 1.0\n",
      "Iter #288320:  Learning rate = 0.000092:  Batch Loss = 3.227414, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.2321603298187256, Accuracy = 1.0\n",
      "Iter #288640:  Learning rate = 0.000092:  Batch Loss = 3.222168, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.225666046142578, Accuracy = 1.0\n",
      "Iter #288960:  Learning rate = 0.000092:  Batch Loss = 3.218485, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.2908647060394287, Accuracy = 0.949999988079071\n",
      "Iter #289280:  Learning rate = 0.000092:  Batch Loss = 3.215170, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.2228667736053467, Accuracy = 1.0\n",
      "Iter #289600:  Learning rate = 0.000092:  Batch Loss = 3.248379, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.2155306339263916, Accuracy = 1.0\n",
      "Iter #289920:  Learning rate = 0.000092:  Batch Loss = 3.208143, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.2106525897979736, Accuracy = 1.0\n",
      "Iter #290240:  Learning rate = 0.000092:  Batch Loss = 3.203920, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.23875093460083, Accuracy = 0.9666666388511658\n",
      "Iter #290560:  Learning rate = 0.000092:  Batch Loss = 3.197811, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.2550246715545654, Accuracy = 0.9666666388511658\n",
      "Iter #290880:  Learning rate = 0.000092:  Batch Loss = 3.195998, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.2009570598602295, Accuracy = 1.0\n",
      "Iter #291200:  Learning rate = 0.000092:  Batch Loss = 3.199528, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.259456157684326, Accuracy = 0.9666666388511658\n",
      "Iter #291520:  Learning rate = 0.000092:  Batch Loss = 3.188327, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.1958377361297607, Accuracy = 1.0\n",
      "Iter #291840:  Learning rate = 0.000092:  Batch Loss = 3.185452, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.2110395431518555, Accuracy = 0.9833333492279053\n",
      "Iter #292160:  Learning rate = 0.000092:  Batch Loss = 3.177509, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.1819868087768555, Accuracy = 1.0\n",
      "Iter #292480:  Learning rate = 0.000092:  Batch Loss = 3.178570, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.188413143157959, Accuracy = 1.0\n",
      "Iter #292800:  Learning rate = 0.000092:  Batch Loss = 3.422570, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.1732211112976074, Accuracy = 1.0\n",
      "Iter #293120:  Learning rate = 0.000092:  Batch Loss = 3.170941, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.188969373703003, Accuracy = 1.0\n",
      "Iter #293440:  Learning rate = 0.000092:  Batch Loss = 3.167681, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.201685667037964, Accuracy = 0.9666666388511658\n",
      "Iter #293760:  Learning rate = 0.000092:  Batch Loss = 3.172049, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.1749086380004883, Accuracy = 1.0\n",
      "Iter #294080:  Learning rate = 0.000092:  Batch Loss = 3.153701, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.1925694942474365, Accuracy = 0.9833333492279053\n",
      "Iter #294400:  Learning rate = 0.000092:  Batch Loss = 3.148837, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.164377450942993, Accuracy = 1.0\n",
      "Iter #294720:  Learning rate = 0.000092:  Batch Loss = 3.147539, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.154644727706909, Accuracy = 1.0\n",
      "Iter #295040:  Learning rate = 0.000092:  Batch Loss = 3.152668, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.178715229034424, Accuracy = 0.9833333492279053\n",
      "Iter #295360:  Learning rate = 0.000092:  Batch Loss = 3.137435, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.154076099395752, Accuracy = 1.0\n",
      "Iter #295680:  Learning rate = 0.000092:  Batch Loss = 3.133640, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.14208984375, Accuracy = 1.0\n",
      "Iter #296000:  Learning rate = 0.000092:  Batch Loss = 3.130563, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.143242359161377, Accuracy = 1.0\n",
      "Iter #296320:  Learning rate = 0.000092:  Batch Loss = 3.125947, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.160125732421875, Accuracy = 0.9833333492279053\n",
      "Iter #296640:  Learning rate = 0.000092:  Batch Loss = 3.120781, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.1284396648406982, Accuracy = 1.0\n",
      "Iter #296960:  Learning rate = 0.000092:  Batch Loss = 3.116526, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.135442018508911, Accuracy = 1.0\n",
      "Iter #297280:  Learning rate = 0.000092:  Batch Loss = 3.112388, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.122295379638672, Accuracy = 1.0\n",
      "Iter #297600:  Learning rate = 0.000092:  Batch Loss = 3.112125, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.11311936378479, Accuracy = 1.0\n",
      "Iter #297920:  Learning rate = 0.000092:  Batch Loss = 3.105586, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.1082863807678223, Accuracy = 1.0\n",
      "Iter #298240:  Learning rate = 0.000092:  Batch Loss = 3.104358, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.1857383251190186, Accuracy = 0.9666666388511658\n",
      "Iter #298560:  Learning rate = 0.000092:  Batch Loss = 3.096871, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.104599952697754, Accuracy = 1.0\n",
      "Iter #298880:  Learning rate = 0.000092:  Batch Loss = 3.095074, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.1127264499664307, Accuracy = 1.0\n",
      "Iter #299200:  Learning rate = 0.000092:  Batch Loss = 3.089124, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.1079487800598145, Accuracy = 1.0\n",
      "Iter #299520:  Learning rate = 0.000092:  Batch Loss = 3.085709, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.161574363708496, Accuracy = 0.949999988079071\n",
      "Iter #299840:  Learning rate = 0.000092:  Batch Loss = 3.084932, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.092954158782959, Accuracy = 1.0\n",
      "Iter #300160:  Learning rate = 0.000088:  Batch Loss = 3.077967, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.123979091644287, Accuracy = 0.9666666388511658\n",
      "Iter #300480:  Learning rate = 0.000088:  Batch Loss = 3.081615, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.0847809314727783, Accuracy = 1.0\n",
      "Iter #300800:  Learning rate = 0.000088:  Batch Loss = 3.070661, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.1332650184631348, Accuracy = 0.9666666388511658\n",
      "Iter #301120:  Learning rate = 0.000088:  Batch Loss = 3.067051, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.089154005050659, Accuracy = 0.9833333492279053\n",
      "Iter #301440:  Learning rate = 0.000088:  Batch Loss = 3.064220, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.083142042160034, Accuracy = 1.0\n",
      "Iter #301760:  Learning rate = 0.000088:  Batch Loss = 3.060632, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.080357551574707, Accuracy = 1.0\n",
      "Iter #302080:  Learning rate = 0.000088:  Batch Loss = 3.057018, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.106868267059326, Accuracy = 0.9666666388511658\n",
      "Iter #302400:  Learning rate = 0.000088:  Batch Loss = 3.051824, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.0611188411712646, Accuracy = 1.0\n",
      "Iter #302720:  Learning rate = 0.000088:  Batch Loss = 3.048757, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.0628368854522705, Accuracy = 1.0\n",
      "Iter #303040:  Learning rate = 0.000088:  Batch Loss = 3.047381, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.0603220462799072, Accuracy = 1.0\n",
      "Iter #303360:  Learning rate = 0.000088:  Batch Loss = 3.042402, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.0545198917388916, Accuracy = 1.0\n",
      "Iter #303680:  Learning rate = 0.000088:  Batch Loss = 3.050236, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.0590691566467285, Accuracy = 1.0\n",
      "Iter #304000:  Learning rate = 0.000088:  Batch Loss = 3.037549, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.044278383255005, Accuracy = 1.0\n",
      "Iter #304320:  Learning rate = 0.000088:  Batch Loss = 3.030699, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.05543851852417, Accuracy = 0.9833333492279053\n",
      "Iter #304640:  Learning rate = 0.000088:  Batch Loss = 3.029052, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.0513205528259277, Accuracy = 1.0\n",
      "Iter #304960:  Learning rate = 0.000088:  Batch Loss = 3.025673, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.0307579040527344, Accuracy = 1.0\n",
      "Iter #305280:  Learning rate = 0.000088:  Batch Loss = 3.021116, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.036939859390259, Accuracy = 1.0\n",
      "Iter #305600:  Learning rate = 0.000088:  Batch Loss = 3.017668, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.022911548614502, Accuracy = 1.0\n",
      "Iter #305920:  Learning rate = 0.000088:  Batch Loss = 3.093910, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.082583427429199, Accuracy = 0.9666666388511658\n",
      "Iter #306240:  Learning rate = 0.000088:  Batch Loss = 3.009490, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.0173089504241943, Accuracy = 1.0\n",
      "Iter #306560:  Learning rate = 0.000088:  Batch Loss = 3.010074, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.010389566421509, Accuracy = 1.0\n",
      "Iter #306880:  Learning rate = 0.000088:  Batch Loss = 3.002377, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.017709732055664, Accuracy = 1.0\n",
      "Iter #307200:  Learning rate = 0.000088:  Batch Loss = 3.247070, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.0013840198516846, Accuracy = 1.0\n",
      "Iter #307520:  Learning rate = 0.000088:  Batch Loss = 2.995374, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.0329477787017822, Accuracy = 1.0\n",
      "Iter #307840:  Learning rate = 0.000088:  Batch Loss = 2.992167, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.032561779022217, Accuracy = 0.9666666388511658\n",
      "Iter #308160:  Learning rate = 0.000088:  Batch Loss = 2.988351, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.9916133880615234, Accuracy = 1.0\n",
      "Iter #308480:  Learning rate = 0.000088:  Batch Loss = 2.985342, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.033649444580078, Accuracy = 0.9833333492279053\n",
      "Iter #308800:  Learning rate = 0.000088:  Batch Loss = 2.982576, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.0118939876556396, Accuracy = 1.0\n",
      "Iter #309120:  Learning rate = 0.000088:  Batch Loss = 2.986835, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.007230043411255, Accuracy = 0.9833333492279053\n",
      "Iter #309440:  Learning rate = 0.000088:  Batch Loss = 2.973247, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.9998085498809814, Accuracy = 0.9833333492279053\n",
      "Iter #309760:  Learning rate = 0.000088:  Batch Loss = 2.969285, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.997283697128296, Accuracy = 0.9833333492279053\n",
      "Iter #310080:  Learning rate = 0.000088:  Batch Loss = 3.001650, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.976475954055786, Accuracy = 1.0\n",
      "Iter #310400:  Learning rate = 0.000088:  Batch Loss = 2.962345, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.9715805053710938, Accuracy = 1.0\n",
      "Iter #310720:  Learning rate = 0.000088:  Batch Loss = 2.958779, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.0249760150909424, Accuracy = 0.9666666388511658\n",
      "Iter #311040:  Learning rate = 0.000088:  Batch Loss = 2.954497, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.963862180709839, Accuracy = 1.0\n",
      "Iter #311360:  Learning rate = 0.000088:  Batch Loss = 2.951640, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.9713006019592285, Accuracy = 1.0\n",
      "Iter #311680:  Learning rate = 0.000088:  Batch Loss = 2.948939, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.016035318374634, Accuracy = 0.9666666388511658\n",
      "Iter #312000:  Learning rate = 0.000088:  Batch Loss = 2.943181, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.956709623336792, Accuracy = 1.0\n",
      "Iter #312320:  Learning rate = 0.000088:  Batch Loss = 2.940053, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.9645063877105713, Accuracy = 1.0\n",
      "Iter #312640:  Learning rate = 0.000088:  Batch Loss = 2.936813, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.9525070190429688, Accuracy = 1.0\n",
      "Iter #312960:  Learning rate = 0.000088:  Batch Loss = 2.934221, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.9419515132904053, Accuracy = 1.0\n",
      "Iter #313280:  Learning rate = 0.000088:  Batch Loss = 2.930151, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.935939073562622, Accuracy = 1.0\n",
      "Iter #313600:  Learning rate = 0.000088:  Batch Loss = 2.938661, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.9420995712280273, Accuracy = 1.0\n",
      "Iter #313920:  Learning rate = 0.000088:  Batch Loss = 2.922328, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.9633162021636963, Accuracy = 0.9666666388511658\n",
      "Iter #314240:  Learning rate = 0.000088:  Batch Loss = 2.919704, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.931886672973633, Accuracy = 1.0\n",
      "Iter #314560:  Learning rate = 0.000088:  Batch Loss = 2.915159, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.9220681190490723, Accuracy = 1.0\n",
      "Iter #314880:  Learning rate = 0.000088:  Batch Loss = 2.914976, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.92060923576355, Accuracy = 1.0\n",
      "Iter #315200:  Learning rate = 0.000088:  Batch Loss = 2.907449, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.913071632385254, Accuracy = 1.0\n",
      "Iter #315520:  Learning rate = 0.000088:  Batch Loss = 2.919397, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.9211301803588867, Accuracy = 1.0\n",
      "Iter #315840:  Learning rate = 0.000088:  Batch Loss = 2.902069, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.9094204902648926, Accuracy = 1.0\n",
      "Iter #316160:  Learning rate = 0.000088:  Batch Loss = 2.896864, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.9279701709747314, Accuracy = 0.9833333492279053\n",
      "Iter #316480:  Learning rate = 0.000088:  Batch Loss = 2.892899, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.926020860671997, Accuracy = 1.0\n",
      "Iter #316800:  Learning rate = 0.000088:  Batch Loss = 2.890158, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.902059316635132, Accuracy = 1.0\n",
      "Iter #317120:  Learning rate = 0.000088:  Batch Loss = 2.895093, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.9189205169677734, Accuracy = 0.9833333492279053\n",
      "Iter #317440:  Learning rate = 0.000088:  Batch Loss = 2.884343, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.9201183319091797, Accuracy = 0.9666666388511658\n",
      "Iter #317760:  Learning rate = 0.000088:  Batch Loss = 2.878106, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.894275426864624, Accuracy = 1.0\n",
      "Iter #318080:  Learning rate = 0.000088:  Batch Loss = 2.875481, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.8985652923583984, Accuracy = 1.0\n",
      "Iter #318400:  Learning rate = 0.000088:  Batch Loss = 2.882289, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.887287139892578, Accuracy = 1.0\n",
      "Iter #318720:  Learning rate = 0.000088:  Batch Loss = 2.868130, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.8739306926727295, Accuracy = 1.0\n",
      "Iter #319040:  Learning rate = 0.000088:  Batch Loss = 2.864978, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.1070809364318848, Accuracy = 0.8833333253860474\n",
      "Iter #319360:  Learning rate = 0.000088:  Batch Loss = 2.860944, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.8671717643737793, Accuracy = 1.0\n",
      "Iter #319680:  Learning rate = 0.000088:  Batch Loss = 2.856643, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.8601362705230713, Accuracy = 1.0\n",
      "Iter #320000:  Learning rate = 0.000088:  Batch Loss = 2.857168, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.865717887878418, Accuracy = 1.0\n",
      "Iter #320320:  Learning rate = 0.000088:  Batch Loss = 2.850232, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.8689072132110596, Accuracy = 1.0\n",
      "Iter #320640:  Learning rate = 0.000088:  Batch Loss = 2.849517, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.904616117477417, Accuracy = 0.9666666388511658\n",
      "Iter #320960:  Learning rate = 0.000088:  Batch Loss = 2.903425, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.862506628036499, Accuracy = 1.0\n",
      "Iter #321280:  Learning rate = 0.000088:  Batch Loss = 2.839767, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.845151662826538, Accuracy = 1.0\n",
      "Iter #321600:  Learning rate = 0.000088:  Batch Loss = 2.871436, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.8592369556427, Accuracy = 1.0\n",
      "Iter #321920:  Learning rate = 0.000088:  Batch Loss = 2.834394, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.8449513912200928, Accuracy = 1.0\n",
      "Iter #322240:  Learning rate = 0.000088:  Batch Loss = 2.832850, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.8374736309051514, Accuracy = 1.0\n",
      "Iter #322560:  Learning rate = 0.000088:  Batch Loss = 2.829291, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.8776795864105225, Accuracy = 0.9666666388511658\n",
      "Iter #322880:  Learning rate = 0.000088:  Batch Loss = 2.823262, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.827970027923584, Accuracy = 1.0\n",
      "Iter #323200:  Learning rate = 0.000088:  Batch Loss = 2.824913, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.896399974822998, Accuracy = 0.9666666388511658\n",
      "Iter #323520:  Learning rate = 0.000088:  Batch Loss = 2.818292, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.8236169815063477, Accuracy = 1.0\n",
      "Iter #323840:  Learning rate = 0.000088:  Batch Loss = 2.812981, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.876906633377075, Accuracy = 0.9666666388511658\n",
      "Iter #324160:  Learning rate = 0.000088:  Batch Loss = 2.810161, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.8237788677215576, Accuracy = 1.0\n",
      "Iter #324480:  Learning rate = 0.000088:  Batch Loss = 2.806233, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.8738768100738525, Accuracy = 0.9666666388511658\n",
      "Iter #324800:  Learning rate = 0.000088:  Batch Loss = 2.807834, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.8162355422973633, Accuracy = 1.0\n",
      "Iter #325120:  Learning rate = 0.000088:  Batch Loss = 2.801057, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.81392502784729, Accuracy = 1.0\n",
      "Iter #325440:  Learning rate = 0.000088:  Batch Loss = 2.795171, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.807631731033325, Accuracy = 1.0\n",
      "Iter #325760:  Learning rate = 0.000088:  Batch Loss = 2.791486, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.838837146759033, Accuracy = 0.9833333492279053\n",
      "Iter #326080:  Learning rate = 0.000088:  Batch Loss = 2.787899, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.8091747760772705, Accuracy = 1.0\n",
      "Iter #326400:  Learning rate = 0.000088:  Batch Loss = 2.786946, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.7947497367858887, Accuracy = 1.0\n",
      "Iter #326720:  Learning rate = 0.000088:  Batch Loss = 2.780694, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.8269121646881104, Accuracy = 0.9666666388511658\n",
      "Iter #327040:  Learning rate = 0.000088:  Batch Loss = 2.778329, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.790397882461548, Accuracy = 1.0\n",
      "Iter #327360:  Learning rate = 0.000088:  Batch Loss = 2.773611, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.78296160697937, Accuracy = 1.0\n",
      "Iter #327680:  Learning rate = 0.000088:  Batch Loss = 2.773990, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.803018569946289, Accuracy = 1.0\n",
      "Iter #328000:  Learning rate = 0.000088:  Batch Loss = 2.768473, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.7748842239379883, Accuracy = 1.0\n",
      "Iter #328320:  Learning rate = 0.000088:  Batch Loss = 2.763816, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.766782283782959, Accuracy = 1.0\n",
      "Iter #328640:  Learning rate = 0.000088:  Batch Loss = 2.887164, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.033111095428467, Accuracy = 0.8500000238418579\n",
      "Iter #328960:  Learning rate = 0.000088:  Batch Loss = 2.760422, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.7843074798583984, Accuracy = 0.9833333492279053\n",
      "Iter #329280:  Learning rate = 0.000088:  Batch Loss = 2.757084, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.8361010551452637, Accuracy = 0.949999988079071\n",
      "Iter #329600:  Learning rate = 0.000088:  Batch Loss = 2.822497, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.77801513671875, Accuracy = 1.0\n",
      "Iter #329920:  Learning rate = 0.000088:  Batch Loss = 2.773596, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.788161516189575, Accuracy = 0.9666666388511658\n",
      "Iter #330240:  Learning rate = 0.000088:  Batch Loss = 2.749648, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.7643492221832275, Accuracy = 1.0\n",
      "Iter #330560:  Learning rate = 0.000088:  Batch Loss = 2.745897, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.766735315322876, Accuracy = 1.0\n",
      "Iter #330880:  Learning rate = 0.000088:  Batch Loss = 2.743150, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.7597601413726807, Accuracy = 1.0\n",
      "Iter #331200:  Learning rate = 0.000088:  Batch Loss = 2.745345, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.7466623783111572, Accuracy = 1.0\n",
      "Iter #331520:  Learning rate = 0.000088:  Batch Loss = 2.739620, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.7597780227661133, Accuracy = 1.0\n",
      "Iter #331840:  Learning rate = 0.000088:  Batch Loss = 2.735342, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.7614269256591797, Accuracy = 0.9833333492279053\n",
      "Iter #332160:  Learning rate = 0.000088:  Batch Loss = 2.734642, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.7501628398895264, Accuracy = 1.0\n",
      "Iter #332480:  Learning rate = 0.000088:  Batch Loss = 2.730463, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.748317241668701, Accuracy = 1.0\n",
      "Iter #332800:  Learning rate = 0.000088:  Batch Loss = 2.727840, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.74202823638916, Accuracy = 1.0\n",
      "Iter #333120:  Learning rate = 0.000088:  Batch Loss = 2.725647, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.7386696338653564, Accuracy = 1.0\n",
      "Iter #333440:  Learning rate = 0.000088:  Batch Loss = 2.722778, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.730041265487671, Accuracy = 1.0\n",
      "Iter #333760:  Learning rate = 0.000088:  Batch Loss = 2.720557, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.7378060817718506, Accuracy = 1.0\n",
      "Iter #334080:  Learning rate = 0.000088:  Batch Loss = 2.717682, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.7388534545898438, Accuracy = 1.0\n",
      "Iter #334400:  Learning rate = 0.000088:  Batch Loss = 2.717861, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.7364869117736816, Accuracy = 1.0\n",
      "Iter #334720:  Learning rate = 0.000088:  Batch Loss = 2.745691, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.7226693630218506, Accuracy = 1.0\n",
      "Iter #335040:  Learning rate = 0.000088:  Batch Loss = 2.776309, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.723395586013794, Accuracy = 1.0\n",
      "Iter #335360:  Learning rate = 0.000088:  Batch Loss = 2.707422, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.714171886444092, Accuracy = 1.0\n",
      "Iter #335680:  Learning rate = 0.000088:  Batch Loss = 2.705255, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.7505693435668945, Accuracy = 0.9666666388511658\n",
      "Iter #336000:  Learning rate = 0.000088:  Batch Loss = 2.706278, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.71120548248291, Accuracy = 1.0\n",
      "Iter #336320:  Learning rate = 0.000088:  Batch Loss = 2.701210, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.7099292278289795, Accuracy = 1.0\n",
      "Iter #336640:  Learning rate = 0.000088:  Batch Loss = 2.699871, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.73058819770813, Accuracy = 0.9833333492279053\n",
      "Iter #336960:  Learning rate = 0.000088:  Batch Loss = 2.695154, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.7333006858825684, Accuracy = 0.9833333492279053\n",
      "Iter #337280:  Learning rate = 0.000088:  Batch Loss = 2.692731, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.699929714202881, Accuracy = 1.0\n",
      "Iter #337600:  Learning rate = 0.000088:  Batch Loss = 2.690222, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.709541082382202, Accuracy = 1.0\n",
      "Iter #337920:  Learning rate = 0.000088:  Batch Loss = 2.688529, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.6967580318450928, Accuracy = 1.0\n",
      "Iter #338240:  Learning rate = 0.000088:  Batch Loss = 2.778911, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.6945600509643555, Accuracy = 1.0\n",
      "Iter #338560:  Learning rate = 0.000088:  Batch Loss = 2.802593, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.705535888671875, Accuracy = 0.9833333492279053\n",
      "Iter #338880:  Learning rate = 0.000088:  Batch Loss = 2.680401, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.6841185092926025, Accuracy = 1.0\n",
      "Iter #339200:  Learning rate = 0.000088:  Batch Loss = 2.676358, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.6798343658447266, Accuracy = 1.0\n",
      "Iter #339520:  Learning rate = 0.000088:  Batch Loss = 2.676617, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.6777760982513428, Accuracy = 1.0\n",
      "Iter #339840:  Learning rate = 0.000088:  Batch Loss = 2.672446, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.6764228343963623, Accuracy = 1.0\n",
      "Iter #340160:  Learning rate = 0.000088:  Batch Loss = 2.670105, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.678349018096924, Accuracy = 1.0\n",
      "Iter #340480:  Learning rate = 0.000088:  Batch Loss = 2.668724, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.6745412349700928, Accuracy = 1.0\n",
      "Iter #340800:  Learning rate = 0.000088:  Batch Loss = 2.666197, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.676875591278076, Accuracy = 1.0\n",
      "Iter #341120:  Learning rate = 0.000088:  Batch Loss = 2.664326, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.702455759048462, Accuracy = 1.0\n",
      "Iter #341440:  Learning rate = 0.000088:  Batch Loss = 2.660062, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.683213710784912, Accuracy = 1.0\n",
      "Iter #341760:  Learning rate = 0.000088:  Batch Loss = 2.661300, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.722395181655884, Accuracy = 0.9666666388511658\n",
      "Iter #342080:  Learning rate = 0.000088:  Batch Loss = 2.696280, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.6798698902130127, Accuracy = 1.0\n",
      "Iter #342400:  Learning rate = 0.000088:  Batch Loss = 2.652449, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.6905629634857178, Accuracy = 0.9833333492279053\n",
      "Iter #342720:  Learning rate = 0.000088:  Batch Loss = 2.652811, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.6882455348968506, Accuracy = 1.0\n",
      "Iter #343040:  Learning rate = 0.000088:  Batch Loss = 2.652659, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.6650497913360596, Accuracy = 1.0\n",
      "Iter #343360:  Learning rate = 0.000088:  Batch Loss = 2.644642, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.684481620788574, Accuracy = 0.9666666388511658\n",
      "Iter #343680:  Learning rate = 0.000088:  Batch Loss = 2.641550, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.671053886413574, Accuracy = 0.9833333492279053\n",
      "Iter #344000:  Learning rate = 0.000088:  Batch Loss = 2.640699, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.6566848754882812, Accuracy = 1.0\n",
      "Iter #344320:  Learning rate = 0.000088:  Batch Loss = 2.640910, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.664633274078369, Accuracy = 0.9833333492279053\n",
      "Iter #344640:  Learning rate = 0.000088:  Batch Loss = 2.634942, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.6476051807403564, Accuracy = 1.0\n",
      "Iter #344960:  Learning rate = 0.000088:  Batch Loss = 2.632584, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.654322862625122, Accuracy = 1.0\n",
      "Iter #345280:  Learning rate = 0.000088:  Batch Loss = 2.629639, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.6588025093078613, Accuracy = 1.0\n",
      "Iter #345600:  Learning rate = 0.000088:  Batch Loss = 2.627702, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.6384496688842773, Accuracy = 1.0\n",
      "Iter #345920:  Learning rate = 0.000088:  Batch Loss = 2.624215, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.648607015609741, Accuracy = 1.0\n",
      "Iter #346240:  Learning rate = 0.000088:  Batch Loss = 2.623677, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.6311960220336914, Accuracy = 1.0\n",
      "Iter #346560:  Learning rate = 0.000088:  Batch Loss = 2.620882, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.6505095958709717, Accuracy = 0.9833333492279053\n",
      "Iter #346880:  Learning rate = 0.000088:  Batch Loss = 2.619230, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.6421875953674316, Accuracy = 0.9833333492279053\n",
      "Iter #347200:  Learning rate = 0.000088:  Batch Loss = 2.613927, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.632305860519409, Accuracy = 1.0\n",
      "Iter #347520:  Learning rate = 0.000088:  Batch Loss = 2.611655, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.665653705596924, Accuracy = 0.9666666388511658\n",
      "Iter #347840:  Learning rate = 0.000088:  Batch Loss = 2.611397, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.6290595531463623, Accuracy = 1.0\n",
      "Iter #348160:  Learning rate = 0.000088:  Batch Loss = 2.615874, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.6378607749938965, Accuracy = 0.9833333492279053\n",
      "Iter #348480:  Learning rate = 0.000088:  Batch Loss = 2.603460, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.6276943683624268, Accuracy = 1.0\n",
      "Iter #348800:  Learning rate = 0.000088:  Batch Loss = 2.601189, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.619596004486084, Accuracy = 1.0\n",
      "Iter #349120:  Learning rate = 0.000088:  Batch Loss = 2.601136, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.60605525970459, Accuracy = 1.0\n",
      "Iter #349440:  Learning rate = 0.000088:  Batch Loss = 2.597416, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.836914300918579, Accuracy = 0.8666666746139526\n",
      "Iter #349760:  Learning rate = 0.000088:  Batch Loss = 2.594260, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.5985922813415527, Accuracy = 1.0\n",
      "Iter #350080:  Learning rate = 0.000088:  Batch Loss = 2.596708, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.5944631099700928, Accuracy = 1.0\n",
      "Iter #350400:  Learning rate = 0.000088:  Batch Loss = 2.589965, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.59692645072937, Accuracy = 1.0\n",
      "Iter #350720:  Learning rate = 0.000088:  Batch Loss = 2.585955, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.6084494590759277, Accuracy = 1.0\n",
      "Iter #351040:  Learning rate = 0.000088:  Batch Loss = 2.583692, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.620117664337158, Accuracy = 1.0\n",
      "Iter #351360:  Learning rate = 0.000088:  Batch Loss = 2.583959, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.607189655303955, Accuracy = 1.0\n",
      "Iter #351680:  Learning rate = 0.000088:  Batch Loss = 2.579156, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.608821153640747, Accuracy = 1.0\n",
      "Iter #352000:  Learning rate = 0.000088:  Batch Loss = 2.578294, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.6111741065979004, Accuracy = 0.9833333492279053\n",
      "Iter #352320:  Learning rate = 0.000088:  Batch Loss = 2.574286, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.595113515853882, Accuracy = 1.0\n",
      "Iter #352640:  Learning rate = 0.000088:  Batch Loss = 2.575256, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.5804574489593506, Accuracy = 1.0\n",
      "Iter #352960:  Learning rate = 0.000088:  Batch Loss = 2.569566, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.610060453414917, Accuracy = 0.9833333492279053\n",
      "Iter #353280:  Learning rate = 0.000088:  Batch Loss = 2.573794, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.5899221897125244, Accuracy = 1.0\n",
      "Iter #353600:  Learning rate = 0.000088:  Batch Loss = 2.563570, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.584282159805298, Accuracy = 1.0\n",
      "Iter #353920:  Learning rate = 0.000088:  Batch Loss = 2.580476, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.5969746112823486, Accuracy = 0.9833333492279053\n",
      "Iter #354240:  Learning rate = 0.000088:  Batch Loss = 2.557832, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.5695884227752686, Accuracy = 1.0\n",
      "Iter #354560:  Learning rate = 0.000088:  Batch Loss = 2.569764, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.5936272144317627, Accuracy = 0.9833333492279053\n",
      "Iter #354880:  Learning rate = 0.000088:  Batch Loss = 2.555511, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.560028076171875, Accuracy = 1.0\n",
      "Iter #355200:  Learning rate = 0.000088:  Batch Loss = 2.550663, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.6145825386047363, Accuracy = 0.949999988079071\n",
      "Iter #355520:  Learning rate = 0.000088:  Batch Loss = 2.548031, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.5712954998016357, Accuracy = 1.0\n",
      "Iter #355840:  Learning rate = 0.000088:  Batch Loss = 2.545865, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.5673325061798096, Accuracy = 1.0\n",
      "Iter #356160:  Learning rate = 0.000088:  Batch Loss = 2.543322, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.5582239627838135, Accuracy = 1.0\n",
      "Iter #356480:  Learning rate = 0.000088:  Batch Loss = 2.542190, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.5473008155822754, Accuracy = 1.0\n",
      "Iter #356800:  Learning rate = 0.000088:  Batch Loss = 2.538201, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.5480101108551025, Accuracy = 1.0\n",
      "Iter #357120:  Learning rate = 0.000088:  Batch Loss = 2.535779, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.552377223968506, Accuracy = 1.0\n",
      "Iter #357440:  Learning rate = 0.000088:  Batch Loss = 2.531500, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.543532609939575, Accuracy = 1.0\n",
      "Iter #357760:  Learning rate = 0.000088:  Batch Loss = 2.531111, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.5412192344665527, Accuracy = 1.0\n",
      "Iter #358080:  Learning rate = 0.000088:  Batch Loss = 2.527013, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.5815365314483643, Accuracy = 0.9666666388511658\n",
      "Iter #358400:  Learning rate = 0.000088:  Batch Loss = 2.525323, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.53082537651062, Accuracy = 1.0\n",
      "Iter #358720:  Learning rate = 0.000088:  Batch Loss = 2.527946, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.5924789905548096, Accuracy = 0.9666666388511658\n",
      "Iter #359040:  Learning rate = 0.000088:  Batch Loss = 2.520450, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.52616286277771, Accuracy = 1.0\n",
      "Iter #359360:  Learning rate = 0.000088:  Batch Loss = 2.528232, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.547545909881592, Accuracy = 1.0\n",
      "Iter #359680:  Learning rate = 0.000088:  Batch Loss = 2.514634, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.5399866104125977, Accuracy = 0.9833333492279053\n",
      "Iter #360000:  Learning rate = 0.000088:  Batch Loss = 2.511411, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.5213418006896973, Accuracy = 1.0\n",
      "Iter #360320:  Learning rate = 0.000088:  Batch Loss = 2.514922, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.517859935760498, Accuracy = 1.0\n",
      "Iter #360640:  Learning rate = 0.000088:  Batch Loss = 2.543136, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.575460910797119, Accuracy = 0.9666666388511658\n",
      "Iter #360960:  Learning rate = 0.000088:  Batch Loss = 2.505640, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.52054500579834, Accuracy = 1.0\n",
      "Iter #361280:  Learning rate = 0.000088:  Batch Loss = 2.501466, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.5243659019470215, Accuracy = 1.0\n",
      "Iter #361600:  Learning rate = 0.000088:  Batch Loss = 2.498369, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.5351786613464355, Accuracy = 0.9833333492279053\n",
      "Iter #361920:  Learning rate = 0.000088:  Batch Loss = 2.495546, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.5315494537353516, Accuracy = 0.9833333492279053\n",
      "Iter #362240:  Learning rate = 0.000088:  Batch Loss = 2.494178, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.514078378677368, Accuracy = 1.0\n",
      "Iter #362560:  Learning rate = 0.000088:  Batch Loss = 2.491282, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.5054917335510254, Accuracy = 1.0\n",
      "Iter #362880:  Learning rate = 0.000088:  Batch Loss = 2.487595, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.4985594749450684, Accuracy = 1.0\n",
      "Iter #363200:  Learning rate = 0.000088:  Batch Loss = 2.485250, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.6657252311706543, Accuracy = 0.8833333253860474\n",
      "Iter #363520:  Learning rate = 0.000088:  Batch Loss = 2.483229, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.4882991313934326, Accuracy = 1.0\n",
      "Iter #363840:  Learning rate = 0.000088:  Batch Loss = 2.480531, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.5567574501037598, Accuracy = 0.9333333373069763\n",
      "Iter #364160:  Learning rate = 0.000088:  Batch Loss = 2.477958, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.506979465484619, Accuracy = 0.9833333492279053\n",
      "Iter #364480:  Learning rate = 0.000088:  Batch Loss = 2.514138, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.508246660232544, Accuracy = 1.0\n",
      "Iter #364800:  Learning rate = 0.000088:  Batch Loss = 2.476809, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.5105254650115967, Accuracy = 0.9666666388511658\n",
      "Iter #365120:  Learning rate = 0.000088:  Batch Loss = 2.472811, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.4886958599090576, Accuracy = 1.0\n",
      "Iter #365440:  Learning rate = 0.000088:  Batch Loss = 2.473531, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.488037109375, Accuracy = 1.0\n",
      "Iter #365760:  Learning rate = 0.000088:  Batch Loss = 2.487058, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.4879040718078613, Accuracy = 1.0\n",
      "Iter #366080:  Learning rate = 0.000088:  Batch Loss = 2.463715, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.4730656147003174, Accuracy = 1.0\n",
      "Iter #366400:  Learning rate = 0.000088:  Batch Loss = 2.459907, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.46478009223938, Accuracy = 1.0\n",
      "Iter #366720:  Learning rate = 0.000088:  Batch Loss = 2.465434, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.4704437255859375, Accuracy = 1.0\n",
      "Iter #367040:  Learning rate = 0.000088:  Batch Loss = 2.453990, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.458327531814575, Accuracy = 1.0\n",
      "Iter #367360:  Learning rate = 0.000088:  Batch Loss = 2.452129, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.481642007827759, Accuracy = 1.0\n",
      "Iter #367680:  Learning rate = 0.000088:  Batch Loss = 2.450366, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.4837021827697754, Accuracy = 0.9833333492279053\n",
      "Iter #368000:  Learning rate = 0.000088:  Batch Loss = 2.458895, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.4726290702819824, Accuracy = 1.0\n",
      "Iter #368320:  Learning rate = 0.000088:  Batch Loss = 2.443934, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.4899518489837646, Accuracy = 0.9666666388511658\n",
      "Iter #368640:  Learning rate = 0.000088:  Batch Loss = 2.441458, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.465902805328369, Accuracy = 1.0\n",
      "Iter #368960:  Learning rate = 0.000088:  Batch Loss = 2.439080, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.4647340774536133, Accuracy = 0.9833333492279053\n",
      "Iter #369280:  Learning rate = 0.000088:  Batch Loss = 2.436680, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.4563865661621094, Accuracy = 1.0\n",
      "Iter #369600:  Learning rate = 0.000088:  Batch Loss = 2.440173, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.4464776515960693, Accuracy = 1.0\n",
      "Iter #369920:  Learning rate = 0.000088:  Batch Loss = 2.431088, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.4827215671539307, Accuracy = 0.9666666388511658\n",
      "Iter #370240:  Learning rate = 0.000088:  Batch Loss = 2.431976, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.4360973834991455, Accuracy = 1.0\n",
      "Iter #370560:  Learning rate = 0.000088:  Batch Loss = 2.426074, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.443134069442749, Accuracy = 1.0\n",
      "Iter #370880:  Learning rate = 0.000088:  Batch Loss = 2.489518, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.5167338848114014, Accuracy = 0.949999988079071\n",
      "Iter #371200:  Learning rate = 0.000088:  Batch Loss = 2.420800, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.427539348602295, Accuracy = 1.0\n",
      "Iter #371520:  Learning rate = 0.000088:  Batch Loss = 2.492184, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.428642511367798, Accuracy = 1.0\n",
      "Iter #371840:  Learning rate = 0.000088:  Batch Loss = 2.449867, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.4625725746154785, Accuracy = 0.9666666388511658\n",
      "Iter #372160:  Learning rate = 0.000088:  Batch Loss = 2.549448, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.426525354385376, Accuracy = 1.0\n",
      "Iter #372480:  Learning rate = 0.000088:  Batch Loss = 2.453696, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.419929027557373, Accuracy = 1.0\n",
      "Iter #372800:  Learning rate = 0.000088:  Batch Loss = 2.410229, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.443023204803467, Accuracy = 0.9833333492279053\n",
      "Iter #373120:  Learning rate = 0.000088:  Batch Loss = 2.406508, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.4381320476531982, Accuracy = 0.9833333492279053\n",
      "Iter #373440:  Learning rate = 0.000088:  Batch Loss = 2.405077, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.427321672439575, Accuracy = 1.0\n",
      "Iter #373760:  Learning rate = 0.000088:  Batch Loss = 2.403563, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.422987937927246, Accuracy = 1.0\n",
      "Iter #374080:  Learning rate = 0.000088:  Batch Loss = 2.399075, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.4075701236724854, Accuracy = 1.0\n",
      "Iter #374400:  Learning rate = 0.000088:  Batch Loss = 2.395458, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.4305291175842285, Accuracy = 0.9833333492279053\n",
      "Iter #374720:  Learning rate = 0.000088:  Batch Loss = 2.392458, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.4146339893341064, Accuracy = 1.0\n",
      "Iter #375040:  Learning rate = 0.000088:  Batch Loss = 2.422634, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.4077117443084717, Accuracy = 1.0\n",
      "Iter #375360:  Learning rate = 0.000088:  Batch Loss = 2.388804, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.397113561630249, Accuracy = 1.0\n",
      "Iter #375680:  Learning rate = 0.000088:  Batch Loss = 2.383851, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.399369716644287, Accuracy = 1.0\n",
      "Iter #376000:  Learning rate = 0.000088:  Batch Loss = 2.405067, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.4174060821533203, Accuracy = 0.9833333492279053\n",
      "Iter #376320:  Learning rate = 0.000088:  Batch Loss = 2.379884, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.4095993041992188, Accuracy = 0.9833333492279053\n",
      "Iter #376640:  Learning rate = 0.000088:  Batch Loss = 2.376918, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.445457696914673, Accuracy = 0.9666666388511658\n",
      "Iter #376960:  Learning rate = 0.000088:  Batch Loss = 2.873744, Accuracy = 0.875\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 3.170670986175537, Accuracy = 0.7666666507720947\n",
      "Iter #377280:  Learning rate = 0.000088:  Batch Loss = 2.376107, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3888537883758545, Accuracy = 1.0\n",
      "Iter #377600:  Learning rate = 0.000088:  Batch Loss = 2.373321, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.395580530166626, Accuracy = 1.0\n",
      "Iter #377920:  Learning rate = 0.000088:  Batch Loss = 2.370654, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.4500954151153564, Accuracy = 0.949999988079071\n",
      "Iter #378240:  Learning rate = 0.000088:  Batch Loss = 2.371997, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.4275474548339844, Accuracy = 0.9666666388511658\n",
      "Iter #378560:  Learning rate = 0.000088:  Batch Loss = 2.369875, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3856658935546875, Accuracy = 1.0\n",
      "Iter #378880:  Learning rate = 0.000088:  Batch Loss = 2.394177, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3870441913604736, Accuracy = 1.0\n",
      "Iter #379200:  Learning rate = 0.000088:  Batch Loss = 2.364115, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3781049251556396, Accuracy = 1.0\n",
      "Iter #379520:  Learning rate = 0.000088:  Batch Loss = 2.362254, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.378345251083374, Accuracy = 1.0\n",
      "Iter #379840:  Learning rate = 0.000088:  Batch Loss = 2.362134, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3882968425750732, Accuracy = 1.0\n",
      "Iter #380160:  Learning rate = 0.000088:  Batch Loss = 2.358902, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.370851516723633, Accuracy = 1.0\n",
      "Iter #380480:  Learning rate = 0.000088:  Batch Loss = 2.356989, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3671724796295166, Accuracy = 1.0\n",
      "Iter #380800:  Learning rate = 0.000088:  Batch Loss = 2.359286, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.4950084686279297, Accuracy = 0.9333333373069763\n",
      "Iter #381120:  Learning rate = 0.000088:  Batch Loss = 2.354131, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.358489513397217, Accuracy = 1.0\n",
      "Iter #381440:  Learning rate = 0.000088:  Batch Loss = 2.351883, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3546900749206543, Accuracy = 1.0\n",
      "Iter #381760:  Learning rate = 0.000088:  Batch Loss = 2.350635, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3600547313690186, Accuracy = 1.0\n",
      "Iter #382080:  Learning rate = 0.000088:  Batch Loss = 2.387362, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3596436977386475, Accuracy = 1.0\n",
      "Iter #382400:  Learning rate = 0.000088:  Batch Loss = 2.347121, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.381819486618042, Accuracy = 0.9666666388511658\n",
      "Iter #382720:  Learning rate = 0.000088:  Batch Loss = 2.382585, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3697848320007324, Accuracy = 1.0\n",
      "Iter #383040:  Learning rate = 0.000088:  Batch Loss = 2.352670, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3777308464050293, Accuracy = 1.0\n",
      "Iter #383360:  Learning rate = 0.000088:  Batch Loss = 2.341963, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3594231605529785, Accuracy = 1.0\n",
      "Iter #383680:  Learning rate = 0.000088:  Batch Loss = 2.341776, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.348878860473633, Accuracy = 1.0\n",
      "Iter #384000:  Learning rate = 0.000088:  Batch Loss = 2.340511, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.363739490509033, Accuracy = 1.0\n",
      "Iter #384320:  Learning rate = 0.000088:  Batch Loss = 2.337142, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.354724645614624, Accuracy = 1.0\n",
      "Iter #384640:  Learning rate = 0.000088:  Batch Loss = 2.336217, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.360285997390747, Accuracy = 0.9833333492279053\n",
      "Iter #384960:  Learning rate = 0.000088:  Batch Loss = 2.334937, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.36154842376709, Accuracy = 0.9833333492279053\n",
      "Iter #385280:  Learning rate = 0.000088:  Batch Loss = 2.331910, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.34018874168396, Accuracy = 1.0\n",
      "Iter #385600:  Learning rate = 0.000088:  Batch Loss = 2.330560, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3447484970092773, Accuracy = 1.0\n",
      "Iter #385920:  Learning rate = 0.000088:  Batch Loss = 2.330200, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.337174892425537, Accuracy = 1.0\n",
      "Iter #386240:  Learning rate = 0.000088:  Batch Loss = 2.329197, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.347439765930176, Accuracy = 1.0\n",
      "Iter #386560:  Learning rate = 0.000088:  Batch Loss = 2.325110, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3350720405578613, Accuracy = 1.0\n",
      "Iter #386880:  Learning rate = 0.000088:  Batch Loss = 2.322717, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3288793563842773, Accuracy = 1.0\n",
      "Iter #387200:  Learning rate = 0.000088:  Batch Loss = 2.330124, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3437793254852295, Accuracy = 1.0\n",
      "Iter #387520:  Learning rate = 0.000088:  Batch Loss = 2.321540, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3314387798309326, Accuracy = 1.0\n",
      "Iter #387840:  Learning rate = 0.000088:  Batch Loss = 2.319674, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3228249549865723, Accuracy = 1.0\n",
      "Iter #388160:  Learning rate = 0.000088:  Batch Loss = 2.316167, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3296425342559814, Accuracy = 1.0\n",
      "Iter #388480:  Learning rate = 0.000088:  Batch Loss = 2.314502, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.331439733505249, Accuracy = 1.0\n",
      "Iter #388800:  Learning rate = 0.000088:  Batch Loss = 2.313707, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3140578269958496, Accuracy = 1.0\n",
      "Iter #389120:  Learning rate = 0.000088:  Batch Loss = 2.312958, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3130199909210205, Accuracy = 1.0\n",
      "Iter #389440:  Learning rate = 0.000088:  Batch Loss = 2.314066, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3180010318756104, Accuracy = 1.0\n",
      "Iter #389760:  Learning rate = 0.000088:  Batch Loss = 2.307452, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3118960857391357, Accuracy = 1.0\n",
      "Iter #390080:  Learning rate = 0.000088:  Batch Loss = 2.309083, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3239943981170654, Accuracy = 1.0\n",
      "Iter #390400:  Learning rate = 0.000088:  Batch Loss = 2.317081, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3984780311584473, Accuracy = 0.949999988079071\n",
      "Iter #390720:  Learning rate = 0.000088:  Batch Loss = 2.303811, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3179802894592285, Accuracy = 1.0\n",
      "Iter #391040:  Learning rate = 0.000088:  Batch Loss = 2.302858, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3183648586273193, Accuracy = 1.0\n",
      "Iter #391360:  Learning rate = 0.000088:  Batch Loss = 2.308432, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3225581645965576, Accuracy = 1.0\n",
      "Iter #391680:  Learning rate = 0.000088:  Batch Loss = 2.297442, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.314685583114624, Accuracy = 1.0\n",
      "Iter #392000:  Learning rate = 0.000088:  Batch Loss = 2.295211, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3032686710357666, Accuracy = 1.0\n",
      "Iter #392320:  Learning rate = 0.000088:  Batch Loss = 2.294278, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.4084715843200684, Accuracy = 0.949999988079071\n",
      "Iter #392640:  Learning rate = 0.000088:  Batch Loss = 2.292786, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3134076595306396, Accuracy = 1.0\n",
      "Iter #392960:  Learning rate = 0.000088:  Batch Loss = 2.295262, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3528354167938232, Accuracy = 0.9833333492279053\n",
      "Iter #393280:  Learning rate = 0.000088:  Batch Loss = 2.290242, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.292634963989258, Accuracy = 1.0\n",
      "Iter #393600:  Learning rate = 0.000088:  Batch Loss = 2.287664, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2904200553894043, Accuracy = 1.0\n",
      "Iter #393920:  Learning rate = 0.000088:  Batch Loss = 2.286579, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.293626546859741, Accuracy = 1.0\n",
      "Iter #394240:  Learning rate = 0.000088:  Batch Loss = 2.284993, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2923874855041504, Accuracy = 1.0\n",
      "Iter #394560:  Learning rate = 0.000088:  Batch Loss = 2.282296, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2918126583099365, Accuracy = 1.0\n",
      "Iter #394880:  Learning rate = 0.000088:  Batch Loss = 2.280479, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.347444772720337, Accuracy = 0.9666666388511658\n",
      "Iter #395200:  Learning rate = 0.000088:  Batch Loss = 2.279608, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.298152446746826, Accuracy = 1.0\n",
      "Iter #395520:  Learning rate = 0.000088:  Batch Loss = 2.299339, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.30680251121521, Accuracy = 1.0\n",
      "Iter #395840:  Learning rate = 0.000088:  Batch Loss = 2.276008, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2792763710021973, Accuracy = 1.0\n",
      "Iter #396160:  Learning rate = 0.000088:  Batch Loss = 2.277017, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2978768348693848, Accuracy = 1.0\n",
      "Iter #396480:  Learning rate = 0.000088:  Batch Loss = 2.292347, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.329953670501709, Accuracy = 0.9666666388511658\n",
      "Iter #396800:  Learning rate = 0.000088:  Batch Loss = 2.272035, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2926442623138428, Accuracy = 1.0\n",
      "Iter #397120:  Learning rate = 0.000088:  Batch Loss = 2.272888, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.300813674926758, Accuracy = 0.9833333492279053\n",
      "Iter #397440:  Learning rate = 0.000088:  Batch Loss = 2.267349, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.278777599334717, Accuracy = 1.0\n",
      "Iter #397760:  Learning rate = 0.000088:  Batch Loss = 2.270566, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3005549907684326, Accuracy = 1.0\n",
      "Iter #398080:  Learning rate = 0.000088:  Batch Loss = 2.268097, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.273711681365967, Accuracy = 1.0\n",
      "Iter #398400:  Learning rate = 0.000088:  Batch Loss = 2.261654, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2869908809661865, Accuracy = 1.0\n",
      "Iter #398720:  Learning rate = 0.000088:  Batch Loss = 2.260473, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.284043312072754, Accuracy = 1.0\n",
      "Iter #399040:  Learning rate = 0.000088:  Batch Loss = 2.261050, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3354079723358154, Accuracy = 0.9333333373069763\n",
      "Iter #399360:  Learning rate = 0.000088:  Batch Loss = 2.256611, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.272998094558716, Accuracy = 1.0\n",
      "Iter #399680:  Learning rate = 0.000088:  Batch Loss = 2.255367, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.288029909133911, Accuracy = 0.9833333492279053\n",
      "Iter #400000:  Learning rate = 0.000085:  Batch Loss = 2.253250, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2982301712036133, Accuracy = 0.9666666388511658\n",
      "Iter #400320:  Learning rate = 0.000085:  Batch Loss = 2.251764, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.280942440032959, Accuracy = 0.9666666388511658\n",
      "Iter #400640:  Learning rate = 0.000085:  Batch Loss = 2.430527, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.254287004470825, Accuracy = 1.0\n",
      "Iter #400960:  Learning rate = 0.000085:  Batch Loss = 2.248281, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.3830580711364746, Accuracy = 0.9166666865348816\n",
      "Iter #401280:  Learning rate = 0.000085:  Batch Loss = 2.246425, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.260474443435669, Accuracy = 1.0\n",
      "Iter #401600:  Learning rate = 0.000085:  Batch Loss = 2.244784, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2731640338897705, Accuracy = 0.9833333492279053\n",
      "Iter #401920:  Learning rate = 0.000085:  Batch Loss = 2.243500, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2885966300964355, Accuracy = 0.9833333492279053\n",
      "Iter #402240:  Learning rate = 0.000085:  Batch Loss = 2.241684, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2715888023376465, Accuracy = 0.9833333492279053\n",
      "Iter #402560:  Learning rate = 0.000085:  Batch Loss = 2.241891, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2553069591522217, Accuracy = 1.0\n",
      "Iter #402880:  Learning rate = 0.000085:  Batch Loss = 2.238883, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.317600965499878, Accuracy = 0.949999988079071\n",
      "Iter #403200:  Learning rate = 0.000085:  Batch Loss = 2.236093, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.279559850692749, Accuracy = 0.9666666388511658\n",
      "Iter #403520:  Learning rate = 0.000085:  Batch Loss = 2.234903, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.246394157409668, Accuracy = 1.0\n",
      "Iter #403840:  Learning rate = 0.000085:  Batch Loss = 2.233056, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.245220422744751, Accuracy = 1.0\n",
      "Iter #404160:  Learning rate = 0.000085:  Batch Loss = 2.231935, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2562592029571533, Accuracy = 1.0\n",
      "Iter #404480:  Learning rate = 0.000085:  Batch Loss = 2.231275, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2636005878448486, Accuracy = 0.9833333492279053\n",
      "Iter #404800:  Learning rate = 0.000085:  Batch Loss = 2.228329, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2403757572174072, Accuracy = 1.0\n",
      "Iter #405120:  Learning rate = 0.000085:  Batch Loss = 2.226190, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.23630690574646, Accuracy = 1.0\n",
      "Iter #405440:  Learning rate = 0.000085:  Batch Loss = 2.225002, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.245196580886841, Accuracy = 1.0\n",
      "Iter #405760:  Learning rate = 0.000085:  Batch Loss = 2.222590, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.293712854385376, Accuracy = 0.9666666388511658\n",
      "Iter #406080:  Learning rate = 0.000085:  Batch Loss = 2.220898, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2332632541656494, Accuracy = 1.0\n",
      "Iter #406400:  Learning rate = 0.000085:  Batch Loss = 2.219827, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2550106048583984, Accuracy = 0.9833333492279053\n",
      "Iter #406720:  Learning rate = 0.000085:  Batch Loss = 2.217955, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2371015548706055, Accuracy = 1.0\n",
      "Iter #407040:  Learning rate = 0.000085:  Batch Loss = 2.216603, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2361724376678467, Accuracy = 1.0\n",
      "Iter #407360:  Learning rate = 0.000085:  Batch Loss = 2.214024, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2313878536224365, Accuracy = 1.0\n",
      "Iter #407680:  Learning rate = 0.000085:  Batch Loss = 2.228846, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2323434352874756, Accuracy = 1.0\n",
      "Iter #408000:  Learning rate = 0.000085:  Batch Loss = 2.211603, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.220698356628418, Accuracy = 1.0\n",
      "Iter #408320:  Learning rate = 0.000085:  Batch Loss = 2.209572, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.232823610305786, Accuracy = 0.9833333492279053\n",
      "Iter #408640:  Learning rate = 0.000085:  Batch Loss = 2.206535, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.221207618713379, Accuracy = 1.0\n",
      "Iter #408960:  Learning rate = 0.000085:  Batch Loss = 2.204696, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2260396480560303, Accuracy = 1.0\n",
      "Iter #409280:  Learning rate = 0.000085:  Batch Loss = 2.202419, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.212001085281372, Accuracy = 1.0\n",
      "Iter #409600:  Learning rate = 0.000085:  Batch Loss = 2.207756, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2133636474609375, Accuracy = 1.0\n",
      "Iter #409920:  Learning rate = 0.000085:  Batch Loss = 2.199145, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2171804904937744, Accuracy = 1.0\n",
      "Iter #410240:  Learning rate = 0.000085:  Batch Loss = 2.198250, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.214102029800415, Accuracy = 1.0\n",
      "Iter #410560:  Learning rate = 0.000085:  Batch Loss = 2.195714, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2133145332336426, Accuracy = 1.0\n",
      "Iter #410880:  Learning rate = 0.000085:  Batch Loss = 2.193650, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2029871940612793, Accuracy = 1.0\n",
      "Iter #411200:  Learning rate = 0.000085:  Batch Loss = 2.202310, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.214510202407837, Accuracy = 1.0\n",
      "Iter #411520:  Learning rate = 0.000085:  Batch Loss = 2.189467, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1983869075775146, Accuracy = 1.0\n",
      "Iter #411840:  Learning rate = 0.000085:  Batch Loss = 2.189438, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.203096628189087, Accuracy = 1.0\n",
      "Iter #412160:  Learning rate = 0.000085:  Batch Loss = 2.185282, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.190321207046509, Accuracy = 1.0\n",
      "Iter #412480:  Learning rate = 0.000085:  Batch Loss = 2.187621, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.22103214263916, Accuracy = 1.0\n",
      "Iter #412800:  Learning rate = 0.000085:  Batch Loss = 2.181213, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.184159278869629, Accuracy = 1.0\n",
      "Iter #413120:  Learning rate = 0.000085:  Batch Loss = 2.180162, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.239248752593994, Accuracy = 0.9666666388511658\n",
      "Iter #413440:  Learning rate = 0.000085:  Batch Loss = 2.176798, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.240712881088257, Accuracy = 0.9666666388511658\n",
      "Iter #413760:  Learning rate = 0.000085:  Batch Loss = 2.175179, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.245593786239624, Accuracy = 0.949999988079071\n",
      "Iter #414080:  Learning rate = 0.000085:  Batch Loss = 2.206289, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2013559341430664, Accuracy = 1.0\n",
      "Iter #414400:  Learning rate = 0.000085:  Batch Loss = 2.172298, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.275657892227173, Accuracy = 0.9666666388511658\n",
      "Iter #414720:  Learning rate = 0.000085:  Batch Loss = 2.171137, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.174407482147217, Accuracy = 1.0\n",
      "Iter #415040:  Learning rate = 0.000085:  Batch Loss = 2.176953, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2862188816070557, Accuracy = 0.9666666388511658\n",
      "Iter #415360:  Learning rate = 0.000085:  Batch Loss = 2.170244, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.180999279022217, Accuracy = 1.0\n",
      "Iter #415680:  Learning rate = 0.000085:  Batch Loss = 2.166476, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.175872564315796, Accuracy = 1.0\n",
      "Iter #416000:  Learning rate = 0.000085:  Batch Loss = 2.169742, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.186436891555786, Accuracy = 1.0\n",
      "Iter #416320:  Learning rate = 0.000085:  Batch Loss = 2.163629, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1959049701690674, Accuracy = 0.9833333492279053\n",
      "Iter #416640:  Learning rate = 0.000085:  Batch Loss = 2.163021, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.179361581802368, Accuracy = 1.0\n",
      "Iter #416960:  Learning rate = 0.000085:  Batch Loss = 2.161871, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2083559036254883, Accuracy = 0.9833333492279053\n",
      "Iter #417280:  Learning rate = 0.000085:  Batch Loss = 2.159635, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1663451194763184, Accuracy = 1.0\n",
      "Iter #417600:  Learning rate = 0.000085:  Batch Loss = 2.160445, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1809771060943604, Accuracy = 1.0\n",
      "Iter #417920:  Learning rate = 0.000085:  Batch Loss = 2.174240, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1775619983673096, Accuracy = 1.0\n",
      "Iter #418240:  Learning rate = 0.000085:  Batch Loss = 2.158138, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.175215244293213, Accuracy = 1.0\n",
      "Iter #418560:  Learning rate = 0.000085:  Batch Loss = 2.155473, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1776251792907715, Accuracy = 1.0\n",
      "Iter #418880:  Learning rate = 0.000085:  Batch Loss = 2.154121, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1723270416259766, Accuracy = 1.0\n",
      "Iter #419200:  Learning rate = 0.000085:  Batch Loss = 2.153152, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.172015428543091, Accuracy = 1.0\n",
      "Iter #419520:  Learning rate = 0.000085:  Batch Loss = 2.153305, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.167778253555298, Accuracy = 1.0\n",
      "Iter #419840:  Learning rate = 0.000085:  Batch Loss = 2.152117, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1594600677490234, Accuracy = 1.0\n",
      "Iter #420160:  Learning rate = 0.000085:  Batch Loss = 2.149297, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.176870346069336, Accuracy = 0.9833333492279053\n",
      "Iter #420480:  Learning rate = 0.000085:  Batch Loss = 2.150087, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1615824699401855, Accuracy = 1.0\n",
      "Iter #420800:  Learning rate = 0.000085:  Batch Loss = 2.147450, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.158879280090332, Accuracy = 1.0\n",
      "Iter #421120:  Learning rate = 0.000085:  Batch Loss = 2.145983, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.158836603164673, Accuracy = 1.0\n",
      "Iter #421440:  Learning rate = 0.000085:  Batch Loss = 2.147834, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.159459352493286, Accuracy = 1.0\n",
      "Iter #421760:  Learning rate = 0.000085:  Batch Loss = 2.144581, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.150916337966919, Accuracy = 1.0\n",
      "Iter #422080:  Learning rate = 0.000085:  Batch Loss = 2.152139, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.182454824447632, Accuracy = 0.9666666388511658\n",
      "Iter #422400:  Learning rate = 0.000085:  Batch Loss = 2.141185, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.184246063232422, Accuracy = 1.0\n",
      "Iter #422720:  Learning rate = 0.000085:  Batch Loss = 2.140173, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.151358127593994, Accuracy = 1.0\n",
      "Iter #423040:  Learning rate = 0.000085:  Batch Loss = 2.138683, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.153228521347046, Accuracy = 1.0\n",
      "Iter #423360:  Learning rate = 0.000085:  Batch Loss = 2.140110, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1435163021087646, Accuracy = 1.0\n",
      "Iter #423680:  Learning rate = 0.000085:  Batch Loss = 2.138115, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.146911144256592, Accuracy = 1.0\n",
      "Iter #424000:  Learning rate = 0.000085:  Batch Loss = 2.139925, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1576051712036133, Accuracy = 1.0\n",
      "Iter #424320:  Learning rate = 0.000085:  Batch Loss = 2.135371, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1512343883514404, Accuracy = 1.0\n",
      "Iter #424640:  Learning rate = 0.000085:  Batch Loss = 2.133375, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.167743682861328, Accuracy = 0.9833333492279053\n",
      "Iter #424960:  Learning rate = 0.000085:  Batch Loss = 2.132515, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1562767028808594, Accuracy = 1.0\n",
      "Iter #425280:  Learning rate = 0.000085:  Batch Loss = 2.135256, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.150698184967041, Accuracy = 1.0\n",
      "Iter #425600:  Learning rate = 0.000085:  Batch Loss = 2.130168, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1499369144439697, Accuracy = 1.0\n",
      "Iter #425920:  Learning rate = 0.000085:  Batch Loss = 2.129256, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.143329381942749, Accuracy = 1.0\n",
      "Iter #426240:  Learning rate = 0.000085:  Batch Loss = 2.160086, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1390998363494873, Accuracy = 1.0\n",
      "Iter #426560:  Learning rate = 0.000085:  Batch Loss = 2.127138, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.149697780609131, Accuracy = 1.0\n",
      "Iter #426880:  Learning rate = 0.000085:  Batch Loss = 2.125252, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.138939619064331, Accuracy = 1.0\n",
      "Iter #427200:  Learning rate = 0.000085:  Batch Loss = 2.125993, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1377451419830322, Accuracy = 1.0\n",
      "Iter #427520:  Learning rate = 0.000085:  Batch Loss = 2.124217, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1407580375671387, Accuracy = 1.0\n",
      "Iter #427840:  Learning rate = 0.000085:  Batch Loss = 2.124288, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1379048824310303, Accuracy = 1.0\n",
      "Iter #428160:  Learning rate = 0.000085:  Batch Loss = 2.125010, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.131688356399536, Accuracy = 1.0\n",
      "Iter #428480:  Learning rate = 0.000085:  Batch Loss = 2.119715, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.133991003036499, Accuracy = 1.0\n",
      "Iter #428800:  Learning rate = 0.000085:  Batch Loss = 2.118789, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1289660930633545, Accuracy = 1.0\n",
      "Iter #429120:  Learning rate = 0.000085:  Batch Loss = 2.119506, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.175246238708496, Accuracy = 0.9833333492279053\n",
      "Iter #429440:  Learning rate = 0.000085:  Batch Loss = 2.116990, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.137352705001831, Accuracy = 1.0\n",
      "Iter #429760:  Learning rate = 0.000085:  Batch Loss = 2.115617, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1302731037139893, Accuracy = 1.0\n",
      "Iter #430080:  Learning rate = 0.000085:  Batch Loss = 2.283329, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.119992971420288, Accuracy = 1.0\n",
      "Iter #430400:  Learning rate = 0.000085:  Batch Loss = 2.112894, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.158665895462036, Accuracy = 0.9666666388511658\n",
      "Iter #430720:  Learning rate = 0.000085:  Batch Loss = 2.112095, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1278107166290283, Accuracy = 1.0\n",
      "Iter #431040:  Learning rate = 0.000085:  Batch Loss = 2.111073, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1204752922058105, Accuracy = 1.0\n",
      "Iter #431360:  Learning rate = 0.000085:  Batch Loss = 2.110317, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1267778873443604, Accuracy = 1.0\n",
      "Iter #431680:  Learning rate = 0.000085:  Batch Loss = 2.111598, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1306605339050293, Accuracy = 1.0\n",
      "Iter #432000:  Learning rate = 0.000085:  Batch Loss = 2.107175, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1226582527160645, Accuracy = 1.0\n",
      "Iter #432320:  Learning rate = 0.000085:  Batch Loss = 2.106511, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.115696668624878, Accuracy = 1.0\n",
      "Iter #432640:  Learning rate = 0.000085:  Batch Loss = 2.104970, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.129654884338379, Accuracy = 1.0\n",
      "Iter #432960:  Learning rate = 0.000085:  Batch Loss = 2.131035, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1208298206329346, Accuracy = 1.0\n",
      "Iter #433280:  Learning rate = 0.000085:  Batch Loss = 2.102306, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1130449771881104, Accuracy = 1.0\n",
      "Iter #433600:  Learning rate = 0.000085:  Batch Loss = 2.103583, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.108659029006958, Accuracy = 1.0\n",
      "Iter #433920:  Learning rate = 0.000085:  Batch Loss = 2.100365, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1108744144439697, Accuracy = 1.0\n",
      "Iter #434240:  Learning rate = 0.000085:  Batch Loss = 2.098513, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.111037492752075, Accuracy = 1.0\n",
      "Iter #434560:  Learning rate = 0.000085:  Batch Loss = 2.098564, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.108311891555786, Accuracy = 1.0\n",
      "Iter #434880:  Learning rate = 0.000085:  Batch Loss = 2.097411, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1064088344573975, Accuracy = 1.0\n",
      "Iter #435200:  Learning rate = 0.000085:  Batch Loss = 2.094851, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1050870418548584, Accuracy = 1.0\n",
      "Iter #435520:  Learning rate = 0.000085:  Batch Loss = 2.112868, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1004977226257324, Accuracy = 1.0\n",
      "Iter #435840:  Learning rate = 0.000085:  Batch Loss = 2.092232, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1022162437438965, Accuracy = 1.0\n",
      "Iter #436160:  Learning rate = 0.000085:  Batch Loss = 2.092939, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1515588760375977, Accuracy = 0.9666666388511658\n",
      "Iter #436480:  Learning rate = 0.000085:  Batch Loss = 2.324258, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.163086414337158, Accuracy = 0.9666666388511658\n",
      "Iter #436800:  Learning rate = 0.000085:  Batch Loss = 2.090980, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2185139656066895, Accuracy = 0.949999988079071\n",
      "Iter #437120:  Learning rate = 0.000085:  Batch Loss = 2.090562, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.093703508377075, Accuracy = 1.0\n",
      "Iter #437440:  Learning rate = 0.000085:  Batch Loss = 2.086370, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.102041006088257, Accuracy = 1.0\n",
      "Iter #437760:  Learning rate = 0.000085:  Batch Loss = 2.086209, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.111102819442749, Accuracy = 1.0\n",
      "Iter #438080:  Learning rate = 0.000085:  Batch Loss = 2.083554, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1006577014923096, Accuracy = 1.0\n",
      "Iter #438400:  Learning rate = 0.000085:  Batch Loss = 2.083047, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.098356246948242, Accuracy = 1.0\n",
      "Iter #438720:  Learning rate = 0.000085:  Batch Loss = 2.083196, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0989792346954346, Accuracy = 1.0\n",
      "Iter #439040:  Learning rate = 0.000085:  Batch Loss = 2.079501, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.093083381652832, Accuracy = 1.0\n",
      "Iter #439360:  Learning rate = 0.000085:  Batch Loss = 2.078423, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1025047302246094, Accuracy = 1.0\n",
      "Iter #439680:  Learning rate = 0.000085:  Batch Loss = 2.077141, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0996975898742676, Accuracy = 1.0\n",
      "Iter #440000:  Learning rate = 0.000085:  Batch Loss = 2.087735, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0860400199890137, Accuracy = 1.0\n",
      "Iter #440320:  Learning rate = 0.000085:  Batch Loss = 2.076007, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.088999032974243, Accuracy = 1.0\n",
      "Iter #440640:  Learning rate = 0.000085:  Batch Loss = 2.074849, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.081373691558838, Accuracy = 1.0\n",
      "Iter #440960:  Learning rate = 0.000085:  Batch Loss = 2.072062, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1184511184692383, Accuracy = 0.9666666388511658\n",
      "Iter #441280:  Learning rate = 0.000085:  Batch Loss = 2.070991, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.073232889175415, Accuracy = 1.0\n",
      "Iter #441600:  Learning rate = 0.000085:  Batch Loss = 2.070551, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1553215980529785, Accuracy = 0.949999988079071\n",
      "Iter #441920:  Learning rate = 0.000085:  Batch Loss = 2.069381, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0742573738098145, Accuracy = 1.0\n",
      "Iter #442240:  Learning rate = 0.000085:  Batch Loss = 2.066625, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.074352264404297, Accuracy = 1.0\n",
      "Iter #442560:  Learning rate = 0.000085:  Batch Loss = 2.099098, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2240679264068604, Accuracy = 0.8999999761581421\n",
      "Iter #442880:  Learning rate = 0.000085:  Batch Loss = 2.063417, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.068784236907959, Accuracy = 1.0\n",
      "Iter #443200:  Learning rate = 0.000085:  Batch Loss = 2.338651, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0640358924865723, Accuracy = 1.0\n",
      "Iter #443520:  Learning rate = 0.000085:  Batch Loss = 2.062899, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.068103551864624, Accuracy = 1.0\n",
      "Iter #443840:  Learning rate = 0.000085:  Batch Loss = 2.059721, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1092307567596436, Accuracy = 0.9833333492279053\n",
      "Iter #444160:  Learning rate = 0.000085:  Batch Loss = 2.057601, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0711216926574707, Accuracy = 1.0\n",
      "Iter #444480:  Learning rate = 0.000085:  Batch Loss = 2.069602, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0853586196899414, Accuracy = 1.0\n",
      "Iter #444800:  Learning rate = 0.000085:  Batch Loss = 2.055766, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1169161796569824, Accuracy = 0.9666666388511658\n",
      "Iter #445120:  Learning rate = 0.000085:  Batch Loss = 2.054400, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.059532642364502, Accuracy = 1.0\n",
      "Iter #445440:  Learning rate = 0.000085:  Batch Loss = 2.052951, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1256513595581055, Accuracy = 0.9666666388511658\n",
      "Iter #445760:  Learning rate = 0.000085:  Batch Loss = 2.052299, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.080122470855713, Accuracy = 1.0\n",
      "Iter #446080:  Learning rate = 0.000085:  Batch Loss = 2.050123, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0681309700012207, Accuracy = 1.0\n",
      "Iter #446400:  Learning rate = 0.000085:  Batch Loss = 2.048776, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0675418376922607, Accuracy = 1.0\n",
      "Iter #446720:  Learning rate = 0.000085:  Batch Loss = 2.064959, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0610365867614746, Accuracy = 1.0\n",
      "Iter #447040:  Learning rate = 0.000085:  Batch Loss = 2.045974, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.059079647064209, Accuracy = 1.0\n",
      "Iter #447360:  Learning rate = 0.000085:  Batch Loss = 2.045630, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0512092113494873, Accuracy = 1.0\n",
      "Iter #447680:  Learning rate = 0.000085:  Batch Loss = 2.043872, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1178066730499268, Accuracy = 0.9666666388511658\n",
      "Iter #448000:  Learning rate = 0.000085:  Batch Loss = 2.044093, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.047330856323242, Accuracy = 1.0\n",
      "Iter #448320:  Learning rate = 0.000085:  Batch Loss = 2.068847, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2022604942321777, Accuracy = 0.9333333373069763\n",
      "Iter #448640:  Learning rate = 0.000085:  Batch Loss = 2.055203, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1019670963287354, Accuracy = 0.9666666388511658\n",
      "Iter #448960:  Learning rate = 0.000085:  Batch Loss = 2.037932, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0860495567321777, Accuracy = 0.9666666388511658\n",
      "Iter #449280:  Learning rate = 0.000085:  Batch Loss = 2.036770, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1059536933898926, Accuracy = 0.9666666388511658\n",
      "Iter #449600:  Learning rate = 0.000085:  Batch Loss = 2.035328, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.045583486557007, Accuracy = 1.0\n",
      "Iter #449920:  Learning rate = 0.000085:  Batch Loss = 2.034413, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.089480400085449, Accuracy = 0.9666666388511658\n",
      "Iter #450240:  Learning rate = 0.000085:  Batch Loss = 2.035241, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.039703607559204, Accuracy = 1.0\n",
      "Iter #450560:  Learning rate = 0.000085:  Batch Loss = 2.031781, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.10368275642395, Accuracy = 0.9666666388511658\n",
      "Iter #450880:  Learning rate = 0.000085:  Batch Loss = 2.030082, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0618865489959717, Accuracy = 0.9833333492279053\n",
      "Iter #451200:  Learning rate = 0.000085:  Batch Loss = 2.045969, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0490732192993164, Accuracy = 1.0\n",
      "Iter #451520:  Learning rate = 0.000085:  Batch Loss = 2.027850, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.044297933578491, Accuracy = 1.0\n",
      "Iter #451840:  Learning rate = 0.000085:  Batch Loss = 2.027315, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.039499044418335, Accuracy = 1.0\n",
      "Iter #452160:  Learning rate = 0.000085:  Batch Loss = 2.025173, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0590341091156006, Accuracy = 0.9833333492279053\n",
      "Iter #452480:  Learning rate = 0.000085:  Batch Loss = 2.024189, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0536367893218994, Accuracy = 0.9833333492279053\n",
      "Iter #452800:  Learning rate = 0.000085:  Batch Loss = 2.049435, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0303008556365967, Accuracy = 1.0\n",
      "Iter #453120:  Learning rate = 0.000085:  Batch Loss = 2.020523, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.038311719894409, Accuracy = 1.0\n",
      "Iter #453440:  Learning rate = 0.000085:  Batch Loss = 2.019081, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0265817642211914, Accuracy = 1.0\n",
      "Iter #453760:  Learning rate = 0.000085:  Batch Loss = 2.020807, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0251646041870117, Accuracy = 1.0\n",
      "Iter #454080:  Learning rate = 0.000085:  Batch Loss = 2.016398, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.024590492248535, Accuracy = 1.0\n",
      "Iter #454400:  Learning rate = 0.000085:  Batch Loss = 2.014487, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.070399761199951, Accuracy = 0.9666666388511658\n",
      "Iter #454720:  Learning rate = 0.000085:  Batch Loss = 2.014301, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.027834415435791, Accuracy = 1.0\n",
      "Iter #455040:  Learning rate = 0.000085:  Batch Loss = 2.014381, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0538899898529053, Accuracy = 0.9666666388511658\n",
      "Iter #455360:  Learning rate = 0.000085:  Batch Loss = 2.010432, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.022948980331421, Accuracy = 1.0\n",
      "Iter #455680:  Learning rate = 0.000085:  Batch Loss = 2.011105, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.1032543182373047, Accuracy = 0.9666666388511658\n",
      "Iter #456000:  Learning rate = 0.000085:  Batch Loss = 2.009081, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0327236652374268, Accuracy = 0.9833333492279053\n",
      "Iter #456320:  Learning rate = 0.000085:  Batch Loss = 2.007318, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.026489496231079, Accuracy = 1.0\n",
      "Iter #456640:  Learning rate = 0.000085:  Batch Loss = 2.006811, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0185115337371826, Accuracy = 1.0\n",
      "Iter #456960:  Learning rate = 0.000085:  Batch Loss = 2.004237, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0316524505615234, Accuracy = 0.9833333492279053\n",
      "Iter #457280:  Learning rate = 0.000085:  Batch Loss = 2.003679, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0255894660949707, Accuracy = 1.0\n",
      "Iter #457600:  Learning rate = 0.000085:  Batch Loss = 2.006279, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0138940811157227, Accuracy = 1.0\n",
      "Iter #457920:  Learning rate = 0.000085:  Batch Loss = 2.001378, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.02630352973938, Accuracy = 0.9833333492279053\n",
      "Iter #458240:  Learning rate = 0.000085:  Batch Loss = 1.999280, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0477569103240967, Accuracy = 0.9666666388511658\n",
      "Iter #458560:  Learning rate = 0.000085:  Batch Loss = 1.997400, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.046355724334717, Accuracy = 0.9666666388511658\n",
      "Iter #458880:  Learning rate = 0.000085:  Batch Loss = 1.996107, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0264034271240234, Accuracy = 0.9833333492279053\n",
      "Iter #459200:  Learning rate = 0.000085:  Batch Loss = 1.994785, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0273773670196533, Accuracy = 0.9833333492279053\n",
      "Iter #459520:  Learning rate = 0.000085:  Batch Loss = 1.993645, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0102717876434326, Accuracy = 1.0\n",
      "Iter #459840:  Learning rate = 0.000085:  Batch Loss = 1.994059, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0445756912231445, Accuracy = 0.9833333492279053\n",
      "Iter #460160:  Learning rate = 0.000085:  Batch Loss = 1.991427, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9995425939559937, Accuracy = 1.0\n",
      "Iter #460480:  Learning rate = 0.000085:  Batch Loss = 1.995485, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0146212577819824, Accuracy = 1.0\n",
      "Iter #460800:  Learning rate = 0.000085:  Batch Loss = 1.987558, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9988422393798828, Accuracy = 1.0\n",
      "Iter #461120:  Learning rate = 0.000085:  Batch Loss = 1.988014, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9906376600265503, Accuracy = 1.0\n",
      "Iter #461440:  Learning rate = 0.000085:  Batch Loss = 1.986681, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.2493839263916016, Accuracy = 0.8833333253860474\n",
      "Iter #461760:  Learning rate = 0.000085:  Batch Loss = 2.031459, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9937849044799805, Accuracy = 1.0\n",
      "Iter #462080:  Learning rate = 0.000085:  Batch Loss = 1.984673, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9975948333740234, Accuracy = 1.0\n",
      "Iter #462400:  Learning rate = 0.000085:  Batch Loss = 1.992193, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.290865421295166, Accuracy = 0.8833333253860474\n",
      "Iter #462720:  Learning rate = 0.000085:  Batch Loss = 1.980489, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0030593872070312, Accuracy = 1.0\n",
      "Iter #463040:  Learning rate = 0.000085:  Batch Loss = 1.979741, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.995481252670288, Accuracy = 0.9833333492279053\n",
      "Iter #463360:  Learning rate = 0.000085:  Batch Loss = 1.978329, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9975274801254272, Accuracy = 1.0\n",
      "Iter #463680:  Learning rate = 0.000085:  Batch Loss = 1.982816, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0081379413604736, Accuracy = 1.0\n",
      "Iter #464000:  Learning rate = 0.000085:  Batch Loss = 1.982061, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.050974130630493, Accuracy = 0.9666666388511658\n",
      "Iter #464320:  Learning rate = 0.000085:  Batch Loss = 1.977827, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0252909660339355, Accuracy = 0.9666666388511658\n",
      "Iter #464640:  Learning rate = 0.000085:  Batch Loss = 1.976117, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0255868434906006, Accuracy = 0.9666666388511658\n",
      "Iter #464960:  Learning rate = 0.000085:  Batch Loss = 1.972799, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9951218366622925, Accuracy = 0.9833333492279053\n",
      "Iter #465280:  Learning rate = 0.000085:  Batch Loss = 1.971720, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9955140352249146, Accuracy = 1.0\n",
      "Iter #465600:  Learning rate = 0.000085:  Batch Loss = 1.974403, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.977374792098999, Accuracy = 1.0\n",
      "Iter #465920:  Learning rate = 0.000085:  Batch Loss = 1.970073, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0510571002960205, Accuracy = 0.9333333373069763\n",
      "Iter #466240:  Learning rate = 0.000085:  Batch Loss = 1.969120, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9711488485336304, Accuracy = 1.0\n",
      "Iter #466560:  Learning rate = 0.000085:  Batch Loss = 1.967881, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9760974645614624, Accuracy = 1.0\n",
      "Iter #466880:  Learning rate = 0.000085:  Batch Loss = 1.966806, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0259997844696045, Accuracy = 0.9666666388511658\n",
      "Iter #467200:  Learning rate = 0.000085:  Batch Loss = 1.965314, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9859710931777954, Accuracy = 1.0\n",
      "Iter #467520:  Learning rate = 0.000085:  Batch Loss = 1.964844, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9776251316070557, Accuracy = 1.0\n",
      "Iter #467840:  Learning rate = 0.000085:  Batch Loss = 1.963488, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9907106161117554, Accuracy = 1.0\n",
      "Iter #468160:  Learning rate = 0.000085:  Batch Loss = 1.961954, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9824304580688477, Accuracy = 1.0\n",
      "Iter #468480:  Learning rate = 0.000085:  Batch Loss = 1.960834, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.980398416519165, Accuracy = 1.0\n",
      "Iter #468800:  Learning rate = 0.000085:  Batch Loss = 1.960252, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9757087230682373, Accuracy = 1.0\n",
      "Iter #469120:  Learning rate = 0.000085:  Batch Loss = 1.960471, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.968722939491272, Accuracy = 1.0\n",
      "Iter #469440:  Learning rate = 0.000085:  Batch Loss = 1.962642, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9887323379516602, Accuracy = 1.0\n",
      "Iter #469760:  Learning rate = 0.000085:  Batch Loss = 1.960185, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9668240547180176, Accuracy = 1.0\n",
      "Iter #470080:  Learning rate = 0.000085:  Batch Loss = 1.971248, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9921813011169434, Accuracy = 0.9833333492279053\n",
      "Iter #470400:  Learning rate = 0.000085:  Batch Loss = 1.954143, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9668039083480835, Accuracy = 1.0\n",
      "Iter #470720:  Learning rate = 0.000085:  Batch Loss = 1.953466, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9811040163040161, Accuracy = 1.0\n",
      "Iter #471040:  Learning rate = 0.000085:  Batch Loss = 1.980607, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.961307406425476, Accuracy = 1.0\n",
      "Iter #471360:  Learning rate = 0.000085:  Batch Loss = 1.950837, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9748419523239136, Accuracy = 1.0\n",
      "Iter #471680:  Learning rate = 0.000085:  Batch Loss = 1.950021, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.957005500793457, Accuracy = 1.0\n",
      "Iter #472000:  Learning rate = 0.000085:  Batch Loss = 1.948557, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9637513160705566, Accuracy = 1.0\n",
      "Iter #472320:  Learning rate = 0.000085:  Batch Loss = 1.949548, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9577643871307373, Accuracy = 1.0\n",
      "Iter #472640:  Learning rate = 0.000085:  Batch Loss = 1.947183, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.954878568649292, Accuracy = 1.0\n",
      "Iter #472960:  Learning rate = 0.000085:  Batch Loss = 1.945114, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9517104625701904, Accuracy = 1.0\n",
      "Iter #473280:  Learning rate = 0.000085:  Batch Loss = 1.944939, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.972908854484558, Accuracy = 0.9833333492279053\n",
      "Iter #473600:  Learning rate = 0.000085:  Batch Loss = 1.944410, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9525928497314453, Accuracy = 1.0\n",
      "Iter #473920:  Learning rate = 0.000085:  Batch Loss = 1.941230, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9474581480026245, Accuracy = 1.0\n",
      "Iter #474240:  Learning rate = 0.000085:  Batch Loss = 1.943719, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9606951475143433, Accuracy = 1.0\n",
      "Iter #474560:  Learning rate = 0.000085:  Batch Loss = 1.939255, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9650557041168213, Accuracy = 0.9833333492279053\n",
      "Iter #474880:  Learning rate = 0.000085:  Batch Loss = 1.957431, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9440510272979736, Accuracy = 1.0\n",
      "Iter #475200:  Learning rate = 0.000085:  Batch Loss = 1.940965, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9500304460525513, Accuracy = 1.0\n",
      "Iter #475520:  Learning rate = 0.000085:  Batch Loss = 1.935944, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9450335502624512, Accuracy = 1.0\n",
      "Iter #475840:  Learning rate = 0.000085:  Batch Loss = 1.934274, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9417145252227783, Accuracy = 1.0\n",
      "Iter #476160:  Learning rate = 0.000085:  Batch Loss = 1.933813, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9465961456298828, Accuracy = 1.0\n",
      "Iter #476480:  Learning rate = 0.000085:  Batch Loss = 1.932078, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9387376308441162, Accuracy = 1.0\n",
      "Iter #476800:  Learning rate = 0.000085:  Batch Loss = 1.930345, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9346166849136353, Accuracy = 1.0\n",
      "Iter #477120:  Learning rate = 0.000085:  Batch Loss = 1.931742, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9324666261672974, Accuracy = 1.0\n",
      "Iter #477440:  Learning rate = 0.000085:  Batch Loss = 1.927992, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.021108388900757, Accuracy = 0.9666666388511658\n",
      "Iter #477760:  Learning rate = 0.000085:  Batch Loss = 1.926131, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9906525611877441, Accuracy = 0.949999988079071\n",
      "Iter #478080:  Learning rate = 0.000085:  Batch Loss = 1.924760, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9316599369049072, Accuracy = 1.0\n",
      "Iter #478400:  Learning rate = 0.000085:  Batch Loss = 1.923295, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9357119798660278, Accuracy = 1.0\n",
      "Iter #478720:  Learning rate = 0.000085:  Batch Loss = 1.936934, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9306814670562744, Accuracy = 1.0\n",
      "Iter #479040:  Learning rate = 0.000085:  Batch Loss = 1.921248, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9314627647399902, Accuracy = 1.0\n",
      "Iter #479360:  Learning rate = 0.000085:  Batch Loss = 1.919799, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.928426742553711, Accuracy = 1.0\n",
      "Iter #479680:  Learning rate = 0.000085:  Batch Loss = 1.920004, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9250797033309937, Accuracy = 1.0\n",
      "Iter #480000:  Learning rate = 0.000085:  Batch Loss = 1.917765, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9366456270217896, Accuracy = 1.0\n",
      "Iter #480320:  Learning rate = 0.000085:  Batch Loss = 1.916059, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9213839769363403, Accuracy = 1.0\n",
      "Iter #480640:  Learning rate = 0.000085:  Batch Loss = 1.914974, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.918633222579956, Accuracy = 1.0\n",
      "Iter #480960:  Learning rate = 0.000085:  Batch Loss = 1.922787, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9379628896713257, Accuracy = 0.9833333492279053\n",
      "Iter #481280:  Learning rate = 0.000085:  Batch Loss = 1.912123, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9156707525253296, Accuracy = 1.0\n",
      "Iter #481600:  Learning rate = 0.000085:  Batch Loss = 1.910748, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9130067825317383, Accuracy = 1.0\n",
      "Iter #481920:  Learning rate = 0.000085:  Batch Loss = 1.909397, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.054025173187256, Accuracy = 0.9333333373069763\n",
      "Iter #482240:  Learning rate = 0.000085:  Batch Loss = 1.907907, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.911488652229309, Accuracy = 1.0\n",
      "Iter #482560:  Learning rate = 0.000085:  Batch Loss = 1.914402, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0142970085144043, Accuracy = 0.9333333373069763\n",
      "Iter #482880:  Learning rate = 0.000085:  Batch Loss = 1.905098, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9166094064712524, Accuracy = 1.0\n",
      "Iter #483200:  Learning rate = 0.000085:  Batch Loss = 1.905624, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9064220190048218, Accuracy = 1.0\n",
      "Iter #483520:  Learning rate = 0.000085:  Batch Loss = 1.902561, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.0913782119750977, Accuracy = 0.8999999761581421\n",
      "Iter #483840:  Learning rate = 0.000085:  Batch Loss = 1.942152, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9293886423110962, Accuracy = 1.0\n",
      "Iter #484160:  Learning rate = 0.000085:  Batch Loss = 1.900921, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.904260516166687, Accuracy = 1.0\n",
      "Iter #484480:  Learning rate = 0.000085:  Batch Loss = 1.901888, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9497753381729126, Accuracy = 0.9833333492279053\n",
      "Iter #484800:  Learning rate = 0.000085:  Batch Loss = 1.897922, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9282033443450928, Accuracy = 0.9833333492279053\n",
      "Iter #485120:  Learning rate = 0.000085:  Batch Loss = 1.896399, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9160706996917725, Accuracy = 1.0\n",
      "Iter #485440:  Learning rate = 0.000085:  Batch Loss = 1.895017, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9050183296203613, Accuracy = 1.0\n",
      "Iter #485760:  Learning rate = 0.000085:  Batch Loss = 1.895117, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9194896221160889, Accuracy = 1.0\n",
      "Iter #486080:  Learning rate = 0.000085:  Batch Loss = 1.902360, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9005025625228882, Accuracy = 1.0\n",
      "Iter #486400:  Learning rate = 0.000085:  Batch Loss = 1.900516, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9273335933685303, Accuracy = 1.0\n",
      "Iter #486720:  Learning rate = 0.000085:  Batch Loss = 1.892314, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9034754037857056, Accuracy = 1.0\n",
      "Iter #487040:  Learning rate = 0.000085:  Batch Loss = 1.888288, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.908313274383545, Accuracy = 1.0\n",
      "Iter #487360:  Learning rate = 0.000085:  Batch Loss = 1.887187, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.895752191543579, Accuracy = 1.0\n",
      "Iter #487680:  Learning rate = 0.000085:  Batch Loss = 1.889190, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8995535373687744, Accuracy = 1.0\n",
      "Iter #488000:  Learning rate = 0.000085:  Batch Loss = 1.884879, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8963664770126343, Accuracy = 1.0\n",
      "Iter #488320:  Learning rate = 0.000085:  Batch Loss = 1.891100, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.896496295928955, Accuracy = 1.0\n",
      "Iter #488640:  Learning rate = 0.000085:  Batch Loss = 1.881721, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8941253423690796, Accuracy = 1.0\n",
      "Iter #488960:  Learning rate = 0.000085:  Batch Loss = 1.879660, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8908597230911255, Accuracy = 1.0\n",
      "Iter #489280:  Learning rate = 0.000085:  Batch Loss = 1.878751, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.891188383102417, Accuracy = 1.0\n",
      "Iter #489600:  Learning rate = 0.000085:  Batch Loss = 1.878031, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8862395286560059, Accuracy = 1.0\n",
      "Iter #489920:  Learning rate = 0.000085:  Batch Loss = 1.888590, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8871744871139526, Accuracy = 1.0\n",
      "Iter #490240:  Learning rate = 0.000085:  Batch Loss = 1.877191, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8882572650909424, Accuracy = 1.0\n",
      "Iter #490560:  Learning rate = 0.000085:  Batch Loss = 1.872843, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.883450984954834, Accuracy = 1.0\n",
      "Iter #490880:  Learning rate = 0.000085:  Batch Loss = 1.871458, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.876261830329895, Accuracy = 1.0\n",
      "Iter #491200:  Learning rate = 0.000085:  Batch Loss = 1.872507, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8922877311706543, Accuracy = 1.0\n",
      "Iter #491520:  Learning rate = 0.000085:  Batch Loss = 1.870041, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8696768283843994, Accuracy = 1.0\n",
      "Iter #491840:  Learning rate = 0.000085:  Batch Loss = 2.099300, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8710793256759644, Accuracy = 1.0\n",
      "Iter #492160:  Learning rate = 0.000085:  Batch Loss = 1.869061, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8763842582702637, Accuracy = 1.0\n",
      "Iter #492480:  Learning rate = 0.000085:  Batch Loss = 1.866503, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8778842687606812, Accuracy = 1.0\n",
      "Iter #492800:  Learning rate = 0.000085:  Batch Loss = 1.864776, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.88546884059906, Accuracy = 1.0\n",
      "Iter #493120:  Learning rate = 0.000085:  Batch Loss = 1.894467, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.868545413017273, Accuracy = 1.0\n",
      "Iter #493440:  Learning rate = 0.000085:  Batch Loss = 1.863529, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9425002336502075, Accuracy = 0.9666666388511658\n",
      "Iter #493760:  Learning rate = 0.000085:  Batch Loss = 1.859311, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8767452239990234, Accuracy = 1.0\n",
      "Iter #494080:  Learning rate = 0.000085:  Batch Loss = 1.860057, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8634278774261475, Accuracy = 1.0\n",
      "Iter #494400:  Learning rate = 0.000085:  Batch Loss = 1.857116, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.861472487449646, Accuracy = 1.0\n",
      "Iter #494720:  Learning rate = 0.000085:  Batch Loss = 1.859363, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8840802907943726, Accuracy = 1.0\n",
      "Iter #495040:  Learning rate = 0.000085:  Batch Loss = 1.855016, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.887609601020813, Accuracy = 0.9833333492279053\n",
      "Iter #495360:  Learning rate = 0.000085:  Batch Loss = 1.852609, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9344923496246338, Accuracy = 0.9666666388511658\n",
      "Iter #495680:  Learning rate = 0.000085:  Batch Loss = 1.853774, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8586235046386719, Accuracy = 1.0\n",
      "Iter #496000:  Learning rate = 0.000085:  Batch Loss = 1.853763, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.874337911605835, Accuracy = 1.0\n",
      "Iter #496320:  Learning rate = 0.000085:  Batch Loss = 1.850655, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.884804368019104, Accuracy = 0.9833333492279053\n",
      "Iter #496640:  Learning rate = 0.000085:  Batch Loss = 1.847040, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8516108989715576, Accuracy = 1.0\n",
      "Iter #496960:  Learning rate = 0.000085:  Batch Loss = 1.845541, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.84795343875885, Accuracy = 1.0\n",
      "Iter #497280:  Learning rate = 0.000085:  Batch Loss = 1.844136, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.851170539855957, Accuracy = 1.0\n",
      "Iter #497600:  Learning rate = 0.000085:  Batch Loss = 1.863674, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9128806591033936, Accuracy = 0.9666666388511658\n",
      "Iter #497920:  Learning rate = 0.000085:  Batch Loss = 1.841776, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8783538341522217, Accuracy = 0.9666666388511658\n",
      "Iter #498240:  Learning rate = 0.000085:  Batch Loss = 1.840062, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.874429702758789, Accuracy = 0.9833333492279053\n",
      "Iter #498560:  Learning rate = 0.000085:  Batch Loss = 1.840996, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8645148277282715, Accuracy = 1.0\n",
      "Iter #498880:  Learning rate = 0.000085:  Batch Loss = 1.858487, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8522624969482422, Accuracy = 1.0\n",
      "Iter #499200:  Learning rate = 0.000085:  Batch Loss = 1.837196, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8542835712432861, Accuracy = 1.0\n",
      "Iter #499520:  Learning rate = 0.000085:  Batch Loss = 1.838486, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.853210210800171, Accuracy = 1.0\n",
      "Iter #499840:  Learning rate = 0.000085:  Batch Loss = 1.833254, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8693811893463135, Accuracy = 0.9666666388511658\n",
      "Iter #500160:  Learning rate = 0.000082:  Batch Loss = 1.832364, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8687834739685059, Accuracy = 0.9833333492279053\n",
      "Iter #500480:  Learning rate = 0.000082:  Batch Loss = 1.837217, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8415687084197998, Accuracy = 1.0\n",
      "Iter #500800:  Learning rate = 0.000082:  Batch Loss = 1.830698, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8559238910675049, Accuracy = 0.9833333492279053\n",
      "Iter #501120:  Learning rate = 0.000082:  Batch Loss = 1.827574, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8331410884857178, Accuracy = 1.0\n",
      "Iter #501440:  Learning rate = 0.000082:  Batch Loss = 1.828184, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.835058569908142, Accuracy = 1.0\n",
      "Iter #501760:  Learning rate = 0.000082:  Batch Loss = 1.826771, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8368152379989624, Accuracy = 1.0\n",
      "Iter #502080:  Learning rate = 0.000082:  Batch Loss = 1.823493, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8456580638885498, Accuracy = 1.0\n",
      "Iter #502400:  Learning rate = 0.000082:  Batch Loss = 1.821868, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.832863450050354, Accuracy = 1.0\n",
      "Iter #502720:  Learning rate = 0.000082:  Batch Loss = 1.829906, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8418577909469604, Accuracy = 1.0\n",
      "Iter #503040:  Learning rate = 0.000082:  Batch Loss = 1.819487, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8299171924591064, Accuracy = 1.0\n",
      "Iter #503360:  Learning rate = 0.000082:  Batch Loss = 1.818198, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.874929666519165, Accuracy = 0.9833333492279053\n",
      "Iter #503680:  Learning rate = 0.000082:  Batch Loss = 1.818006, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.838716983795166, Accuracy = 1.0\n",
      "Iter #504000:  Learning rate = 0.000082:  Batch Loss = 1.814736, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8187528848648071, Accuracy = 1.0\n",
      "Iter #504320:  Learning rate = 0.000082:  Batch Loss = 1.813377, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 2.132985830307007, Accuracy = 0.8666666746139526\n",
      "Iter #504640:  Learning rate = 0.000082:  Batch Loss = 1.812753, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8132832050323486, Accuracy = 1.0\n",
      "Iter #504960:  Learning rate = 0.000082:  Batch Loss = 1.810595, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8110862970352173, Accuracy = 1.0\n",
      "Iter #505280:  Learning rate = 0.000082:  Batch Loss = 1.811855, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8107000589370728, Accuracy = 1.0\n",
      "Iter #505600:  Learning rate = 0.000082:  Batch Loss = 1.941903, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.815527081489563, Accuracy = 1.0\n",
      "Iter #505920:  Learning rate = 0.000082:  Batch Loss = 1.806955, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8220031261444092, Accuracy = 1.0\n",
      "Iter #506240:  Learning rate = 0.000082:  Batch Loss = 1.806135, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8131294250488281, Accuracy = 1.0\n",
      "Iter #506560:  Learning rate = 0.000082:  Batch Loss = 1.812086, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.827770709991455, Accuracy = 1.0\n",
      "Iter #506880:  Learning rate = 0.000082:  Batch Loss = 1.807783, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8322317600250244, Accuracy = 1.0\n",
      "Iter #507200:  Learning rate = 0.000082:  Batch Loss = 1.801734, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.826990008354187, Accuracy = 1.0\n",
      "Iter #507520:  Learning rate = 0.000082:  Batch Loss = 1.799977, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8156719207763672, Accuracy = 1.0\n",
      "Iter #507840:  Learning rate = 0.000082:  Batch Loss = 1.803633, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8621926307678223, Accuracy = 0.9666666388511658\n",
      "Iter #508160:  Learning rate = 0.000082:  Batch Loss = 1.818761, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8254735469818115, Accuracy = 1.0\n",
      "Iter #508480:  Learning rate = 0.000082:  Batch Loss = 1.795964, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.804356336593628, Accuracy = 1.0\n",
      "Iter #508800:  Learning rate = 0.000082:  Batch Loss = 1.794627, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8788068294525146, Accuracy = 0.9666666388511658\n",
      "Iter #509120:  Learning rate = 0.000082:  Batch Loss = 1.796072, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8003838062286377, Accuracy = 1.0\n",
      "Iter #509440:  Learning rate = 0.000082:  Batch Loss = 1.791971, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9071863889694214, Accuracy = 0.9666666388511658\n",
      "Iter #509760:  Learning rate = 0.000082:  Batch Loss = 1.791884, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8102543354034424, Accuracy = 1.0\n",
      "Iter #510080:  Learning rate = 0.000082:  Batch Loss = 1.792291, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8024749755859375, Accuracy = 1.0\n",
      "Iter #510400:  Learning rate = 0.000082:  Batch Loss = 1.787893, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7984696626663208, Accuracy = 1.0\n",
      "Iter #510720:  Learning rate = 0.000082:  Batch Loss = 1.787411, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8618097305297852, Accuracy = 0.9666666388511658\n",
      "Iter #511040:  Learning rate = 0.000082:  Batch Loss = 1.789423, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8421753644943237, Accuracy = 0.9666666388511658\n",
      "Iter #511360:  Learning rate = 0.000082:  Batch Loss = 1.784333, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7963573932647705, Accuracy = 1.0\n",
      "Iter #511680:  Learning rate = 0.000082:  Batch Loss = 1.782985, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7894972562789917, Accuracy = 1.0\n",
      "Iter #512000:  Learning rate = 0.000082:  Batch Loss = 1.782784, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.792468786239624, Accuracy = 1.0\n",
      "Iter #512320:  Learning rate = 0.000082:  Batch Loss = 1.780341, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.9266579151153564, Accuracy = 0.8999999761581421\n",
      "Iter #512640:  Learning rate = 0.000082:  Batch Loss = 1.780053, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7903469800949097, Accuracy = 1.0\n",
      "Iter #512960:  Learning rate = 0.000082:  Batch Loss = 1.793019, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8728505373001099, Accuracy = 0.9666666388511658\n",
      "Iter #513280:  Learning rate = 0.000082:  Batch Loss = 1.777022, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7879180908203125, Accuracy = 1.0\n",
      "Iter #513600:  Learning rate = 0.000082:  Batch Loss = 1.776595, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7971787452697754, Accuracy = 1.0\n",
      "Iter #513920:  Learning rate = 0.000082:  Batch Loss = 1.773755, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7865848541259766, Accuracy = 1.0\n",
      "Iter #514240:  Learning rate = 0.000082:  Batch Loss = 1.772214, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7913650274276733, Accuracy = 1.0\n",
      "Iter #514560:  Learning rate = 0.000082:  Batch Loss = 1.775215, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8124339580535889, Accuracy = 0.9833333492279053\n",
      "Iter #514880:  Learning rate = 0.000082:  Batch Loss = 1.769321, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8112800121307373, Accuracy = 0.9666666388511658\n",
      "Iter #515200:  Learning rate = 0.000082:  Batch Loss = 1.775109, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8429007530212402, Accuracy = 0.9666666388511658\n",
      "Iter #515520:  Learning rate = 0.000082:  Batch Loss = 1.767031, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7800899744033813, Accuracy = 1.0\n",
      "Iter #515840:  Learning rate = 0.000082:  Batch Loss = 1.768519, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8098520040512085, Accuracy = 0.9833333492279053\n",
      "Iter #516160:  Learning rate = 0.000082:  Batch Loss = 1.767999, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.785332441329956, Accuracy = 1.0\n",
      "Iter #516480:  Learning rate = 0.000082:  Batch Loss = 1.763653, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7685739994049072, Accuracy = 1.0\n",
      "Iter #516800:  Learning rate = 0.000082:  Batch Loss = 1.764854, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8216556310653687, Accuracy = 0.9666666388511658\n",
      "Iter #517120:  Learning rate = 0.000082:  Batch Loss = 1.777227, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7945358753204346, Accuracy = 0.9833333492279053\n",
      "Iter #517440:  Learning rate = 0.000082:  Batch Loss = 1.763178, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7674694061279297, Accuracy = 1.0\n",
      "Iter #517760:  Learning rate = 0.000082:  Batch Loss = 1.761758, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7727552652359009, Accuracy = 1.0\n",
      "Iter #518080:  Learning rate = 0.000082:  Batch Loss = 1.760011, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7932460308074951, Accuracy = 0.9833333492279053\n",
      "Iter #518400:  Learning rate = 0.000082:  Batch Loss = 1.765158, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7992286682128906, Accuracy = 0.9666666388511658\n",
      "Iter #518720:  Learning rate = 0.000082:  Batch Loss = 1.762983, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7814747095108032, Accuracy = 1.0\n",
      "Iter #519040:  Learning rate = 0.000082:  Batch Loss = 1.768856, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7766478061676025, Accuracy = 1.0\n",
      "Iter #519360:  Learning rate = 0.000082:  Batch Loss = 1.758916, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7721998691558838, Accuracy = 1.0\n",
      "Iter #519680:  Learning rate = 0.000082:  Batch Loss = 1.760144, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8109633922576904, Accuracy = 0.9833333492279053\n",
      "Iter #520000:  Learning rate = 0.000082:  Batch Loss = 1.761956, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7770334482192993, Accuracy = 1.0\n",
      "Iter #520320:  Learning rate = 0.000082:  Batch Loss = 1.753589, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7714955806732178, Accuracy = 1.0\n",
      "Iter #520640:  Learning rate = 0.000082:  Batch Loss = 1.756750, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7815111875534058, Accuracy = 0.9833333492279053\n",
      "Iter #520960:  Learning rate = 0.000082:  Batch Loss = 1.753184, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7653954029083252, Accuracy = 1.0\n",
      "Iter #521280:  Learning rate = 0.000082:  Batch Loss = 1.756457, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.768829107284546, Accuracy = 1.0\n",
      "Iter #521600:  Learning rate = 0.000082:  Batch Loss = 1.753005, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7782565355300903, Accuracy = 0.9833333492279053\n",
      "Iter #521920:  Learning rate = 0.000082:  Batch Loss = 1.750613, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7784850597381592, Accuracy = 0.9833333492279053\n",
      "Iter #522240:  Learning rate = 0.000082:  Batch Loss = 1.749083, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7624070644378662, Accuracy = 1.0\n",
      "Iter #522560:  Learning rate = 0.000082:  Batch Loss = 1.748700, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7692639827728271, Accuracy = 1.0\n",
      "Iter #522880:  Learning rate = 0.000082:  Batch Loss = 1.747524, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7640193700790405, Accuracy = 1.0\n",
      "Iter #523200:  Learning rate = 0.000082:  Batch Loss = 1.748214, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7625935077667236, Accuracy = 1.0\n",
      "Iter #523520:  Learning rate = 0.000082:  Batch Loss = 1.745949, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.758217692375183, Accuracy = 1.0\n",
      "Iter #523840:  Learning rate = 0.000082:  Batch Loss = 1.751939, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7605167627334595, Accuracy = 1.0\n",
      "Iter #524160:  Learning rate = 0.000082:  Batch Loss = 1.745123, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7620189189910889, Accuracy = 1.0\n",
      "Iter #524480:  Learning rate = 0.000082:  Batch Loss = 1.753833, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7538260221481323, Accuracy = 1.0\n",
      "Iter #524800:  Learning rate = 0.000082:  Batch Loss = 1.742850, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.766998291015625, Accuracy = 1.0\n",
      "Iter #525120:  Learning rate = 0.000082:  Batch Loss = 1.752297, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7500545978546143, Accuracy = 1.0\n",
      "Iter #525440:  Learning rate = 0.000082:  Batch Loss = 1.742933, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.752963900566101, Accuracy = 1.0\n",
      "Iter #525760:  Learning rate = 0.000082:  Batch Loss = 1.739300, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.749051570892334, Accuracy = 1.0\n",
      "Iter #526080:  Learning rate = 0.000082:  Batch Loss = 1.738913, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7563254833221436, Accuracy = 1.0\n",
      "Iter #526400:  Learning rate = 0.000082:  Batch Loss = 1.738482, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7552083730697632, Accuracy = 1.0\n",
      "Iter #526720:  Learning rate = 0.000082:  Batch Loss = 1.739054, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.751886010169983, Accuracy = 1.0\n",
      "Iter #527040:  Learning rate = 0.000082:  Batch Loss = 1.735456, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7470120191574097, Accuracy = 1.0\n",
      "Iter #527360:  Learning rate = 0.000082:  Batch Loss = 1.746662, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7442816495895386, Accuracy = 1.0\n",
      "Iter #527680:  Learning rate = 0.000082:  Batch Loss = 1.733326, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7428722381591797, Accuracy = 1.0\n",
      "Iter #528000:  Learning rate = 0.000082:  Batch Loss = 1.732646, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7511528730392456, Accuracy = 1.0\n",
      "Iter #528320:  Learning rate = 0.000082:  Batch Loss = 1.737257, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7376296520233154, Accuracy = 1.0\n",
      "Iter #528640:  Learning rate = 0.000082:  Batch Loss = 1.732358, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7613985538482666, Accuracy = 0.9833333492279053\n",
      "Iter #528960:  Learning rate = 0.000082:  Batch Loss = 1.730313, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7367476224899292, Accuracy = 1.0\n",
      "Iter #529280:  Learning rate = 0.000082:  Batch Loss = 1.729932, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.737963080406189, Accuracy = 1.0\n",
      "Iter #529600:  Learning rate = 0.000082:  Batch Loss = 1.728930, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7381281852722168, Accuracy = 1.0\n",
      "Iter #529920:  Learning rate = 0.000082:  Batch Loss = 1.728550, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.740346074104309, Accuracy = 1.0\n",
      "Iter #530240:  Learning rate = 0.000082:  Batch Loss = 1.734419, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7338366508483887, Accuracy = 1.0\n",
      "Iter #530560:  Learning rate = 0.000082:  Batch Loss = 1.727237, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7394776344299316, Accuracy = 1.0\n",
      "Iter #530880:  Learning rate = 0.000082:  Batch Loss = 1.725934, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7299785614013672, Accuracy = 1.0\n",
      "Iter #531200:  Learning rate = 0.000082:  Batch Loss = 1.722388, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7301957607269287, Accuracy = 1.0\n",
      "Iter #531520:  Learning rate = 0.000082:  Batch Loss = 1.721672, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7599742412567139, Accuracy = 0.9666666388511658\n",
      "Iter #531840:  Learning rate = 0.000082:  Batch Loss = 1.720808, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7322794198989868, Accuracy = 1.0\n",
      "Iter #532160:  Learning rate = 0.000082:  Batch Loss = 1.718910, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7248624563217163, Accuracy = 1.0\n",
      "Iter #532480:  Learning rate = 0.000082:  Batch Loss = 1.719422, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7282962799072266, Accuracy = 1.0\n",
      "Iter #532800:  Learning rate = 0.000082:  Batch Loss = 1.718565, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.722166895866394, Accuracy = 1.0\n",
      "Iter #533120:  Learning rate = 0.000082:  Batch Loss = 1.717818, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7348800897598267, Accuracy = 1.0\n",
      "Iter #533440:  Learning rate = 0.000082:  Batch Loss = 1.715142, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7162362337112427, Accuracy = 1.0\n",
      "Iter #533760:  Learning rate = 0.000082:  Batch Loss = 1.713626, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7149871587753296, Accuracy = 1.0\n",
      "Iter #534080:  Learning rate = 0.000082:  Batch Loss = 1.712674, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8043092489242554, Accuracy = 0.9333333373069763\n",
      "Iter #534400:  Learning rate = 0.000082:  Batch Loss = 1.711990, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7125272750854492, Accuracy = 1.0\n",
      "Iter #534720:  Learning rate = 0.000082:  Batch Loss = 1.710568, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.711032748222351, Accuracy = 1.0\n",
      "Iter #535040:  Learning rate = 0.000082:  Batch Loss = 1.709461, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8774665594100952, Accuracy = 0.8999999761581421\n",
      "Iter #535360:  Learning rate = 0.000082:  Batch Loss = 1.708797, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7319118976593018, Accuracy = 0.9833333492279053\n",
      "Iter #535680:  Learning rate = 0.000082:  Batch Loss = 1.707442, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7142096757888794, Accuracy = 1.0\n",
      "Iter #536000:  Learning rate = 0.000082:  Batch Loss = 1.706164, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7329376935958862, Accuracy = 1.0\n",
      "Iter #536320:  Learning rate = 0.000082:  Batch Loss = 1.722016, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7174149751663208, Accuracy = 1.0\n",
      "Iter #536640:  Learning rate = 0.000082:  Batch Loss = 1.704099, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7183092832565308, Accuracy = 1.0\n",
      "Iter #536960:  Learning rate = 0.000082:  Batch Loss = 1.710702, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.73690664768219, Accuracy = 1.0\n",
      "Iter #537280:  Learning rate = 0.000082:  Batch Loss = 1.710107, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.718542218208313, Accuracy = 1.0\n",
      "Iter #537600:  Learning rate = 0.000082:  Batch Loss = 1.701698, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7084723711013794, Accuracy = 1.0\n",
      "Iter #537920:  Learning rate = 0.000082:  Batch Loss = 1.699854, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7041548490524292, Accuracy = 1.0\n",
      "Iter #538240:  Learning rate = 0.000082:  Batch Loss = 1.700144, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8084512948989868, Accuracy = 0.9333333373069763\n",
      "Iter #538560:  Learning rate = 0.000082:  Batch Loss = 1.733078, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7100646495819092, Accuracy = 1.0\n",
      "Iter #538880:  Learning rate = 0.000082:  Batch Loss = 1.698206, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7046006917953491, Accuracy = 1.0\n",
      "Iter #539200:  Learning rate = 0.000082:  Batch Loss = 1.695305, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7107727527618408, Accuracy = 1.0\n",
      "Iter #539520:  Learning rate = 0.000082:  Batch Loss = 1.694245, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7103043794631958, Accuracy = 1.0\n",
      "Iter #539840:  Learning rate = 0.000082:  Batch Loss = 1.698207, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.702810525894165, Accuracy = 1.0\n",
      "Iter #540160:  Learning rate = 0.000082:  Batch Loss = 1.692510, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.708487868309021, Accuracy = 1.0\n",
      "Iter #540480:  Learning rate = 0.000082:  Batch Loss = 1.697763, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7038254737854004, Accuracy = 1.0\n",
      "Iter #540800:  Learning rate = 0.000082:  Batch Loss = 1.689567, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7069759368896484, Accuracy = 1.0\n",
      "Iter #541120:  Learning rate = 0.000082:  Batch Loss = 1.689981, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6937718391418457, Accuracy = 1.0\n",
      "Iter #541440:  Learning rate = 0.000082:  Batch Loss = 1.693062, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6966997385025024, Accuracy = 1.0\n",
      "Iter #541760:  Learning rate = 0.000082:  Batch Loss = 1.686624, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7893685102462769, Accuracy = 0.949999988079071\n",
      "Iter #542080:  Learning rate = 0.000082:  Batch Loss = 1.685632, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6898794174194336, Accuracy = 1.0\n",
      "Iter #542400:  Learning rate = 0.000082:  Batch Loss = 1.730004, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6922132968902588, Accuracy = 1.0\n",
      "Iter #542720:  Learning rate = 0.000082:  Batch Loss = 1.683598, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7501343488693237, Accuracy = 0.9666666388511658\n",
      "Iter #543040:  Learning rate = 0.000082:  Batch Loss = 1.683954, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.798525094985962, Accuracy = 0.9666666388511658\n",
      "Iter #543360:  Learning rate = 0.000082:  Batch Loss = 1.681203, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6918302774429321, Accuracy = 1.0\n",
      "Iter #543680:  Learning rate = 0.000082:  Batch Loss = 1.690000, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7198486328125, Accuracy = 0.9833333492279053\n",
      "Iter #544000:  Learning rate = 0.000082:  Batch Loss = 1.678732, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6904921531677246, Accuracy = 1.0\n",
      "Iter #544320:  Learning rate = 0.000082:  Batch Loss = 1.680331, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.709248661994934, Accuracy = 1.0\n",
      "Iter #544640:  Learning rate = 0.000082:  Batch Loss = 1.677299, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6839699745178223, Accuracy = 1.0\n",
      "Iter #544960:  Learning rate = 0.000082:  Batch Loss = 1.676451, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7072685956954956, Accuracy = 0.9833333492279053\n",
      "Iter #545280:  Learning rate = 0.000082:  Batch Loss = 1.674907, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6892422437667847, Accuracy = 1.0\n",
      "Iter #545600:  Learning rate = 0.000082:  Batch Loss = 1.675191, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.695969820022583, Accuracy = 1.0\n",
      "Iter #545920:  Learning rate = 0.000082:  Batch Loss = 1.672863, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.693116545677185, Accuracy = 1.0\n",
      "Iter #546240:  Learning rate = 0.000082:  Batch Loss = 1.673419, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.690210223197937, Accuracy = 1.0\n",
      "Iter #546560:  Learning rate = 0.000082:  Batch Loss = 1.670843, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6865026950836182, Accuracy = 1.0\n",
      "Iter #546880:  Learning rate = 0.000082:  Batch Loss = 1.669175, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7192178964614868, Accuracy = 0.9833333492279053\n",
      "Iter #547200:  Learning rate = 0.000082:  Batch Loss = 1.668570, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6786901950836182, Accuracy = 1.0\n",
      "Iter #547520:  Learning rate = 0.000082:  Batch Loss = 1.669658, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6901456117630005, Accuracy = 1.0\n",
      "Iter #547840:  Learning rate = 0.000082:  Batch Loss = 1.667688, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6914423704147339, Accuracy = 1.0\n",
      "Iter #548160:  Learning rate = 0.000082:  Batch Loss = 1.674496, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.678160309791565, Accuracy = 1.0\n",
      "Iter #548480:  Learning rate = 0.000082:  Batch Loss = 1.670157, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6929734945297241, Accuracy = 1.0\n",
      "Iter #548800:  Learning rate = 0.000082:  Batch Loss = 1.662902, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6677803993225098, Accuracy = 1.0\n",
      "Iter #549120:  Learning rate = 0.000082:  Batch Loss = 1.662235, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7581864595413208, Accuracy = 0.9666666388511658\n",
      "Iter #549440:  Learning rate = 0.000082:  Batch Loss = 1.664492, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6702779531478882, Accuracy = 1.0\n",
      "Iter #549760:  Learning rate = 0.000082:  Batch Loss = 1.659485, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.664387583732605, Accuracy = 1.0\n",
      "Iter #550080:  Learning rate = 0.000082:  Batch Loss = 1.659652, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8016297817230225, Accuracy = 0.9333333373069763\n",
      "Iter #550400:  Learning rate = 0.000082:  Batch Loss = 1.657319, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7582650184631348, Accuracy = 0.949999988079071\n",
      "Iter #550720:  Learning rate = 0.000082:  Batch Loss = 1.656545, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7077152729034424, Accuracy = 0.9666666388511658\n",
      "Iter #551040:  Learning rate = 0.000082:  Batch Loss = 1.655287, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.675092101097107, Accuracy = 1.0\n",
      "Iter #551360:  Learning rate = 0.000082:  Batch Loss = 1.655720, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7054646015167236, Accuracy = 0.9833333492279053\n",
      "Iter #551680:  Learning rate = 0.000082:  Batch Loss = 1.653189, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6726661920547485, Accuracy = 0.9833333492279053\n",
      "Iter #552000:  Learning rate = 0.000082:  Batch Loss = 1.733319, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8111324310302734, Accuracy = 0.8999999761581421\n",
      "Iter #552320:  Learning rate = 0.000082:  Batch Loss = 1.651296, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6574889421463013, Accuracy = 1.0\n",
      "Iter #552640:  Learning rate = 0.000082:  Batch Loss = 1.650371, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6571882963180542, Accuracy = 1.0\n",
      "Iter #552960:  Learning rate = 0.000082:  Batch Loss = 1.650007, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7355308532714844, Accuracy = 0.9666666388511658\n",
      "Iter #553280:  Learning rate = 0.000082:  Batch Loss = 1.648282, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6682348251342773, Accuracy = 1.0\n",
      "Iter #553600:  Learning rate = 0.000082:  Batch Loss = 1.646820, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6672135591506958, Accuracy = 1.0\n",
      "Iter #553920:  Learning rate = 0.000082:  Batch Loss = 1.645812, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6845550537109375, Accuracy = 0.9666666388511658\n",
      "Iter #554240:  Learning rate = 0.000082:  Batch Loss = 1.647364, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.665124773979187, Accuracy = 1.0\n",
      "Iter #554560:  Learning rate = 0.000082:  Batch Loss = 1.643259, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.658026099205017, Accuracy = 1.0\n",
      "Iter #554880:  Learning rate = 0.000082:  Batch Loss = 1.650017, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6845446825027466, Accuracy = 0.9833333492279053\n",
      "Iter #555200:  Learning rate = 0.000082:  Batch Loss = 1.642001, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6601959466934204, Accuracy = 1.0\n",
      "Iter #555520:  Learning rate = 0.000082:  Batch Loss = 1.639843, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6647648811340332, Accuracy = 0.9833333492279053\n",
      "Iter #555840:  Learning rate = 0.000082:  Batch Loss = 1.639259, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6723815202713013, Accuracy = 0.9833333492279053\n",
      "Iter #556160:  Learning rate = 0.000082:  Batch Loss = 1.638162, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6564828157424927, Accuracy = 1.0\n",
      "Iter #556480:  Learning rate = 0.000082:  Batch Loss = 1.637924, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6455742120742798, Accuracy = 1.0\n",
      "Iter #556800:  Learning rate = 0.000082:  Batch Loss = 1.694782, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6442277431488037, Accuracy = 1.0\n",
      "Iter #557120:  Learning rate = 0.000082:  Batch Loss = 1.634439, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6763348579406738, Accuracy = 0.9833333492279053\n",
      "Iter #557440:  Learning rate = 0.000082:  Batch Loss = 1.633568, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7913320064544678, Accuracy = 0.9166666865348816\n",
      "Iter #557760:  Learning rate = 0.000082:  Batch Loss = 1.634059, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6410385370254517, Accuracy = 1.0\n",
      "Iter #558080:  Learning rate = 0.000082:  Batch Loss = 1.747727, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.674385666847229, Accuracy = 0.9833333492279053\n",
      "Iter #558400:  Learning rate = 0.000082:  Batch Loss = 1.894273, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.653012990951538, Accuracy = 0.9833333492279053\n",
      "Iter #558720:  Learning rate = 0.000082:  Batch Loss = 1.647774, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.690204381942749, Accuracy = 1.0\n",
      "Iter #559040:  Learning rate = 0.000082:  Batch Loss = 1.628830, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.664082646369934, Accuracy = 0.9833333492279053\n",
      "Iter #559360:  Learning rate = 0.000082:  Batch Loss = 1.627939, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6808953285217285, Accuracy = 0.9666666388511658\n",
      "Iter #559680:  Learning rate = 0.000082:  Batch Loss = 1.627722, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6711316108703613, Accuracy = 0.9666666388511658\n",
      "Iter #560000:  Learning rate = 0.000082:  Batch Loss = 1.626042, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6739071607589722, Accuracy = 0.9666666388511658\n",
      "Iter #560320:  Learning rate = 0.000082:  Batch Loss = 1.625831, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6754980087280273, Accuracy = 0.9666666388511658\n",
      "Iter #560640:  Learning rate = 0.000082:  Batch Loss = 1.624050, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6757255792617798, Accuracy = 0.9666666388511658\n",
      "Iter #560960:  Learning rate = 0.000082:  Batch Loss = 1.623386, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6630498170852661, Accuracy = 0.9833333492279053\n",
      "Iter #561280:  Learning rate = 0.000082:  Batch Loss = 1.621351, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6522032022476196, Accuracy = 0.9833333492279053\n",
      "Iter #561600:  Learning rate = 0.000082:  Batch Loss = 1.622082, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.656193733215332, Accuracy = 0.9666666388511658\n",
      "Iter #561920:  Learning rate = 0.000082:  Batch Loss = 1.634790, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6476881504058838, Accuracy = 1.0\n",
      "Iter #562240:  Learning rate = 0.000082:  Batch Loss = 1.619246, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6281274557113647, Accuracy = 1.0\n",
      "Iter #562560:  Learning rate = 0.000082:  Batch Loss = 1.617656, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7622967958450317, Accuracy = 0.9333333373069763\n",
      "Iter #562880:  Learning rate = 0.000082:  Batch Loss = 1.617377, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6535334587097168, Accuracy = 1.0\n",
      "Iter #563200:  Learning rate = 0.000082:  Batch Loss = 1.616457, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6187940835952759, Accuracy = 1.0\n",
      "Iter #563520:  Learning rate = 0.000082:  Batch Loss = 1.614546, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6408783197402954, Accuracy = 0.9833333492279053\n",
      "Iter #563840:  Learning rate = 0.000082:  Batch Loss = 1.612871, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6144436597824097, Accuracy = 1.0\n",
      "Iter #564160:  Learning rate = 0.000082:  Batch Loss = 1.614513, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6243443489074707, Accuracy = 1.0\n",
      "Iter #564480:  Learning rate = 0.000082:  Batch Loss = 1.623997, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7056198120117188, Accuracy = 0.949999988079071\n",
      "Iter #564800:  Learning rate = 0.000082:  Batch Loss = 1.610916, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6259959936141968, Accuracy = 1.0\n",
      "Iter #565120:  Learning rate = 0.000082:  Batch Loss = 1.610597, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6347064971923828, Accuracy = 0.9833333492279053\n",
      "Iter #565440:  Learning rate = 0.000082:  Batch Loss = 1.629044, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6262329816818237, Accuracy = 1.0\n",
      "Iter #565760:  Learning rate = 0.000082:  Batch Loss = 1.607962, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.648154377937317, Accuracy = 0.9666666388511658\n",
      "Iter #566080:  Learning rate = 0.000082:  Batch Loss = 1.606453, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.658971905708313, Accuracy = 1.0\n",
      "Iter #566400:  Learning rate = 0.000082:  Batch Loss = 1.607463, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6121368408203125, Accuracy = 1.0\n",
      "Iter #566720:  Learning rate = 0.000082:  Batch Loss = 1.605907, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.698168158531189, Accuracy = 0.9666666388511658\n",
      "Iter #567040:  Learning rate = 0.000082:  Batch Loss = 1.603879, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6390230655670166, Accuracy = 0.9666666388511658\n",
      "Iter #567360:  Learning rate = 0.000082:  Batch Loss = 1.603865, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6356086730957031, Accuracy = 0.9666666388511658\n",
      "Iter #567680:  Learning rate = 0.000082:  Batch Loss = 1.605109, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6345901489257812, Accuracy = 0.9833333492279053\n",
      "Iter #568000:  Learning rate = 0.000082:  Batch Loss = 1.601639, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6248666048049927, Accuracy = 1.0\n",
      "Iter #568320:  Learning rate = 0.000082:  Batch Loss = 1.599721, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6331212520599365, Accuracy = 0.9833333492279053\n",
      "Iter #568640:  Learning rate = 0.000082:  Batch Loss = 1.598731, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.605619192123413, Accuracy = 1.0\n",
      "Iter #568960:  Learning rate = 0.000082:  Batch Loss = 1.602825, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.8499046564102173, Accuracy = 0.8833333253860474\n",
      "Iter #569280:  Learning rate = 0.000082:  Batch Loss = 1.596946, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6835877895355225, Accuracy = 0.949999988079071\n",
      "Iter #569600:  Learning rate = 0.000082:  Batch Loss = 1.600583, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.621817708015442, Accuracy = 1.0\n",
      "Iter #569920:  Learning rate = 0.000082:  Batch Loss = 1.599681, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6232749223709106, Accuracy = 1.0\n",
      "Iter #570240:  Learning rate = 0.000082:  Batch Loss = 1.595128, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6306047439575195, Accuracy = 0.9666666388511658\n",
      "Iter #570560:  Learning rate = 0.000082:  Batch Loss = 1.595900, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.639363408088684, Accuracy = 0.9666666388511658\n",
      "Iter #570880:  Learning rate = 0.000082:  Batch Loss = 1.592168, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6203866004943848, Accuracy = 0.9833333492279053\n",
      "Iter #571200:  Learning rate = 0.000082:  Batch Loss = 1.590739, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.615097999572754, Accuracy = 1.0\n",
      "Iter #571520:  Learning rate = 0.000082:  Batch Loss = 1.589554, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6009790897369385, Accuracy = 1.0\n",
      "Iter #571840:  Learning rate = 0.000082:  Batch Loss = 1.588779, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6287540197372437, Accuracy = 0.9666666388511658\n",
      "Iter #572160:  Learning rate = 0.000082:  Batch Loss = 1.592461, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.61951744556427, Accuracy = 0.9666666388511658\n",
      "Iter #572480:  Learning rate = 0.000082:  Batch Loss = 1.586571, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.607871651649475, Accuracy = 1.0\n",
      "Iter #572800:  Learning rate = 0.000082:  Batch Loss = 1.585135, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5978727340698242, Accuracy = 1.0\n",
      "Iter #573120:  Learning rate = 0.000082:  Batch Loss = 1.585769, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6040366888046265, Accuracy = 1.0\n",
      "Iter #573440:  Learning rate = 0.000082:  Batch Loss = 1.584330, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5987448692321777, Accuracy = 1.0\n",
      "Iter #573760:  Learning rate = 0.000082:  Batch Loss = 1.582094, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6046972274780273, Accuracy = 1.0\n",
      "Iter #574080:  Learning rate = 0.000082:  Batch Loss = 1.581273, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6003528833389282, Accuracy = 1.0\n",
      "Iter #574400:  Learning rate = 0.000082:  Batch Loss = 1.579774, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5902312994003296, Accuracy = 1.0\n",
      "Iter #574720:  Learning rate = 0.000082:  Batch Loss = 1.579230, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5816066265106201, Accuracy = 1.0\n",
      "Iter #575040:  Learning rate = 0.000082:  Batch Loss = 1.577291, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5777300596237183, Accuracy = 1.0\n",
      "Iter #575360:  Learning rate = 0.000082:  Batch Loss = 1.575896, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5780372619628906, Accuracy = 1.0\n",
      "Iter #575680:  Learning rate = 0.000082:  Batch Loss = 1.580029, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6005759239196777, Accuracy = 1.0\n",
      "Iter #576000:  Learning rate = 0.000082:  Batch Loss = 1.574401, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.583791971206665, Accuracy = 1.0\n",
      "Iter #576320:  Learning rate = 0.000082:  Batch Loss = 1.573291, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.633739709854126, Accuracy = 0.9666666388511658\n",
      "Iter #576640:  Learning rate = 0.000082:  Batch Loss = 1.572076, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5810976028442383, Accuracy = 1.0\n",
      "Iter #576960:  Learning rate = 0.000082:  Batch Loss = 1.608088, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.701772689819336, Accuracy = 0.949999988079071\n",
      "Iter #577280:  Learning rate = 0.000082:  Batch Loss = 1.570145, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6069226264953613, Accuracy = 0.9666666388511658\n",
      "Iter #577600:  Learning rate = 0.000082:  Batch Loss = 1.569055, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5721062421798706, Accuracy = 1.0\n",
      "Iter #577920:  Learning rate = 0.000082:  Batch Loss = 1.567920, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6520564556121826, Accuracy = 0.949999988079071\n",
      "Iter #578240:  Learning rate = 0.000082:  Batch Loss = 1.566713, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.592018961906433, Accuracy = 1.0\n",
      "Iter #578560:  Learning rate = 0.000082:  Batch Loss = 1.567010, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5796741247177124, Accuracy = 1.0\n",
      "Iter #578880:  Learning rate = 0.000082:  Batch Loss = 1.566391, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5707393884658813, Accuracy = 1.0\n",
      "Iter #579200:  Learning rate = 0.000082:  Batch Loss = 1.564317, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6833603382110596, Accuracy = 0.949999988079071\n",
      "Iter #579520:  Learning rate = 0.000082:  Batch Loss = 1.563519, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6419261693954468, Accuracy = 0.9666666388511658\n",
      "Iter #579840:  Learning rate = 0.000082:  Batch Loss = 1.561280, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5912559032440186, Accuracy = 0.9833333492279053\n",
      "Iter #580160:  Learning rate = 0.000082:  Batch Loss = 1.564098, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5806119441986084, Accuracy = 1.0\n",
      "Iter #580480:  Learning rate = 0.000082:  Batch Loss = 1.559811, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5879350900650024, Accuracy = 1.0\n",
      "Iter #580800:  Learning rate = 0.000082:  Batch Loss = 1.558743, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5853508710861206, Accuracy = 0.9833333492279053\n",
      "Iter #581120:  Learning rate = 0.000082:  Batch Loss = 1.559602, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.56026029586792, Accuracy = 1.0\n",
      "Iter #581440:  Learning rate = 0.000082:  Batch Loss = 1.802701, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5591999292373657, Accuracy = 1.0\n",
      "Iter #581760:  Learning rate = 0.000082:  Batch Loss = 1.557512, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5594282150268555, Accuracy = 1.0\n",
      "Iter #582080:  Learning rate = 0.000082:  Batch Loss = 1.560032, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5929374694824219, Accuracy = 1.0\n",
      "Iter #582400:  Learning rate = 0.000082:  Batch Loss = 1.556568, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6061149835586548, Accuracy = 0.9666666388511658\n",
      "Iter #582720:  Learning rate = 0.000082:  Batch Loss = 1.552600, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6031559705734253, Accuracy = 0.9666666388511658\n",
      "Iter #583040:  Learning rate = 0.000082:  Batch Loss = 1.557129, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5914138555526733, Accuracy = 0.9833333492279053\n",
      "Iter #583360:  Learning rate = 0.000082:  Batch Loss = 1.553882, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5680623054504395, Accuracy = 1.0\n",
      "Iter #583680:  Learning rate = 0.000082:  Batch Loss = 1.554305, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5855780839920044, Accuracy = 0.9833333492279053\n",
      "Iter #584000:  Learning rate = 0.000082:  Batch Loss = 1.548255, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5711612701416016, Accuracy = 1.0\n",
      "Iter #584320:  Learning rate = 0.000082:  Batch Loss = 1.546866, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5611990690231323, Accuracy = 1.0\n",
      "Iter #584640:  Learning rate = 0.000082:  Batch Loss = 1.548909, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5572372674942017, Accuracy = 1.0\n",
      "Iter #584960:  Learning rate = 0.000082:  Batch Loss = 1.551457, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5727595090866089, Accuracy = 0.9833333492279053\n",
      "Iter #585280:  Learning rate = 0.000082:  Batch Loss = 1.545141, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5526753664016724, Accuracy = 1.0\n",
      "Iter #585600:  Learning rate = 0.000082:  Batch Loss = 1.548406, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6190398931503296, Accuracy = 0.9666666388511658\n",
      "Iter #585920:  Learning rate = 0.000082:  Batch Loss = 1.561420, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5702372789382935, Accuracy = 1.0\n",
      "Iter #586240:  Learning rate = 0.000082:  Batch Loss = 1.551794, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6669392585754395, Accuracy = 0.9166666865348816\n",
      "Iter #586560:  Learning rate = 0.000082:  Batch Loss = 1.540169, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5452229976654053, Accuracy = 1.0\n",
      "Iter #586880:  Learning rate = 0.000082:  Batch Loss = 1.557640, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5849077701568604, Accuracy = 0.9666666388511658\n",
      "Iter #587200:  Learning rate = 0.000082:  Batch Loss = 1.538373, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6516708135604858, Accuracy = 0.949999988079071\n",
      "Iter #587520:  Learning rate = 0.000082:  Batch Loss = 1.537377, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.555935025215149, Accuracy = 1.0\n",
      "Iter #587840:  Learning rate = 0.000082:  Batch Loss = 1.536556, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5774199962615967, Accuracy = 0.9666666388511658\n",
      "Iter #588160:  Learning rate = 0.000082:  Batch Loss = 1.535689, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5516784191131592, Accuracy = 1.0\n",
      "Iter #588480:  Learning rate = 0.000082:  Batch Loss = 1.535885, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5436573028564453, Accuracy = 1.0\n",
      "Iter #588800:  Learning rate = 0.000082:  Batch Loss = 1.537700, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6246581077575684, Accuracy = 0.949999988079071\n",
      "Iter #589120:  Learning rate = 0.000082:  Batch Loss = 1.532036, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5405312776565552, Accuracy = 1.0\n",
      "Iter #589440:  Learning rate = 0.000082:  Batch Loss = 1.532072, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.535235047340393, Accuracy = 1.0\n",
      "Iter #589760:  Learning rate = 0.000082:  Batch Loss = 1.530095, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5682733058929443, Accuracy = 0.9666666388511658\n",
      "Iter #590080:  Learning rate = 0.000082:  Batch Loss = 1.529426, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.553609848022461, Accuracy = 1.0\n",
      "Iter #590400:  Learning rate = 0.000082:  Batch Loss = 1.532572, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5397701263427734, Accuracy = 1.0\n",
      "Iter #590720:  Learning rate = 0.000082:  Batch Loss = 1.526671, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.54306161403656, Accuracy = 1.0\n",
      "Iter #591040:  Learning rate = 0.000082:  Batch Loss = 1.525656, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5508860349655151, Accuracy = 1.0\n",
      "Iter #591360:  Learning rate = 0.000082:  Batch Loss = 1.525176, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5272129774093628, Accuracy = 1.0\n",
      "Iter #591680:  Learning rate = 0.000082:  Batch Loss = 1.526090, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5441298484802246, Accuracy = 1.0\n",
      "Iter #592000:  Learning rate = 0.000082:  Batch Loss = 1.522523, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5238312482833862, Accuracy = 1.0\n",
      "Iter #592320:  Learning rate = 0.000082:  Batch Loss = 1.522327, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5408505201339722, Accuracy = 1.0\n",
      "Iter #592640:  Learning rate = 0.000082:  Batch Loss = 1.521060, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5661990642547607, Accuracy = 0.9666666388511658\n",
      "Iter #592960:  Learning rate = 0.000082:  Batch Loss = 1.521787, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5477254390716553, Accuracy = 1.0\n",
      "Iter #593280:  Learning rate = 0.000082:  Batch Loss = 1.520500, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5487713813781738, Accuracy = 0.9833333492279053\n",
      "Iter #593600:  Learning rate = 0.000082:  Batch Loss = 1.517450, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5507463216781616, Accuracy = 0.9666666388511658\n",
      "Iter #593920:  Learning rate = 0.000082:  Batch Loss = 1.516795, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.535272240638733, Accuracy = 1.0\n",
      "Iter #594240:  Learning rate = 0.000082:  Batch Loss = 1.515007, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5282304286956787, Accuracy = 1.0\n",
      "Iter #594560:  Learning rate = 0.000082:  Batch Loss = 1.517317, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.549302339553833, Accuracy = 0.9666666388511658\n",
      "Iter #594880:  Learning rate = 0.000082:  Batch Loss = 1.523380, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5336320400238037, Accuracy = 1.0\n",
      "Iter #595200:  Learning rate = 0.000082:  Batch Loss = 1.512339, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5496433973312378, Accuracy = 0.9833333492279053\n",
      "Iter #595520:  Learning rate = 0.000082:  Batch Loss = 1.510805, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5130960941314697, Accuracy = 1.0\n",
      "Iter #595840:  Learning rate = 0.000082:  Batch Loss = 1.509820, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5239943265914917, Accuracy = 1.0\n",
      "Iter #596160:  Learning rate = 0.000082:  Batch Loss = 1.508937, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5136512517929077, Accuracy = 1.0\n",
      "Iter #596480:  Learning rate = 0.000082:  Batch Loss = 1.508396, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5991315841674805, Accuracy = 0.949999988079071\n",
      "Iter #596800:  Learning rate = 0.000082:  Batch Loss = 1.506328, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5343563556671143, Accuracy = 1.0\n",
      "Iter #597120:  Learning rate = 0.000082:  Batch Loss = 1.507803, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5332450866699219, Accuracy = 1.0\n",
      "Iter #597440:  Learning rate = 0.000082:  Batch Loss = 1.505015, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5281981229782104, Accuracy = 1.0\n",
      "Iter #597760:  Learning rate = 0.000082:  Batch Loss = 1.503481, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5534719228744507, Accuracy = 1.0\n",
      "Iter #598080:  Learning rate = 0.000082:  Batch Loss = 1.504045, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5175626277923584, Accuracy = 1.0\n",
      "Iter #598400:  Learning rate = 0.000082:  Batch Loss = 1.501905, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6055043935775757, Accuracy = 0.949999988079071\n",
      "Iter #598720:  Learning rate = 0.000082:  Batch Loss = 1.501959, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5694655179977417, Accuracy = 0.9666666388511658\n",
      "Iter #599040:  Learning rate = 0.000082:  Batch Loss = 1.502041, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5093555450439453, Accuracy = 1.0\n",
      "Iter #599360:  Learning rate = 0.000082:  Batch Loss = 1.513017, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5979441404342651, Accuracy = 0.9666666388511658\n",
      "Iter #599680:  Learning rate = 0.000082:  Batch Loss = 1.497336, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5034881830215454, Accuracy = 1.0\n",
      "Iter #600000:  Learning rate = 0.000078:  Batch Loss = 1.498264, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.514049768447876, Accuracy = 1.0\n",
      "Iter #600320:  Learning rate = 0.000078:  Batch Loss = 1.501515, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5263967514038086, Accuracy = 0.9666666388511658\n",
      "Iter #600640:  Learning rate = 0.000078:  Batch Loss = 1.494673, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5123039484024048, Accuracy = 1.0\n",
      "Iter #600960:  Learning rate = 0.000078:  Batch Loss = 1.492728, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5004425048828125, Accuracy = 1.0\n",
      "Iter #601280:  Learning rate = 0.000078:  Batch Loss = 1.491957, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5698813199996948, Accuracy = 0.9666666388511658\n",
      "Iter #601600:  Learning rate = 0.000078:  Batch Loss = 1.491433, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.496138095855713, Accuracy = 1.0\n",
      "Iter #601920:  Learning rate = 0.000078:  Batch Loss = 1.491239, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4951132535934448, Accuracy = 1.0\n",
      "Iter #602240:  Learning rate = 0.000078:  Batch Loss = 1.496121, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6120887994766235, Accuracy = 0.949999988079071\n",
      "Iter #602560:  Learning rate = 0.000078:  Batch Loss = 1.487899, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5256668329238892, Accuracy = 0.9666666388511658\n",
      "Iter #602880:  Learning rate = 0.000078:  Batch Loss = 1.616683, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.63739013671875, Accuracy = 0.9166666865348816\n",
      "Iter #603200:  Learning rate = 0.000078:  Batch Loss = 1.493840, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5381039381027222, Accuracy = 0.9666666388511658\n",
      "Iter #603520:  Learning rate = 0.000078:  Batch Loss = 1.522959, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5585943460464478, Accuracy = 0.9666666388511658\n",
      "Iter #603840:  Learning rate = 0.000078:  Batch Loss = 1.485856, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5007644891738892, Accuracy = 1.0\n",
      "Iter #604160:  Learning rate = 0.000078:  Batch Loss = 1.485521, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5251374244689941, Accuracy = 0.9666666388511658\n",
      "Iter #604480:  Learning rate = 0.000078:  Batch Loss = 1.482289, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4920958280563354, Accuracy = 1.0\n",
      "Iter #604800:  Learning rate = 0.000078:  Batch Loss = 1.500435, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5676897764205933, Accuracy = 0.9666666388511658\n",
      "Iter #605120:  Learning rate = 0.000078:  Batch Loss = 1.480168, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5126210451126099, Accuracy = 0.9833333492279053\n",
      "Iter #605440:  Learning rate = 0.000078:  Batch Loss = 1.867074, Accuracy = 0.8125\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6726555824279785, Accuracy = 0.8833333253860474\n",
      "Iter #605760:  Learning rate = 0.000078:  Batch Loss = 1.484758, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4887070655822754, Accuracy = 1.0\n",
      "Iter #606080:  Learning rate = 0.000078:  Batch Loss = 1.480475, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4827048778533936, Accuracy = 1.0\n",
      "Iter #606400:  Learning rate = 0.000078:  Batch Loss = 1.479676, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4828304052352905, Accuracy = 1.0\n",
      "Iter #606720:  Learning rate = 0.000078:  Batch Loss = 1.481928, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4835338592529297, Accuracy = 1.0\n",
      "Iter #607040:  Learning rate = 0.000078:  Batch Loss = 1.480850, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4856914281845093, Accuracy = 1.0\n",
      "Iter #607360:  Learning rate = 0.000078:  Batch Loss = 1.483399, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5002071857452393, Accuracy = 1.0\n",
      "Iter #607680:  Learning rate = 0.000078:  Batch Loss = 1.479181, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.512256145477295, Accuracy = 0.9666666388511658\n",
      "Iter #608000:  Learning rate = 0.000078:  Batch Loss = 1.475474, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5093215703964233, Accuracy = 1.0\n",
      "Iter #608320:  Learning rate = 0.000078:  Batch Loss = 1.476490, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4837874174118042, Accuracy = 1.0\n",
      "Iter #608640:  Learning rate = 0.000078:  Batch Loss = 1.475741, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4853332042694092, Accuracy = 1.0\n",
      "Iter #608960:  Learning rate = 0.000078:  Batch Loss = 1.473901, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5169917345046997, Accuracy = 0.9666666388511658\n",
      "Iter #609280:  Learning rate = 0.000078:  Batch Loss = 1.475528, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4865460395812988, Accuracy = 1.0\n",
      "Iter #609600:  Learning rate = 0.000078:  Batch Loss = 1.475009, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4891088008880615, Accuracy = 1.0\n",
      "Iter #609920:  Learning rate = 0.000078:  Batch Loss = 1.472764, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4840179681777954, Accuracy = 1.0\n",
      "Iter #610240:  Learning rate = 0.000078:  Batch Loss = 1.473011, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4912176132202148, Accuracy = 1.0\n",
      "Iter #610560:  Learning rate = 0.000078:  Batch Loss = 1.471379, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.478758454322815, Accuracy = 1.0\n",
      "Iter #610880:  Learning rate = 0.000078:  Batch Loss = 1.471073, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4838932752609253, Accuracy = 1.0\n",
      "Iter #611200:  Learning rate = 0.000078:  Batch Loss = 1.476388, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4881290197372437, Accuracy = 1.0\n",
      "Iter #611520:  Learning rate = 0.000078:  Batch Loss = 1.470874, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4782562255859375, Accuracy = 1.0\n",
      "Iter #611840:  Learning rate = 0.000078:  Batch Loss = 1.470414, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4817001819610596, Accuracy = 1.0\n",
      "Iter #612160:  Learning rate = 0.000078:  Batch Loss = 1.475449, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4794729948043823, Accuracy = 1.0\n",
      "Iter #612480:  Learning rate = 0.000078:  Batch Loss = 1.469221, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4787086248397827, Accuracy = 1.0\n",
      "Iter #612800:  Learning rate = 0.000078:  Batch Loss = 1.467912, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.497923731803894, Accuracy = 0.9833333492279053\n",
      "Iter #613120:  Learning rate = 0.000078:  Batch Loss = 1.466431, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4754953384399414, Accuracy = 1.0\n",
      "Iter #613440:  Learning rate = 0.000078:  Batch Loss = 1.469490, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4823777675628662, Accuracy = 1.0\n",
      "Iter #613760:  Learning rate = 0.000078:  Batch Loss = 1.465569, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4771536588668823, Accuracy = 1.0\n",
      "Iter #614080:  Learning rate = 0.000078:  Batch Loss = 1.470942, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.484379768371582, Accuracy = 1.0\n",
      "Iter #614400:  Learning rate = 0.000078:  Batch Loss = 1.464204, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4726499319076538, Accuracy = 1.0\n",
      "Iter #614720:  Learning rate = 0.000078:  Batch Loss = 1.463675, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4798604249954224, Accuracy = 1.0\n",
      "Iter #615040:  Learning rate = 0.000078:  Batch Loss = 1.463467, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4747190475463867, Accuracy = 1.0\n",
      "Iter #615360:  Learning rate = 0.000078:  Batch Loss = 1.462508, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4715185165405273, Accuracy = 1.0\n",
      "Iter #615680:  Learning rate = 0.000078:  Batch Loss = 1.463877, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4701415300369263, Accuracy = 1.0\n",
      "Iter #616000:  Learning rate = 0.000078:  Batch Loss = 1.475756, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.469792366027832, Accuracy = 1.0\n",
      "Iter #616320:  Learning rate = 0.000078:  Batch Loss = 1.460740, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.479807734489441, Accuracy = 1.0\n",
      "Iter #616640:  Learning rate = 0.000078:  Batch Loss = 1.460680, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4673285484313965, Accuracy = 1.0\n",
      "Iter #616960:  Learning rate = 0.000078:  Batch Loss = 1.461951, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4657026529312134, Accuracy = 1.0\n",
      "Iter #617280:  Learning rate = 0.000078:  Batch Loss = 1.463673, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4672881364822388, Accuracy = 1.0\n",
      "Iter #617600:  Learning rate = 0.000078:  Batch Loss = 1.458955, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4827885627746582, Accuracy = 1.0\n",
      "Iter #617920:  Learning rate = 0.000078:  Batch Loss = 1.457372, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4621691703796387, Accuracy = 1.0\n",
      "Iter #618240:  Learning rate = 0.000078:  Batch Loss = 1.457235, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5117449760437012, Accuracy = 0.9666666388511658\n",
      "Iter #618560:  Learning rate = 0.000078:  Batch Loss = 1.456922, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4590094089508057, Accuracy = 1.0\n",
      "Iter #618880:  Learning rate = 0.000078:  Batch Loss = 1.458165, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5211912393569946, Accuracy = 0.9833333492279053\n",
      "Iter #619200:  Learning rate = 0.000078:  Batch Loss = 1.454629, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4724643230438232, Accuracy = 1.0\n",
      "Iter #619520:  Learning rate = 0.000078:  Batch Loss = 1.454381, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4637929201126099, Accuracy = 1.0\n",
      "Iter #619840:  Learning rate = 0.000078:  Batch Loss = 1.453905, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.570677399635315, Accuracy = 0.949999988079071\n",
      "Iter #620160:  Learning rate = 0.000078:  Batch Loss = 1.565900, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5330262184143066, Accuracy = 0.9666666388511658\n",
      "Iter #620480:  Learning rate = 0.000078:  Batch Loss = 1.451901, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4543235301971436, Accuracy = 1.0\n",
      "Iter #620800:  Learning rate = 0.000078:  Batch Loss = 1.451549, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5806785821914673, Accuracy = 0.949999988079071\n",
      "Iter #621120:  Learning rate = 0.000078:  Batch Loss = 1.452695, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.463494896888733, Accuracy = 1.0\n",
      "Iter #621440:  Learning rate = 0.000078:  Batch Loss = 1.450650, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5099536180496216, Accuracy = 0.9666666388511658\n",
      "Iter #621760:  Learning rate = 0.000078:  Batch Loss = 1.451997, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5477523803710938, Accuracy = 0.9666666388511658\n",
      "Iter #622080:  Learning rate = 0.000078:  Batch Loss = 1.459101, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4573463201522827, Accuracy = 1.0\n",
      "Iter #622400:  Learning rate = 0.000078:  Batch Loss = 1.448249, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4984803199768066, Accuracy = 0.9666666388511658\n",
      "Iter #622720:  Learning rate = 0.000078:  Batch Loss = 1.447587, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.468313217163086, Accuracy = 1.0\n",
      "Iter #623040:  Learning rate = 0.000078:  Batch Loss = 1.450593, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4620615243911743, Accuracy = 1.0\n",
      "Iter #623360:  Learning rate = 0.000078:  Batch Loss = 1.446193, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4605841636657715, Accuracy = 1.0\n",
      "Iter #623680:  Learning rate = 0.000078:  Batch Loss = 1.445864, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4709006547927856, Accuracy = 1.0\n",
      "Iter #624000:  Learning rate = 0.000078:  Batch Loss = 1.445509, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4624667167663574, Accuracy = 1.0\n",
      "Iter #624320:  Learning rate = 0.000078:  Batch Loss = 1.444172, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.489315152168274, Accuracy = 0.9833333492279053\n",
      "Iter #624640:  Learning rate = 0.000078:  Batch Loss = 1.445334, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4592186212539673, Accuracy = 1.0\n",
      "Iter #624960:  Learning rate = 0.000078:  Batch Loss = 1.443504, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.455376148223877, Accuracy = 1.0\n",
      "Iter #625280:  Learning rate = 0.000078:  Batch Loss = 1.443381, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4555132389068604, Accuracy = 1.0\n",
      "Iter #625600:  Learning rate = 0.000078:  Batch Loss = 1.441666, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4605669975280762, Accuracy = 1.0\n",
      "Iter #625920:  Learning rate = 0.000078:  Batch Loss = 1.440696, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.452616810798645, Accuracy = 1.0\n",
      "Iter #626240:  Learning rate = 0.000078:  Batch Loss = 1.440247, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4479739665985107, Accuracy = 1.0\n",
      "Iter #626560:  Learning rate = 0.000078:  Batch Loss = 1.439315, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4525095224380493, Accuracy = 1.0\n",
      "Iter #626880:  Learning rate = 0.000078:  Batch Loss = 1.438674, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4572389125823975, Accuracy = 1.0\n",
      "Iter #627200:  Learning rate = 0.000078:  Batch Loss = 1.438474, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4464043378829956, Accuracy = 1.0\n",
      "Iter #627520:  Learning rate = 0.000078:  Batch Loss = 1.439601, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4540364742279053, Accuracy = 1.0\n",
      "Iter #627840:  Learning rate = 0.000078:  Batch Loss = 1.437618, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.449670672416687, Accuracy = 1.0\n",
      "Iter #628160:  Learning rate = 0.000078:  Batch Loss = 1.436410, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4671025276184082, Accuracy = 0.9666666388511658\n",
      "Iter #628480:  Learning rate = 0.000078:  Batch Loss = 1.434896, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.438330054283142, Accuracy = 1.0\n",
      "Iter #628800:  Learning rate = 0.000078:  Batch Loss = 1.434519, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4517216682434082, Accuracy = 0.9833333492279053\n",
      "Iter #629120:  Learning rate = 0.000078:  Batch Loss = 1.434071, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4357166290283203, Accuracy = 1.0\n",
      "Iter #629440:  Learning rate = 0.000078:  Batch Loss = 1.432985, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.434424877166748, Accuracy = 1.0\n",
      "Iter #629760:  Learning rate = 0.000078:  Batch Loss = 1.431921, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4337494373321533, Accuracy = 1.0\n",
      "Iter #630080:  Learning rate = 0.000078:  Batch Loss = 1.431828, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.440210223197937, Accuracy = 1.0\n",
      "Iter #630400:  Learning rate = 0.000078:  Batch Loss = 1.432048, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4361885786056519, Accuracy = 1.0\n",
      "Iter #630720:  Learning rate = 0.000078:  Batch Loss = 1.434643, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4380773305892944, Accuracy = 1.0\n",
      "Iter #631040:  Learning rate = 0.000078:  Batch Loss = 1.429655, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.465877652168274, Accuracy = 0.9666666388511658\n",
      "Iter #631360:  Learning rate = 0.000078:  Batch Loss = 1.492735, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.478442907333374, Accuracy = 0.9833333492279053\n",
      "Iter #631680:  Learning rate = 0.000078:  Batch Loss = 1.427621, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4305479526519775, Accuracy = 1.0\n",
      "Iter #632000:  Learning rate = 0.000078:  Batch Loss = 1.427290, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4307987689971924, Accuracy = 1.0\n",
      "Iter #632320:  Learning rate = 0.000078:  Batch Loss = 1.438327, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4849841594696045, Accuracy = 0.9833333492279053\n",
      "Iter #632640:  Learning rate = 0.000078:  Batch Loss = 1.433421, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4749518632888794, Accuracy = 1.0\n",
      "Iter #632960:  Learning rate = 0.000078:  Batch Loss = 1.429409, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4473711252212524, Accuracy = 1.0\n",
      "Iter #633280:  Learning rate = 0.000078:  Batch Loss = 1.424193, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5072376728057861, Accuracy = 0.949999988079071\n",
      "Iter #633600:  Learning rate = 0.000078:  Batch Loss = 1.424926, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4279693365097046, Accuracy = 1.0\n",
      "Iter #633920:  Learning rate = 0.000078:  Batch Loss = 1.441174, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4722830057144165, Accuracy = 0.9833333492279053\n",
      "Iter #634240:  Learning rate = 0.000078:  Batch Loss = 1.423265, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.442132830619812, Accuracy = 1.0\n",
      "Iter #634560:  Learning rate = 0.000078:  Batch Loss = 1.421602, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4313859939575195, Accuracy = 1.0\n",
      "Iter #634880:  Learning rate = 0.000078:  Batch Loss = 1.421265, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4787788391113281, Accuracy = 0.9666666388511658\n",
      "Iter #635200:  Learning rate = 0.000078:  Batch Loss = 1.420175, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4280363321304321, Accuracy = 1.0\n",
      "Iter #635520:  Learning rate = 0.000078:  Batch Loss = 1.430265, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4418452978134155, Accuracy = 1.0\n",
      "Iter #635840:  Learning rate = 0.000078:  Batch Loss = 1.420277, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.432681918144226, Accuracy = 1.0\n",
      "Iter #636160:  Learning rate = 0.000078:  Batch Loss = 1.418941, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4349298477172852, Accuracy = 1.0\n",
      "Iter #636480:  Learning rate = 0.000078:  Batch Loss = 1.417705, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4443336725234985, Accuracy = 1.0\n",
      "Iter #636800:  Learning rate = 0.000078:  Batch Loss = 1.417894, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.431709885597229, Accuracy = 1.0\n",
      "Iter #637120:  Learning rate = 0.000078:  Batch Loss = 1.417466, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.428640604019165, Accuracy = 1.0\n",
      "Iter #637440:  Learning rate = 0.000078:  Batch Loss = 1.416040, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4267799854278564, Accuracy = 1.0\n",
      "Iter #637760:  Learning rate = 0.000078:  Batch Loss = 1.425796, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4386719465255737, Accuracy = 1.0\n",
      "Iter #638080:  Learning rate = 0.000078:  Batch Loss = 1.428510, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4230231046676636, Accuracy = 1.0\n",
      "Iter #638400:  Learning rate = 0.000078:  Batch Loss = 1.414252, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4265140295028687, Accuracy = 1.0\n",
      "Iter #638720:  Learning rate = 0.000078:  Batch Loss = 1.414304, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4386733770370483, Accuracy = 1.0\n",
      "Iter #639040:  Learning rate = 0.000078:  Batch Loss = 1.413731, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4201191663742065, Accuracy = 1.0\n",
      "Iter #639360:  Learning rate = 0.000078:  Batch Loss = 1.412687, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.419193983078003, Accuracy = 1.0\n",
      "Iter #639680:  Learning rate = 0.000078:  Batch Loss = 1.411167, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4577784538269043, Accuracy = 0.9666666388511658\n",
      "Iter #640000:  Learning rate = 0.000078:  Batch Loss = 1.409698, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4139665365219116, Accuracy = 1.0\n",
      "Iter #640320:  Learning rate = 0.000078:  Batch Loss = 1.408375, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5833714008331299, Accuracy = 0.9333333373069763\n",
      "Iter #640640:  Learning rate = 0.000078:  Batch Loss = 1.425254, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4240626096725464, Accuracy = 1.0\n",
      "Iter #640960:  Learning rate = 0.000078:  Batch Loss = 1.406686, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4086798429489136, Accuracy = 1.0\n",
      "Iter #641280:  Learning rate = 0.000078:  Batch Loss = 1.406665, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4546020030975342, Accuracy = 0.9666666388511658\n",
      "Iter #641600:  Learning rate = 0.000078:  Batch Loss = 1.409046, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.494209885597229, Accuracy = 0.9166666865348816\n",
      "Iter #641920:  Learning rate = 0.000078:  Batch Loss = 1.404154, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4365166425704956, Accuracy = 0.9666666388511658\n",
      "Iter #642240:  Learning rate = 0.000078:  Batch Loss = 1.404199, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4665899276733398, Accuracy = 0.9666666388511658\n",
      "Iter #642560:  Learning rate = 0.000078:  Batch Loss = 1.404048, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.416258692741394, Accuracy = 1.0\n",
      "Iter #642880:  Learning rate = 0.000078:  Batch Loss = 1.402268, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4250344038009644, Accuracy = 1.0\n",
      "Iter #643200:  Learning rate = 0.000078:  Batch Loss = 1.402626, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4088995456695557, Accuracy = 1.0\n",
      "Iter #643520:  Learning rate = 0.000078:  Batch Loss = 1.401111, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.443333387374878, Accuracy = 0.9833333492279053\n",
      "Iter #643840:  Learning rate = 0.000078:  Batch Loss = 1.399610, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4079208374023438, Accuracy = 1.0\n",
      "Iter #644160:  Learning rate = 0.000078:  Batch Loss = 1.571998, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5026795864105225, Accuracy = 0.9333333373069763\n",
      "Iter #644480:  Learning rate = 0.000078:  Batch Loss = 1.398606, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4146329164505005, Accuracy = 1.0\n",
      "Iter #644800:  Learning rate = 0.000078:  Batch Loss = 1.397326, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.404459834098816, Accuracy = 1.0\n",
      "Iter #645120:  Learning rate = 0.000078:  Batch Loss = 1.397649, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.419472336769104, Accuracy = 1.0\n",
      "Iter #645440:  Learning rate = 0.000078:  Batch Loss = 1.399181, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.419476866722107, Accuracy = 1.0\n",
      "Iter #645760:  Learning rate = 0.000078:  Batch Loss = 1.395784, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5085232257843018, Accuracy = 0.9666666388511658\n",
      "Iter #646080:  Learning rate = 0.000078:  Batch Loss = 1.394773, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4020116329193115, Accuracy = 1.0\n",
      "Iter #646400:  Learning rate = 0.000078:  Batch Loss = 1.393658, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4029347896575928, Accuracy = 1.0\n",
      "Iter #646720:  Learning rate = 0.000078:  Batch Loss = 1.393839, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4047725200653076, Accuracy = 1.0\n",
      "Iter #647040:  Learning rate = 0.000078:  Batch Loss = 1.391968, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4073320627212524, Accuracy = 1.0\n",
      "Iter #647360:  Learning rate = 0.000078:  Batch Loss = 1.392361, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4032843112945557, Accuracy = 1.0\n",
      "Iter #647680:  Learning rate = 0.000078:  Batch Loss = 1.391802, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.406001329421997, Accuracy = 1.0\n",
      "Iter #648000:  Learning rate = 0.000078:  Batch Loss = 1.390241, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4024336338043213, Accuracy = 1.0\n",
      "Iter #648320:  Learning rate = 0.000078:  Batch Loss = 1.394654, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.42875337600708, Accuracy = 0.9666666388511658\n",
      "Iter #648640:  Learning rate = 0.000078:  Batch Loss = 1.388059, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3919886350631714, Accuracy = 1.0\n",
      "Iter #648960:  Learning rate = 0.000078:  Batch Loss = 1.388071, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.391895055770874, Accuracy = 1.0\n",
      "Iter #649280:  Learning rate = 0.000078:  Batch Loss = 1.404851, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.7453070878982544, Accuracy = 0.8666666746139526\n",
      "Iter #649600:  Learning rate = 0.000078:  Batch Loss = 1.388087, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.394594430923462, Accuracy = 1.0\n",
      "Iter #649920:  Learning rate = 0.000078:  Batch Loss = 1.385468, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3865220546722412, Accuracy = 1.0\n",
      "Iter #650240:  Learning rate = 0.000078:  Batch Loss = 1.387353, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4353177547454834, Accuracy = 0.9666666388511658\n",
      "Iter #650560:  Learning rate = 0.000078:  Batch Loss = 1.387511, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3978017568588257, Accuracy = 1.0\n",
      "Iter #650880:  Learning rate = 0.000078:  Batch Loss = 1.384244, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.399294137954712, Accuracy = 1.0\n",
      "Iter #651200:  Learning rate = 0.000078:  Batch Loss = 1.385431, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.397853136062622, Accuracy = 1.0\n",
      "Iter #651520:  Learning rate = 0.000078:  Batch Loss = 1.383562, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3996539115905762, Accuracy = 1.0\n",
      "Iter #651840:  Learning rate = 0.000078:  Batch Loss = 1.382904, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3928277492523193, Accuracy = 1.0\n",
      "Iter #652160:  Learning rate = 0.000078:  Batch Loss = 1.384197, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.418907642364502, Accuracy = 0.9833333492279053\n",
      "Iter #652480:  Learning rate = 0.000078:  Batch Loss = 1.384772, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3946971893310547, Accuracy = 1.0\n",
      "Iter #652800:  Learning rate = 0.000078:  Batch Loss = 1.381389, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3900184631347656, Accuracy = 1.0\n",
      "Iter #653120:  Learning rate = 0.000078:  Batch Loss = 1.381278, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3946568965911865, Accuracy = 1.0\n",
      "Iter #653440:  Learning rate = 0.000078:  Batch Loss = 1.380462, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3981828689575195, Accuracy = 1.0\n",
      "Iter #653760:  Learning rate = 0.000078:  Batch Loss = 1.385604, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3967194557189941, Accuracy = 1.0\n",
      "Iter #654080:  Learning rate = 0.000078:  Batch Loss = 1.379736, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3867809772491455, Accuracy = 1.0\n",
      "Iter #654400:  Learning rate = 0.000078:  Batch Loss = 1.379381, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3916972875595093, Accuracy = 1.0\n",
      "Iter #654720:  Learning rate = 0.000078:  Batch Loss = 1.382154, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4171689748764038, Accuracy = 0.9666666388511658\n",
      "Iter #655040:  Learning rate = 0.000078:  Batch Loss = 1.378041, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.444986343383789, Accuracy = 0.9666666388511658\n",
      "Iter #655360:  Learning rate = 0.000078:  Batch Loss = 1.377073, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.421424388885498, Accuracy = 0.9666666388511658\n",
      "Iter #655680:  Learning rate = 0.000078:  Batch Loss = 1.378465, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3822354078292847, Accuracy = 1.0\n",
      "Iter #656000:  Learning rate = 0.000078:  Batch Loss = 1.376568, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.378584384918213, Accuracy = 1.0\n",
      "Iter #656320:  Learning rate = 0.000078:  Batch Loss = 1.375655, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3989439010620117, Accuracy = 1.0\n",
      "Iter #656640:  Learning rate = 0.000078:  Batch Loss = 1.374795, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.386952519416809, Accuracy = 1.0\n",
      "Iter #656960:  Learning rate = 0.000078:  Batch Loss = 1.387041, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4788501262664795, Accuracy = 0.9333333373069763\n",
      "Iter #657280:  Learning rate = 0.000078:  Batch Loss = 1.375036, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3784550428390503, Accuracy = 1.0\n",
      "Iter #657600:  Learning rate = 0.000078:  Batch Loss = 1.374416, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3763338327407837, Accuracy = 1.0\n",
      "Iter #657920:  Learning rate = 0.000078:  Batch Loss = 1.373693, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6184059381484985, Accuracy = 0.8833333253860474\n",
      "Iter #658240:  Learning rate = 0.000078:  Batch Loss = 1.375149, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4723178148269653, Accuracy = 0.9166666865348816\n",
      "Iter #658560:  Learning rate = 0.000078:  Batch Loss = 1.372980, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.384737253189087, Accuracy = 1.0\n",
      "Iter #658880:  Learning rate = 0.000078:  Batch Loss = 1.379353, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4360579252243042, Accuracy = 0.9666666388511658\n",
      "Iter #659200:  Learning rate = 0.000078:  Batch Loss = 1.372324, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3971401453018188, Accuracy = 1.0\n",
      "Iter #659520:  Learning rate = 0.000078:  Batch Loss = 1.370957, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.390275239944458, Accuracy = 1.0\n",
      "Iter #659840:  Learning rate = 0.000078:  Batch Loss = 1.371265, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3890845775604248, Accuracy = 1.0\n",
      "Iter #660160:  Learning rate = 0.000078:  Batch Loss = 1.371295, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3919233083724976, Accuracy = 1.0\n",
      "Iter #660480:  Learning rate = 0.000078:  Batch Loss = 1.370402, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.387077808380127, Accuracy = 1.0\n",
      "Iter #660800:  Learning rate = 0.000078:  Batch Loss = 1.368901, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3865933418273926, Accuracy = 1.0\n",
      "Iter #661120:  Learning rate = 0.000078:  Batch Loss = 1.368261, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3839154243469238, Accuracy = 1.0\n",
      "Iter #661440:  Learning rate = 0.000078:  Batch Loss = 1.368301, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4092541933059692, Accuracy = 0.9833333492279053\n",
      "Iter #661760:  Learning rate = 0.000078:  Batch Loss = 1.367537, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3798006772994995, Accuracy = 1.0\n",
      "Iter #662080:  Learning rate = 0.000078:  Batch Loss = 1.367404, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3841112852096558, Accuracy = 1.0\n",
      "Iter #662400:  Learning rate = 0.000078:  Batch Loss = 1.367804, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3820334672927856, Accuracy = 1.0\n",
      "Iter #662720:  Learning rate = 0.000078:  Batch Loss = 1.366056, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3750848770141602, Accuracy = 1.0\n",
      "Iter #663040:  Learning rate = 0.000078:  Batch Loss = 1.366937, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3909119367599487, Accuracy = 1.0\n",
      "Iter #663360:  Learning rate = 0.000078:  Batch Loss = 1.365255, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3795937299728394, Accuracy = 1.0\n",
      "Iter #663680:  Learning rate = 0.000078:  Batch Loss = 1.364674, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3744806051254272, Accuracy = 1.0\n",
      "Iter #664000:  Learning rate = 0.000078:  Batch Loss = 1.364291, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.375909447669983, Accuracy = 1.0\n",
      "Iter #664320:  Learning rate = 0.000078:  Batch Loss = 1.363434, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3874893188476562, Accuracy = 1.0\n",
      "Iter #664640:  Learning rate = 0.000078:  Batch Loss = 1.363253, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3792632818222046, Accuracy = 1.0\n",
      "Iter #664960:  Learning rate = 0.000078:  Batch Loss = 1.364524, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3716048002243042, Accuracy = 1.0\n",
      "Iter #665280:  Learning rate = 0.000078:  Batch Loss = 1.361860, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3749537467956543, Accuracy = 1.0\n",
      "Iter #665600:  Learning rate = 0.000078:  Batch Loss = 1.361409, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.379845142364502, Accuracy = 1.0\n",
      "Iter #665920:  Learning rate = 0.000078:  Batch Loss = 1.361509, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3680520057678223, Accuracy = 1.0\n",
      "Iter #666240:  Learning rate = 0.000078:  Batch Loss = 1.369574, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3702927827835083, Accuracy = 1.0\n",
      "Iter #666560:  Learning rate = 0.000078:  Batch Loss = 1.360902, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3884180784225464, Accuracy = 1.0\n",
      "Iter #666880:  Learning rate = 0.000078:  Batch Loss = 1.359384, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3655250072479248, Accuracy = 1.0\n",
      "Iter #667200:  Learning rate = 0.000078:  Batch Loss = 1.361288, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3729524612426758, Accuracy = 1.0\n",
      "Iter #667520:  Learning rate = 0.000078:  Batch Loss = 1.357644, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.365904450416565, Accuracy = 1.0\n",
      "Iter #667840:  Learning rate = 0.000078:  Batch Loss = 1.357567, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3684711456298828, Accuracy = 1.0\n",
      "Iter #668160:  Learning rate = 0.000078:  Batch Loss = 1.357406, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.366923451423645, Accuracy = 1.0\n",
      "Iter #668480:  Learning rate = 0.000078:  Batch Loss = 1.356177, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3655790090560913, Accuracy = 1.0\n",
      "Iter #668800:  Learning rate = 0.000078:  Batch Loss = 1.356770, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3651334047317505, Accuracy = 1.0\n",
      "Iter #669120:  Learning rate = 0.000078:  Batch Loss = 1.355172, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3689770698547363, Accuracy = 1.0\n",
      "Iter #669440:  Learning rate = 0.000078:  Batch Loss = 1.355730, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3612747192382812, Accuracy = 1.0\n",
      "Iter #669760:  Learning rate = 0.000078:  Batch Loss = 1.354039, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3671355247497559, Accuracy = 1.0\n",
      "Iter #670080:  Learning rate = 0.000078:  Batch Loss = 1.352992, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3632744550704956, Accuracy = 1.0\n",
      "Iter #670400:  Learning rate = 0.000078:  Batch Loss = 1.358814, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3583632707595825, Accuracy = 1.0\n",
      "Iter #670720:  Learning rate = 0.000078:  Batch Loss = 1.352118, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3694779872894287, Accuracy = 1.0\n",
      "Iter #671040:  Learning rate = 0.000078:  Batch Loss = 1.351146, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3587546348571777, Accuracy = 1.0\n",
      "Iter #671360:  Learning rate = 0.000078:  Batch Loss = 1.351393, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3559871912002563, Accuracy = 1.0\n",
      "Iter #671680:  Learning rate = 0.000078:  Batch Loss = 1.350270, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.357240915298462, Accuracy = 1.0\n",
      "Iter #672000:  Learning rate = 0.000078:  Batch Loss = 1.349139, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.388988971710205, Accuracy = 0.9666666388511658\n",
      "Iter #672320:  Learning rate = 0.000078:  Batch Loss = 1.350374, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3566491603851318, Accuracy = 1.0\n",
      "Iter #672640:  Learning rate = 0.000078:  Batch Loss = 1.348498, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4651416540145874, Accuracy = 0.9333333373069763\n",
      "Iter #672960:  Learning rate = 0.000078:  Batch Loss = 1.347259, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3498568534851074, Accuracy = 1.0\n",
      "Iter #673280:  Learning rate = 0.000078:  Batch Loss = 1.348224, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.451808214187622, Accuracy = 0.9333333373069763\n",
      "Iter #673600:  Learning rate = 0.000078:  Batch Loss = 1.347478, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3492709398269653, Accuracy = 1.0\n",
      "Iter #673920:  Learning rate = 0.000078:  Batch Loss = 1.346408, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3489947319030762, Accuracy = 1.0\n",
      "Iter #674240:  Learning rate = 0.000078:  Batch Loss = 1.619394, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3491169214248657, Accuracy = 1.0\n",
      "Iter #674560:  Learning rate = 0.000078:  Batch Loss = 1.346487, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3509029150009155, Accuracy = 1.0\n",
      "Iter #674880:  Learning rate = 0.000078:  Batch Loss = 1.347254, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3544830083847046, Accuracy = 1.0\n",
      "Iter #675200:  Learning rate = 0.000078:  Batch Loss = 1.346955, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3528130054473877, Accuracy = 1.0\n",
      "Iter #675520:  Learning rate = 0.000078:  Batch Loss = 1.347695, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3540961742401123, Accuracy = 1.0\n",
      "Iter #675840:  Learning rate = 0.000078:  Batch Loss = 1.344581, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3596904277801514, Accuracy = 1.0\n",
      "Iter #676160:  Learning rate = 0.000078:  Batch Loss = 1.341508, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3727463483810425, Accuracy = 1.0\n",
      "Iter #676480:  Learning rate = 0.000078:  Batch Loss = 1.342549, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3967571258544922, Accuracy = 0.9666666388511658\n",
      "Iter #676800:  Learning rate = 0.000078:  Batch Loss = 1.342159, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3446611166000366, Accuracy = 1.0\n",
      "Iter #677120:  Learning rate = 0.000078:  Batch Loss = 1.339188, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3508620262145996, Accuracy = 1.0\n",
      "Iter #677440:  Learning rate = 0.000078:  Batch Loss = 1.342224, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3469973802566528, Accuracy = 1.0\n",
      "Iter #677760:  Learning rate = 0.000078:  Batch Loss = 1.342546, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3563636541366577, Accuracy = 1.0\n",
      "Iter #678080:  Learning rate = 0.000078:  Batch Loss = 1.347165, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3528571128845215, Accuracy = 1.0\n",
      "Iter #678400:  Learning rate = 0.000078:  Batch Loss = 1.336864, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3751072883605957, Accuracy = 1.0\n",
      "Iter #678720:  Learning rate = 0.000078:  Batch Loss = 1.337398, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3638458251953125, Accuracy = 1.0\n",
      "Iter #679040:  Learning rate = 0.000078:  Batch Loss = 1.347173, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3836020231246948, Accuracy = 1.0\n",
      "Iter #679360:  Learning rate = 0.000078:  Batch Loss = 1.436552, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3605519533157349, Accuracy = 1.0\n",
      "Iter #679680:  Learning rate = 0.000078:  Batch Loss = 1.379749, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4045339822769165, Accuracy = 0.9666666388511658\n",
      "Iter #680000:  Learning rate = 0.000078:  Batch Loss = 1.356741, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4089950323104858, Accuracy = 0.9666666388511658\n",
      "Iter #680320:  Learning rate = 0.000078:  Batch Loss = 1.336534, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3777366876602173, Accuracy = 0.9666666388511658\n",
      "Iter #680640:  Learning rate = 0.000078:  Batch Loss = 1.332668, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3582206964492798, Accuracy = 1.0\n",
      "Iter #680960:  Learning rate = 0.000078:  Batch Loss = 1.352234, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4000720977783203, Accuracy = 0.9833333492279053\n",
      "Iter #681280:  Learning rate = 0.000078:  Batch Loss = 1.331717, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3457934856414795, Accuracy = 1.0\n",
      "Iter #681600:  Learning rate = 0.000078:  Batch Loss = 1.334987, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4663522243499756, Accuracy = 0.8999999761581421\n",
      "Iter #681920:  Learning rate = 0.000078:  Batch Loss = 1.330489, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3392817974090576, Accuracy = 1.0\n",
      "Iter #682240:  Learning rate = 0.000078:  Batch Loss = 1.337538, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3538209199905396, Accuracy = 1.0\n",
      "Iter #682560:  Learning rate = 0.000078:  Batch Loss = 1.329435, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.362167239189148, Accuracy = 0.9833333492279053\n",
      "Iter #682880:  Learning rate = 0.000078:  Batch Loss = 1.333343, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3641034364700317, Accuracy = 0.9666666388511658\n",
      "Iter #683200:  Learning rate = 0.000078:  Batch Loss = 1.328290, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3765615224838257, Accuracy = 0.9666666388511658\n",
      "Iter #683520:  Learning rate = 0.000078:  Batch Loss = 1.328136, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3499958515167236, Accuracy = 1.0\n",
      "Iter #683840:  Learning rate = 0.000078:  Batch Loss = 1.326138, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.353409767150879, Accuracy = 1.0\n",
      "Iter #684160:  Learning rate = 0.000078:  Batch Loss = 1.328961, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3503081798553467, Accuracy = 1.0\n",
      "Iter #684480:  Learning rate = 0.000078:  Batch Loss = 1.327960, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3262112140655518, Accuracy = 1.0\n",
      "Iter #684800:  Learning rate = 0.000078:  Batch Loss = 1.325084, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3299320936203003, Accuracy = 1.0\n",
      "Iter #685120:  Learning rate = 0.000078:  Batch Loss = 1.324471, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4105674028396606, Accuracy = 0.9166666865348816\n",
      "Iter #685440:  Learning rate = 0.000078:  Batch Loss = 1.323284, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3385379314422607, Accuracy = 1.0\n",
      "Iter #685760:  Learning rate = 0.000078:  Batch Loss = 1.322268, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.424229383468628, Accuracy = 0.9666666388511658\n",
      "Iter #686080:  Learning rate = 0.000078:  Batch Loss = 1.322573, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.338415503501892, Accuracy = 1.0\n",
      "Iter #686400:  Learning rate = 0.000078:  Batch Loss = 1.321784, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.351588249206543, Accuracy = 1.0\n",
      "Iter #686720:  Learning rate = 0.000078:  Batch Loss = 1.321181, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3516356945037842, Accuracy = 0.9833333492279053\n",
      "Iter #687040:  Learning rate = 0.000078:  Batch Loss = 1.398693, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5496383905410767, Accuracy = 0.8833333253860474\n",
      "Iter #687360:  Learning rate = 0.000078:  Batch Loss = 1.318931, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3215581178665161, Accuracy = 1.0\n",
      "Iter #687680:  Learning rate = 0.000078:  Batch Loss = 1.318626, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.321605920791626, Accuracy = 1.0\n",
      "Iter #688000:  Learning rate = 0.000078:  Batch Loss = 1.317489, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.354324221611023, Accuracy = 1.0\n",
      "Iter #688320:  Learning rate = 0.000078:  Batch Loss = 1.317715, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3412411212921143, Accuracy = 1.0\n",
      "Iter #688640:  Learning rate = 0.000078:  Batch Loss = 1.317345, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3488576412200928, Accuracy = 1.0\n",
      "Iter #688960:  Learning rate = 0.000078:  Batch Loss = 1.316210, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3468841314315796, Accuracy = 0.9833333492279053\n",
      "Iter #689280:  Learning rate = 0.000078:  Batch Loss = 1.315336, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3555452823638916, Accuracy = 1.0\n",
      "Iter #689600:  Learning rate = 0.000078:  Batch Loss = 1.315121, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3490198850631714, Accuracy = 1.0\n",
      "Iter #689920:  Learning rate = 0.000078:  Batch Loss = 1.316140, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.332305669784546, Accuracy = 1.0\n",
      "Iter #690240:  Learning rate = 0.000078:  Batch Loss = 1.313324, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3806519508361816, Accuracy = 0.9833333492279053\n",
      "Iter #690560:  Learning rate = 0.000078:  Batch Loss = 1.312585, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3225473165512085, Accuracy = 1.0\n",
      "Iter #690880:  Learning rate = 0.000078:  Batch Loss = 1.312980, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4162448644638062, Accuracy = 0.9666666388511658\n",
      "Iter #691200:  Learning rate = 0.000078:  Batch Loss = 1.387752, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.47232985496521, Accuracy = 0.9333333373069763\n",
      "Iter #691520:  Learning rate = 0.000078:  Batch Loss = 1.311486, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3172872066497803, Accuracy = 1.0\n",
      "Iter #691840:  Learning rate = 0.000078:  Batch Loss = 1.392209, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.5923573970794678, Accuracy = 0.8666666746139526\n",
      "Iter #692160:  Learning rate = 0.000078:  Batch Loss = 1.310235, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3420617580413818, Accuracy = 0.9833333492279053\n",
      "Iter #692480:  Learning rate = 0.000078:  Batch Loss = 1.374877, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.446448802947998, Accuracy = 0.9333333373069763\n",
      "Iter #692800:  Learning rate = 0.000078:  Batch Loss = 1.311157, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3547779321670532, Accuracy = 0.9833333492279053\n",
      "Iter #693120:  Learning rate = 0.000078:  Batch Loss = 1.338140, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3877530097961426, Accuracy = 0.9666666388511658\n",
      "Iter #693440:  Learning rate = 0.000078:  Batch Loss = 1.308284, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3407726287841797, Accuracy = 0.9833333492279053\n",
      "Iter #693760:  Learning rate = 0.000078:  Batch Loss = 1.312556, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.339747428894043, Accuracy = 0.9833333492279053\n",
      "Iter #694080:  Learning rate = 0.000078:  Batch Loss = 1.308529, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3532615900039673, Accuracy = 0.9666666388511658\n",
      "Iter #694400:  Learning rate = 0.000078:  Batch Loss = 1.310276, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3410483598709106, Accuracy = 0.9833333492279053\n",
      "Iter #694720:  Learning rate = 0.000078:  Batch Loss = 1.306924, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3249385356903076, Accuracy = 1.0\n",
      "Iter #695040:  Learning rate = 0.000078:  Batch Loss = 1.312606, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3364616632461548, Accuracy = 0.9833333492279053\n",
      "Iter #695360:  Learning rate = 0.000078:  Batch Loss = 1.310244, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3174189329147339, Accuracy = 1.0\n",
      "Iter #695680:  Learning rate = 0.000078:  Batch Loss = 1.323794, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.337310791015625, Accuracy = 1.0\n",
      "Iter #696000:  Learning rate = 0.000078:  Batch Loss = 1.304243, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3155726194381714, Accuracy = 1.0\n",
      "Iter #696320:  Learning rate = 0.000078:  Batch Loss = 1.309290, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3632460832595825, Accuracy = 0.9666666388511658\n",
      "Iter #696640:  Learning rate = 0.000078:  Batch Loss = 1.303294, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3429845571517944, Accuracy = 0.9666666388511658\n",
      "Iter #696960:  Learning rate = 0.000078:  Batch Loss = 1.304111, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3167505264282227, Accuracy = 1.0\n",
      "Iter #697280:  Learning rate = 0.000078:  Batch Loss = 1.301868, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3448702096939087, Accuracy = 0.9833333492279053\n",
      "Iter #697600:  Learning rate = 0.000078:  Batch Loss = 1.302468, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3462717533111572, Accuracy = 0.9833333492279053\n",
      "Iter #697920:  Learning rate = 0.000078:  Batch Loss = 1.301130, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3136175870895386, Accuracy = 1.0\n",
      "Iter #698240:  Learning rate = 0.000078:  Batch Loss = 1.300260, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.33371102809906, Accuracy = 0.9833333492279053\n",
      "Iter #698560:  Learning rate = 0.000078:  Batch Loss = 1.300894, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3261148929595947, Accuracy = 1.0\n",
      "Iter #698880:  Learning rate = 0.000078:  Batch Loss = 1.340266, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4067810773849487, Accuracy = 0.949999988079071\n",
      "Iter #699200:  Learning rate = 0.000078:  Batch Loss = 1.301025, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3071963787078857, Accuracy = 1.0\n",
      "Iter #699520:  Learning rate = 0.000078:  Batch Loss = 1.298570, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.406772494316101, Accuracy = 0.949999988079071\n",
      "Iter #699840:  Learning rate = 0.000078:  Batch Loss = 1.310672, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3095014095306396, Accuracy = 1.0\n",
      "Iter #700160:  Learning rate = 0.000075:  Batch Loss = 1.297884, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3055039644241333, Accuracy = 1.0\n",
      "Iter #700480:  Learning rate = 0.000075:  Batch Loss = 1.302059, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3282067775726318, Accuracy = 1.0\n",
      "Iter #700800:  Learning rate = 0.000075:  Batch Loss = 1.298734, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3374855518341064, Accuracy = 0.9666666388511658\n",
      "Iter #701120:  Learning rate = 0.000075:  Batch Loss = 1.313175, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.306376576423645, Accuracy = 1.0\n",
      "Iter #701440:  Learning rate = 0.000075:  Batch Loss = 1.296070, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3042328357696533, Accuracy = 1.0\n",
      "Iter #701760:  Learning rate = 0.000075:  Batch Loss = 1.295768, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3021138906478882, Accuracy = 1.0\n",
      "Iter #702080:  Learning rate = 0.000075:  Batch Loss = 1.294608, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3057365417480469, Accuracy = 1.0\n",
      "Iter #702400:  Learning rate = 0.000075:  Batch Loss = 1.294709, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3219746351242065, Accuracy = 0.9833333492279053\n",
      "Iter #702720:  Learning rate = 0.000075:  Batch Loss = 1.300133, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3148776292800903, Accuracy = 1.0\n",
      "Iter #703040:  Learning rate = 0.000075:  Batch Loss = 1.296831, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3095660209655762, Accuracy = 1.0\n",
      "Iter #703360:  Learning rate = 0.000075:  Batch Loss = 1.294844, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3059072494506836, Accuracy = 1.0\n",
      "Iter #703680:  Learning rate = 0.000075:  Batch Loss = 1.292102, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.303422212600708, Accuracy = 1.0\n",
      "Iter #704000:  Learning rate = 0.000075:  Batch Loss = 1.291391, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3099100589752197, Accuracy = 1.0\n",
      "Iter #704320:  Learning rate = 0.000075:  Batch Loss = 1.295827, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3158645629882812, Accuracy = 1.0\n",
      "Iter #704640:  Learning rate = 0.000075:  Batch Loss = 1.290772, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3023077249526978, Accuracy = 1.0\n",
      "Iter #704960:  Learning rate = 0.000075:  Batch Loss = 1.289924, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2984585762023926, Accuracy = 1.0\n",
      "Iter #705280:  Learning rate = 0.000075:  Batch Loss = 1.293236, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.325155258178711, Accuracy = 0.9833333492279053\n",
      "Iter #705600:  Learning rate = 0.000075:  Batch Loss = 1.288700, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3013269901275635, Accuracy = 1.0\n",
      "Iter #705920:  Learning rate = 0.000075:  Batch Loss = 1.289239, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2998753786087036, Accuracy = 1.0\n",
      "Iter #706240:  Learning rate = 0.000075:  Batch Loss = 1.289727, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3033860921859741, Accuracy = 1.0\n",
      "Iter #706560:  Learning rate = 0.000075:  Batch Loss = 1.287821, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3008538484573364, Accuracy = 1.0\n",
      "Iter #706880:  Learning rate = 0.000075:  Batch Loss = 1.286608, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2978507280349731, Accuracy = 1.0\n",
      "Iter #707200:  Learning rate = 0.000075:  Batch Loss = 1.285793, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2963148355484009, Accuracy = 1.0\n",
      "Iter #707520:  Learning rate = 0.000075:  Batch Loss = 1.285285, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3006505966186523, Accuracy = 1.0\n",
      "Iter #707840:  Learning rate = 0.000075:  Batch Loss = 1.284824, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2976908683776855, Accuracy = 1.0\n",
      "Iter #708160:  Learning rate = 0.000075:  Batch Loss = 1.284251, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2932120561599731, Accuracy = 1.0\n",
      "Iter #708480:  Learning rate = 0.000075:  Batch Loss = 1.283429, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3020601272583008, Accuracy = 1.0\n",
      "Iter #708800:  Learning rate = 0.000075:  Batch Loss = 1.282669, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.289647102355957, Accuracy = 1.0\n",
      "Iter #709120:  Learning rate = 0.000075:  Batch Loss = 1.289978, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.286932349205017, Accuracy = 1.0\n",
      "Iter #709440:  Learning rate = 0.000075:  Batch Loss = 1.281923, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3282418251037598, Accuracy = 0.9666666388511658\n",
      "Iter #709760:  Learning rate = 0.000075:  Batch Loss = 1.285117, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3032584190368652, Accuracy = 1.0\n",
      "Iter #710080:  Learning rate = 0.000075:  Batch Loss = 1.280815, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.285275936126709, Accuracy = 1.0\n",
      "Iter #710400:  Learning rate = 0.000075:  Batch Loss = 1.280293, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.319122552871704, Accuracy = 0.9666666388511658\n",
      "Iter #710720:  Learning rate = 0.000075:  Batch Loss = 1.279761, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2832376956939697, Accuracy = 1.0\n",
      "Iter #711040:  Learning rate = 0.000075:  Batch Loss = 1.299332, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.366502285003662, Accuracy = 0.9666666388511658\n",
      "Iter #711360:  Learning rate = 0.000075:  Batch Loss = 1.279569, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4151638746261597, Accuracy = 0.949999988079071\n",
      "Iter #711680:  Learning rate = 0.000075:  Batch Loss = 1.279191, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3402482271194458, Accuracy = 0.9666666388511658\n",
      "Iter #712000:  Learning rate = 0.000075:  Batch Loss = 1.282865, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3616480827331543, Accuracy = 0.9166666865348816\n",
      "Iter #712320:  Learning rate = 0.000075:  Batch Loss = 1.276976, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3147203922271729, Accuracy = 0.9666666388511658\n",
      "Iter #712640:  Learning rate = 0.000075:  Batch Loss = 1.275710, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3620028495788574, Accuracy = 0.9166666865348816\n",
      "Iter #712960:  Learning rate = 0.000075:  Batch Loss = 1.275103, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2754381895065308, Accuracy = 1.0\n",
      "Iter #713280:  Learning rate = 0.000075:  Batch Loss = 1.274615, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2742609977722168, Accuracy = 1.0\n",
      "Iter #713600:  Learning rate = 0.000075:  Batch Loss = 1.273675, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2739307880401611, Accuracy = 1.0\n",
      "Iter #713920:  Learning rate = 0.000075:  Batch Loss = 1.273657, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2742823362350464, Accuracy = 1.0\n",
      "Iter #714240:  Learning rate = 0.000075:  Batch Loss = 1.273256, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2897355556488037, Accuracy = 1.0\n",
      "Iter #714560:  Learning rate = 0.000075:  Batch Loss = 1.274381, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2804449796676636, Accuracy = 1.0\n",
      "Iter #714880:  Learning rate = 0.000075:  Batch Loss = 1.271252, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3623757362365723, Accuracy = 0.9666666388511658\n",
      "Iter #715200:  Learning rate = 0.000075:  Batch Loss = 1.279760, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2967345714569092, Accuracy = 1.0\n",
      "Iter #715520:  Learning rate = 0.000075:  Batch Loss = 1.269979, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.28488028049469, Accuracy = 1.0\n",
      "Iter #715840:  Learning rate = 0.000075:  Batch Loss = 1.271440, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3323076963424683, Accuracy = 0.9666666388511658\n",
      "Iter #716160:  Learning rate = 0.000075:  Batch Loss = 1.278422, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3228257894515991, Accuracy = 0.9666666388511658\n",
      "Iter #716480:  Learning rate = 0.000075:  Batch Loss = 1.268281, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2986698150634766, Accuracy = 1.0\n",
      "Iter #716800:  Learning rate = 0.000075:  Batch Loss = 1.284690, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.455503225326538, Accuracy = 0.8999999761581421\n",
      "Iter #717120:  Learning rate = 0.000075:  Batch Loss = 1.571533, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2703272104263306, Accuracy = 1.0\n",
      "Iter #717440:  Learning rate = 0.000075:  Batch Loss = 1.265662, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2992985248565674, Accuracy = 0.9833333492279053\n",
      "Iter #717760:  Learning rate = 0.000075:  Batch Loss = 1.265835, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2827479839324951, Accuracy = 1.0\n",
      "Iter #718080:  Learning rate = 0.000075:  Batch Loss = 1.266119, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3339976072311401, Accuracy = 0.9666666388511658\n",
      "Iter #718400:  Learning rate = 0.000075:  Batch Loss = 1.264358, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.294310450553894, Accuracy = 1.0\n",
      "Iter #718720:  Learning rate = 0.000075:  Batch Loss = 1.265178, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2805064916610718, Accuracy = 1.0\n",
      "Iter #719040:  Learning rate = 0.000075:  Batch Loss = 1.262997, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2941197156906128, Accuracy = 0.9833333492279053\n",
      "Iter #719360:  Learning rate = 0.000075:  Batch Loss = 1.263716, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3021374940872192, Accuracy = 0.9666666388511658\n",
      "Iter #719680:  Learning rate = 0.000075:  Batch Loss = 1.262352, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2807694673538208, Accuracy = 1.0\n",
      "Iter #720000:  Learning rate = 0.000075:  Batch Loss = 1.261599, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2811497449874878, Accuracy = 1.0\n",
      "Iter #720320:  Learning rate = 0.000075:  Batch Loss = 1.262450, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2785285711288452, Accuracy = 1.0\n",
      "Iter #720640:  Learning rate = 0.000075:  Batch Loss = 1.272642, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2801536321640015, Accuracy = 1.0\n",
      "Iter #720960:  Learning rate = 0.000075:  Batch Loss = 1.266161, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.280632734298706, Accuracy = 1.0\n",
      "Iter #721280:  Learning rate = 0.000075:  Batch Loss = 1.258610, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2691890001296997, Accuracy = 1.0\n",
      "Iter #721600:  Learning rate = 0.000075:  Batch Loss = 1.258537, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2798048257827759, Accuracy = 1.0\n",
      "Iter #721920:  Learning rate = 0.000075:  Batch Loss = 1.258761, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2765637636184692, Accuracy = 1.0\n",
      "Iter #722240:  Learning rate = 0.000075:  Batch Loss = 1.262530, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.281260371208191, Accuracy = 1.0\n",
      "Iter #722560:  Learning rate = 0.000075:  Batch Loss = 1.256569, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2640928030014038, Accuracy = 1.0\n",
      "Iter #722880:  Learning rate = 0.000075:  Batch Loss = 1.256594, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2620224952697754, Accuracy = 1.0\n",
      "Iter #723200:  Learning rate = 0.000075:  Batch Loss = 1.255537, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2871270179748535, Accuracy = 0.9666666388511658\n",
      "Iter #723520:  Learning rate = 0.000075:  Batch Loss = 1.257605, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3102185726165771, Accuracy = 0.9833333492279053\n",
      "Iter #723840:  Learning rate = 0.000075:  Batch Loss = 1.255805, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2710024118423462, Accuracy = 1.0\n",
      "Iter #724160:  Learning rate = 0.000075:  Batch Loss = 1.253494, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2652995586395264, Accuracy = 1.0\n",
      "Iter #724480:  Learning rate = 0.000075:  Batch Loss = 1.254780, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2583215236663818, Accuracy = 1.0\n",
      "Iter #724800:  Learning rate = 0.000075:  Batch Loss = 1.272661, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4091027975082397, Accuracy = 0.9333333373069763\n",
      "Iter #725120:  Learning rate = 0.000075:  Batch Loss = 1.252633, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2663089036941528, Accuracy = 1.0\n",
      "Iter #725440:  Learning rate = 0.000075:  Batch Loss = 1.255221, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2816190719604492, Accuracy = 1.0\n",
      "Iter #725760:  Learning rate = 0.000075:  Batch Loss = 1.270586, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2676212787628174, Accuracy = 1.0\n",
      "Iter #726080:  Learning rate = 0.000075:  Batch Loss = 1.251558, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2614362239837646, Accuracy = 1.0\n",
      "Iter #726400:  Learning rate = 0.000075:  Batch Loss = 1.249966, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2796953916549683, Accuracy = 1.0\n",
      "Iter #726720:  Learning rate = 0.000075:  Batch Loss = 1.252381, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2615185976028442, Accuracy = 1.0\n",
      "Iter #727040:  Learning rate = 0.000075:  Batch Loss = 1.251063, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2642202377319336, Accuracy = 1.0\n",
      "Iter #727360:  Learning rate = 0.000075:  Batch Loss = 1.248880, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2597934007644653, Accuracy = 1.0\n",
      "Iter #727680:  Learning rate = 0.000075:  Batch Loss = 1.249055, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.257232904434204, Accuracy = 1.0\n",
      "Iter #728000:  Learning rate = 0.000075:  Batch Loss = 1.247989, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2696202993392944, Accuracy = 1.0\n",
      "Iter #728320:  Learning rate = 0.000075:  Batch Loss = 1.248923, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2556511163711548, Accuracy = 1.0\n",
      "Iter #728640:  Learning rate = 0.000075:  Batch Loss = 1.246009, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2557772397994995, Accuracy = 1.0\n",
      "Iter #728960:  Learning rate = 0.000075:  Batch Loss = 1.246771, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.257421612739563, Accuracy = 1.0\n",
      "Iter #729280:  Learning rate = 0.000075:  Batch Loss = 1.245664, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2654974460601807, Accuracy = 1.0\n",
      "Iter #729600:  Learning rate = 0.000075:  Batch Loss = 1.244266, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2539689540863037, Accuracy = 1.0\n",
      "Iter #729920:  Learning rate = 0.000075:  Batch Loss = 1.243841, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2514766454696655, Accuracy = 1.0\n",
      "Iter #730240:  Learning rate = 0.000075:  Batch Loss = 1.253943, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.283246636390686, Accuracy = 1.0\n",
      "Iter #730560:  Learning rate = 0.000075:  Batch Loss = 1.242735, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2495288848876953, Accuracy = 1.0\n",
      "Iter #730880:  Learning rate = 0.000075:  Batch Loss = 1.241839, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.247695803642273, Accuracy = 1.0\n",
      "Iter #731200:  Learning rate = 0.000075:  Batch Loss = 1.242596, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3059890270233154, Accuracy = 0.9666666388511658\n",
      "Iter #731520:  Learning rate = 0.000075:  Batch Loss = 1.241080, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3633246421813965, Accuracy = 0.9166666865348816\n",
      "Iter #731840:  Learning rate = 0.000075:  Batch Loss = 1.240531, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2414758205413818, Accuracy = 1.0\n",
      "Iter #732160:  Learning rate = 0.000075:  Batch Loss = 1.241506, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2472453117370605, Accuracy = 1.0\n",
      "Iter #732480:  Learning rate = 0.000075:  Batch Loss = 1.239202, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3758249282836914, Accuracy = 0.9333333373069763\n",
      "Iter #732800:  Learning rate = 0.000075:  Batch Loss = 1.239312, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2449414730072021, Accuracy = 1.0\n",
      "Iter #733120:  Learning rate = 0.000075:  Batch Loss = 1.237484, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4092357158660889, Accuracy = 0.8999999761581421\n",
      "Iter #733440:  Learning rate = 0.000075:  Batch Loss = 1.238151, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2431970834732056, Accuracy = 1.0\n",
      "Iter #733760:  Learning rate = 0.000075:  Batch Loss = 1.237610, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2634434700012207, Accuracy = 1.0\n",
      "Iter #734080:  Learning rate = 0.000075:  Batch Loss = 1.240616, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2787213325500488, Accuracy = 0.9666666388511658\n",
      "Iter #734400:  Learning rate = 0.000075:  Batch Loss = 1.235318, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2457201480865479, Accuracy = 1.0\n",
      "Iter #734720:  Learning rate = 0.000075:  Batch Loss = 1.236309, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2790520191192627, Accuracy = 1.0\n",
      "Iter #735040:  Learning rate = 0.000075:  Batch Loss = 1.236477, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.247930884361267, Accuracy = 1.0\n",
      "Iter #735360:  Learning rate = 0.000075:  Batch Loss = 1.234956, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2599213123321533, Accuracy = 1.0\n",
      "Iter #735680:  Learning rate = 0.000075:  Batch Loss = 1.232958, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2416726350784302, Accuracy = 1.0\n",
      "Iter #736000:  Learning rate = 0.000075:  Batch Loss = 1.234395, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.238667607307434, Accuracy = 1.0\n",
      "Iter #736320:  Learning rate = 0.000075:  Batch Loss = 1.239917, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2485365867614746, Accuracy = 1.0\n",
      "Iter #736640:  Learning rate = 0.000075:  Batch Loss = 1.231839, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.242188572883606, Accuracy = 1.0\n",
      "Iter #736960:  Learning rate = 0.000075:  Batch Loss = 1.277910, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2626292705535889, Accuracy = 0.9666666388511658\n",
      "Iter #737280:  Learning rate = 0.000075:  Batch Loss = 1.244170, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2483010292053223, Accuracy = 1.0\n",
      "Iter #737600:  Learning rate = 0.000075:  Batch Loss = 1.230060, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2485268115997314, Accuracy = 1.0\n",
      "Iter #737920:  Learning rate = 0.000075:  Batch Loss = 1.230763, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2480279207229614, Accuracy = 1.0\n",
      "Iter #738240:  Learning rate = 0.000075:  Batch Loss = 1.231597, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.249241828918457, Accuracy = 1.0\n",
      "Iter #738560:  Learning rate = 0.000075:  Batch Loss = 1.228134, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2409521341323853, Accuracy = 1.0\n",
      "Iter #738880:  Learning rate = 0.000075:  Batch Loss = 1.230116, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2372775077819824, Accuracy = 1.0\n",
      "Iter #739200:  Learning rate = 0.000075:  Batch Loss = 1.240886, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.23564875125885, Accuracy = 1.0\n",
      "Iter #739520:  Learning rate = 0.000075:  Batch Loss = 1.226959, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2364552021026611, Accuracy = 1.0\n",
      "Iter #739840:  Learning rate = 0.000075:  Batch Loss = 1.226090, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2415980100631714, Accuracy = 1.0\n",
      "Iter #740160:  Learning rate = 0.000075:  Batch Loss = 1.226378, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.234108328819275, Accuracy = 1.0\n",
      "Iter #740480:  Learning rate = 0.000075:  Batch Loss = 1.225231, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.22942316532135, Accuracy = 1.0\n",
      "Iter #740800:  Learning rate = 0.000075:  Batch Loss = 1.225198, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.236924409866333, Accuracy = 1.0\n",
      "Iter #741120:  Learning rate = 0.000075:  Batch Loss = 1.240936, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.230325698852539, Accuracy = 1.0\n",
      "Iter #741440:  Learning rate = 0.000075:  Batch Loss = 1.225269, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2302006483078003, Accuracy = 1.0\n",
      "Iter #741760:  Learning rate = 0.000075:  Batch Loss = 1.224323, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3038156032562256, Accuracy = 0.9666666388511658\n",
      "Iter #742080:  Learning rate = 0.000075:  Batch Loss = 1.222624, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2277822494506836, Accuracy = 1.0\n",
      "Iter #742400:  Learning rate = 0.000075:  Batch Loss = 1.228682, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2669743299484253, Accuracy = 0.9666666388511658\n",
      "Iter #742720:  Learning rate = 0.000075:  Batch Loss = 1.222286, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2302734851837158, Accuracy = 1.0\n",
      "Iter #743040:  Learning rate = 0.000075:  Batch Loss = 1.220612, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2401074171066284, Accuracy = 1.0\n",
      "Iter #743360:  Learning rate = 0.000075:  Batch Loss = 1.220098, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2421618700027466, Accuracy = 1.0\n",
      "Iter #743680:  Learning rate = 0.000075:  Batch Loss = 1.223997, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2330853939056396, Accuracy = 1.0\n",
      "Iter #744000:  Learning rate = 0.000075:  Batch Loss = 1.218422, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.22658371925354, Accuracy = 1.0\n",
      "Iter #744320:  Learning rate = 0.000075:  Batch Loss = 1.219304, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.239888072013855, Accuracy = 1.0\n",
      "Iter #744640:  Learning rate = 0.000075:  Batch Loss = 1.217304, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.230649709701538, Accuracy = 1.0\n",
      "Iter #744960:  Learning rate = 0.000075:  Batch Loss = 1.216719, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.222879409790039, Accuracy = 1.0\n",
      "Iter #745280:  Learning rate = 0.000075:  Batch Loss = 1.215952, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3028303384780884, Accuracy = 0.949999988079071\n",
      "Iter #745600:  Learning rate = 0.000075:  Batch Loss = 1.215957, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2165296077728271, Accuracy = 1.0\n",
      "Iter #745920:  Learning rate = 0.000075:  Batch Loss = 1.215634, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3253809213638306, Accuracy = 0.9333333373069763\n",
      "Iter #746240:  Learning rate = 0.000075:  Batch Loss = 1.215053, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.216507911682129, Accuracy = 1.0\n",
      "Iter #746560:  Learning rate = 0.000075:  Batch Loss = 1.214063, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2809803485870361, Accuracy = 0.9666666388511658\n",
      "Iter #746880:  Learning rate = 0.000075:  Batch Loss = 1.213549, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2189903259277344, Accuracy = 1.0\n",
      "Iter #747200:  Learning rate = 0.000075:  Batch Loss = 1.212639, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2522255182266235, Accuracy = 0.9833333492279053\n",
      "Iter #747520:  Learning rate = 0.000075:  Batch Loss = 1.216073, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3216134309768677, Accuracy = 0.9666666388511658\n",
      "Iter #747840:  Learning rate = 0.000075:  Batch Loss = 1.210908, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.222068428993225, Accuracy = 1.0\n",
      "Iter #748160:  Learning rate = 0.000075:  Batch Loss = 1.318314, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3027126789093018, Accuracy = 0.949999988079071\n",
      "Iter #748480:  Learning rate = 0.000075:  Batch Loss = 1.437152, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2117384672164917, Accuracy = 1.0\n",
      "Iter #748800:  Learning rate = 0.000075:  Batch Loss = 1.208979, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.349376916885376, Accuracy = 0.9333333373069763\n",
      "Iter #749120:  Learning rate = 0.000075:  Batch Loss = 1.411446, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2477912902832031, Accuracy = 0.9833333492279053\n",
      "Iter #749440:  Learning rate = 0.000075:  Batch Loss = 1.277050, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.4103883504867554, Accuracy = 0.9166666865348816\n",
      "Iter #749760:  Learning rate = 0.000075:  Batch Loss = 1.218074, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.242223858833313, Accuracy = 0.9833333492279053\n",
      "Iter #750080:  Learning rate = 0.000075:  Batch Loss = 1.216799, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2238337993621826, Accuracy = 1.0\n",
      "Iter #750400:  Learning rate = 0.000075:  Batch Loss = 1.211619, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.22970449924469, Accuracy = 1.0\n",
      "Iter #750720:  Learning rate = 0.000075:  Batch Loss = 1.211154, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2296662330627441, Accuracy = 1.0\n",
      "Iter #751040:  Learning rate = 0.000075:  Batch Loss = 1.213130, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2559974193572998, Accuracy = 0.9833333492279053\n",
      "Iter #751360:  Learning rate = 0.000075:  Batch Loss = 1.211874, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2196147441864014, Accuracy = 1.0\n",
      "Iter #751680:  Learning rate = 0.000075:  Batch Loss = 1.211203, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2452607154846191, Accuracy = 1.0\n",
      "Iter #752000:  Learning rate = 0.000075:  Batch Loss = 1.214759, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2567152976989746, Accuracy = 1.0\n",
      "Iter #752320:  Learning rate = 0.000075:  Batch Loss = 1.208773, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2211787700653076, Accuracy = 1.0\n",
      "Iter #752640:  Learning rate = 0.000075:  Batch Loss = 1.208867, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2220793962478638, Accuracy = 1.0\n",
      "Iter #752960:  Learning rate = 0.000075:  Batch Loss = 1.210462, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2199631929397583, Accuracy = 1.0\n",
      "Iter #753280:  Learning rate = 0.000075:  Batch Loss = 1.218938, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2182246446609497, Accuracy = 1.0\n",
      "Iter #753600:  Learning rate = 0.000075:  Batch Loss = 1.209247, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2176793813705444, Accuracy = 1.0\n",
      "Iter #753920:  Learning rate = 0.000075:  Batch Loss = 1.206963, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2181525230407715, Accuracy = 1.0\n",
      "Iter #754240:  Learning rate = 0.000075:  Batch Loss = 1.210260, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2196030616760254, Accuracy = 1.0\n",
      "Iter #754560:  Learning rate = 0.000075:  Batch Loss = 1.207735, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2173107862472534, Accuracy = 1.0\n",
      "Iter #754880:  Learning rate = 0.000075:  Batch Loss = 1.206804, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2172844409942627, Accuracy = 1.0\n",
      "Iter #755200:  Learning rate = 0.000075:  Batch Loss = 1.206527, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.214996099472046, Accuracy = 1.0\n",
      "Iter #755520:  Learning rate = 0.000075:  Batch Loss = 1.207296, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2144867181777954, Accuracy = 1.0\n",
      "Iter #755840:  Learning rate = 0.000075:  Batch Loss = 1.205073, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2174296379089355, Accuracy = 1.0\n",
      "Iter #756160:  Learning rate = 0.000075:  Batch Loss = 1.209718, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2150640487670898, Accuracy = 1.0\n",
      "Iter #756480:  Learning rate = 0.000075:  Batch Loss = 1.206670, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2113072872161865, Accuracy = 1.0\n",
      "Iter #756800:  Learning rate = 0.000075:  Batch Loss = 1.206605, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2239693403244019, Accuracy = 1.0\n",
      "Iter #757120:  Learning rate = 0.000075:  Batch Loss = 1.204104, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.213107943534851, Accuracy = 1.0\n",
      "Iter #757440:  Learning rate = 0.000075:  Batch Loss = 1.204203, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2164582014083862, Accuracy = 1.0\n",
      "Iter #757760:  Learning rate = 0.000075:  Batch Loss = 1.203524, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.217373013496399, Accuracy = 1.0\n",
      "Iter #758080:  Learning rate = 0.000075:  Batch Loss = 1.297828, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2445900440216064, Accuracy = 0.9833333492279053\n",
      "Iter #758400:  Learning rate = 0.000075:  Batch Loss = 1.205694, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.207890272140503, Accuracy = 1.0\n",
      "Iter #758720:  Learning rate = 0.000075:  Batch Loss = 1.254721, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2571024894714355, Accuracy = 0.9833333492279053\n",
      "Iter #759040:  Learning rate = 0.000075:  Batch Loss = 1.202967, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.207556128501892, Accuracy = 1.0\n",
      "Iter #759360:  Learning rate = 0.000075:  Batch Loss = 1.205194, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.293390154838562, Accuracy = 0.949999988079071\n",
      "Iter #759680:  Learning rate = 0.000075:  Batch Loss = 1.202060, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2050532102584839, Accuracy = 1.0\n",
      "Iter #760000:  Learning rate = 0.000075:  Batch Loss = 1.202217, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.3397095203399658, Accuracy = 0.9166666865348816\n",
      "Iter #760320:  Learning rate = 0.000075:  Batch Loss = 1.203054, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2160229682922363, Accuracy = 1.0\n",
      "Iter #760640:  Learning rate = 0.000075:  Batch Loss = 1.201605, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2092959880828857, Accuracy = 1.0\n",
      "Iter #760960:  Learning rate = 0.000075:  Batch Loss = 1.201012, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2186306715011597, Accuracy = 1.0\n",
      "Iter #761280:  Learning rate = 0.000075:  Batch Loss = 1.229813, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2083027362823486, Accuracy = 1.0\n",
      "Iter #761600:  Learning rate = 0.000075:  Batch Loss = 1.202606, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2191245555877686, Accuracy = 1.0\n",
      "Iter #761920:  Learning rate = 0.000075:  Batch Loss = 1.200639, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2126294374465942, Accuracy = 1.0\n",
      "Iter #762240:  Learning rate = 0.000075:  Batch Loss = 1.200042, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.208475112915039, Accuracy = 1.0\n",
      "Iter #762560:  Learning rate = 0.000075:  Batch Loss = 1.210320, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2070746421813965, Accuracy = 1.0\n",
      "Iter #762880:  Learning rate = 0.000075:  Batch Loss = 1.200066, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.208961844444275, Accuracy = 1.0\n",
      "Iter #763200:  Learning rate = 0.000075:  Batch Loss = 1.199371, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2086081504821777, Accuracy = 1.0\n",
      "Iter #763520:  Learning rate = 0.000075:  Batch Loss = 1.199020, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.205686330795288, Accuracy = 1.0\n",
      "Iter #763840:  Learning rate = 0.000075:  Batch Loss = 1.199882, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.208611011505127, Accuracy = 1.0\n",
      "Iter #764160:  Learning rate = 0.000075:  Batch Loss = 1.203225, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.208038091659546, Accuracy = 1.0\n",
      "Iter #764480:  Learning rate = 0.000075:  Batch Loss = 1.198864, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2065256834030151, Accuracy = 1.0\n",
      "Iter #764800:  Learning rate = 0.000075:  Batch Loss = 1.198053, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2063820362091064, Accuracy = 1.0\n",
      "Iter #765120:  Learning rate = 0.000075:  Batch Loss = 1.197926, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2061898708343506, Accuracy = 1.0\n",
      "Iter #765440:  Learning rate = 0.000075:  Batch Loss = 1.203831, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2045643329620361, Accuracy = 1.0\n",
      "Iter #765760:  Learning rate = 0.000075:  Batch Loss = 1.197970, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2035096883773804, Accuracy = 1.0\n",
      "Iter #766080:  Learning rate = 0.000075:  Batch Loss = 1.198560, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2060707807540894, Accuracy = 1.0\n",
      "Iter #766400:  Learning rate = 0.000075:  Batch Loss = 1.197493, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2037009000778198, Accuracy = 1.0\n",
      "Iter #766720:  Learning rate = 0.000075:  Batch Loss = 1.199767, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.203660488128662, Accuracy = 1.0\n",
      "Iter #767040:  Learning rate = 0.000075:  Batch Loss = 1.199099, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2040736675262451, Accuracy = 1.0\n",
      "Iter #767360:  Learning rate = 0.000075:  Batch Loss = 1.196386, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2029297351837158, Accuracy = 1.0\n",
      "Iter #767680:  Learning rate = 0.000075:  Batch Loss = 1.195966, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2015196084976196, Accuracy = 1.0\n",
      "Iter #768000:  Learning rate = 0.000075:  Batch Loss = 1.197364, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2017533779144287, Accuracy = 1.0\n",
      "Iter #768320:  Learning rate = 0.000075:  Batch Loss = 1.199083, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.201499581336975, Accuracy = 1.0\n",
      "Iter #768640:  Learning rate = 0.000075:  Batch Loss = 1.195850, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2007747888565063, Accuracy = 1.0\n",
      "Iter #768960:  Learning rate = 0.000075:  Batch Loss = 1.195705, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2008239030838013, Accuracy = 1.0\n",
      "Iter #769280:  Learning rate = 0.000075:  Batch Loss = 1.194407, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2008893489837646, Accuracy = 1.0\n",
      "Iter #769600:  Learning rate = 0.000075:  Batch Loss = 1.198343, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1987261772155762, Accuracy = 1.0\n",
      "Iter #769920:  Learning rate = 0.000075:  Batch Loss = 1.194788, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2014497518539429, Accuracy = 1.0\n",
      "Iter #770240:  Learning rate = 0.000075:  Batch Loss = 1.197304, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1991469860076904, Accuracy = 1.0\n",
      "Iter #770560:  Learning rate = 0.000075:  Batch Loss = 1.193530, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1977601051330566, Accuracy = 1.0\n",
      "Iter #770880:  Learning rate = 0.000075:  Batch Loss = 1.192401, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.200700283050537, Accuracy = 1.0\n",
      "Iter #771200:  Learning rate = 0.000075:  Batch Loss = 1.192482, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1985042095184326, Accuracy = 1.0\n",
      "Iter #771520:  Learning rate = 0.000075:  Batch Loss = 1.198422, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1984816789627075, Accuracy = 1.0\n",
      "Iter #771840:  Learning rate = 0.000075:  Batch Loss = 1.193626, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1973708868026733, Accuracy = 1.0\n",
      "Iter #772160:  Learning rate = 0.000075:  Batch Loss = 1.192748, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.199109435081482, Accuracy = 1.0\n",
      "Iter #772480:  Learning rate = 0.000075:  Batch Loss = 1.195398, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.195778489112854, Accuracy = 1.0\n",
      "Iter #772800:  Learning rate = 0.000075:  Batch Loss = 1.195147, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1952464580535889, Accuracy = 1.0\n",
      "Iter #773120:  Learning rate = 0.000075:  Batch Loss = 1.191429, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1962794065475464, Accuracy = 1.0\n",
      "Iter #773440:  Learning rate = 0.000075:  Batch Loss = 1.190127, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1935845613479614, Accuracy = 1.0\n",
      "Iter #773760:  Learning rate = 0.000075:  Batch Loss = 1.189681, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.199352741241455, Accuracy = 1.0\n",
      "Iter #774080:  Learning rate = 0.000075:  Batch Loss = 1.191605, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.196258783340454, Accuracy = 1.0\n",
      "Iter #774400:  Learning rate = 0.000075:  Batch Loss = 1.191022, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1938916444778442, Accuracy = 1.0\n",
      "Iter #774720:  Learning rate = 0.000075:  Batch Loss = 1.188961, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1932315826416016, Accuracy = 1.0\n",
      "Iter #775040:  Learning rate = 0.000075:  Batch Loss = 1.191108, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.194771647453308, Accuracy = 1.0\n",
      "Iter #775360:  Learning rate = 0.000075:  Batch Loss = 1.190524, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1936708688735962, Accuracy = 1.0\n",
      "Iter #775680:  Learning rate = 0.000075:  Batch Loss = 1.188773, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1928775310516357, Accuracy = 1.0\n",
      "Iter #776000:  Learning rate = 0.000075:  Batch Loss = 1.194383, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1922751665115356, Accuracy = 1.0\n",
      "Iter #776320:  Learning rate = 0.000075:  Batch Loss = 1.187846, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1918007135391235, Accuracy = 1.0\n",
      "Iter #776640:  Learning rate = 0.000075:  Batch Loss = 1.186555, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1908811330795288, Accuracy = 1.0\n",
      "Iter #776960:  Learning rate = 0.000075:  Batch Loss = 1.187149, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1906603574752808, Accuracy = 1.0\n",
      "Iter #777280:  Learning rate = 0.000075:  Batch Loss = 1.186274, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1896549463272095, Accuracy = 1.0\n",
      "Iter #777600:  Learning rate = 0.000075:  Batch Loss = 1.185251, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1921820640563965, Accuracy = 1.0\n",
      "Iter #777920:  Learning rate = 0.000075:  Batch Loss = 1.185695, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1888418197631836, Accuracy = 1.0\n",
      "Iter #778240:  Learning rate = 0.000075:  Batch Loss = 1.185829, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.188413381576538, Accuracy = 1.0\n",
      "Iter #778560:  Learning rate = 0.000075:  Batch Loss = 1.185350, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1901482343673706, Accuracy = 1.0\n",
      "Iter #778880:  Learning rate = 0.000075:  Batch Loss = 1.183805, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.187841534614563, Accuracy = 1.0\n",
      "Iter #779200:  Learning rate = 0.000075:  Batch Loss = 1.183885, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1857261657714844, Accuracy = 1.0\n",
      "Iter #779520:  Learning rate = 0.000075:  Batch Loss = 1.182929, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2075732946395874, Accuracy = 1.0\n",
      "Iter #779840:  Learning rate = 0.000075:  Batch Loss = 1.182975, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1853930950164795, Accuracy = 1.0\n",
      "Iter #780160:  Learning rate = 0.000075:  Batch Loss = 1.182142, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.406559944152832, Accuracy = 0.8833333253860474\n",
      "Iter #780480:  Learning rate = 0.000075:  Batch Loss = 1.182763, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1822552680969238, Accuracy = 1.0\n",
      "Iter #780800:  Learning rate = 0.000075:  Batch Loss = 1.182196, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.181883692741394, Accuracy = 1.0\n",
      "Iter #781120:  Learning rate = 0.000075:  Batch Loss = 1.181292, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.2117191553115845, Accuracy = 1.0\n",
      "Iter #781440:  Learning rate = 0.000075:  Batch Loss = 1.181030, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1846983432769775, Accuracy = 1.0\n",
      "Iter #781760:  Learning rate = 0.000075:  Batch Loss = 1.179902, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1976267099380493, Accuracy = 1.0\n",
      "Iter #782080:  Learning rate = 0.000075:  Batch Loss = 1.179320, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1887421607971191, Accuracy = 1.0\n",
      "Iter #782400:  Learning rate = 0.000075:  Batch Loss = 1.179461, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1921309232711792, Accuracy = 1.0\n",
      "Iter #782720:  Learning rate = 0.000075:  Batch Loss = 1.179293, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1852076053619385, Accuracy = 1.0\n",
      "Iter #783040:  Learning rate = 0.000075:  Batch Loss = 1.178717, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1893863677978516, Accuracy = 1.0\n",
      "Iter #783360:  Learning rate = 0.000075:  Batch Loss = 1.179315, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1842232942581177, Accuracy = 1.0\n",
      "Iter #783680:  Learning rate = 0.000075:  Batch Loss = 1.178546, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1864714622497559, Accuracy = 1.0\n",
      "Iter #784000:  Learning rate = 0.000075:  Batch Loss = 1.183867, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.182870626449585, Accuracy = 1.0\n",
      "Iter #784320:  Learning rate = 0.000075:  Batch Loss = 1.178315, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.191323161125183, Accuracy = 1.0\n",
      "Iter #784640:  Learning rate = 0.000075:  Batch Loss = 1.183900, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1844326257705688, Accuracy = 1.0\n",
      "Iter #784960:  Learning rate = 0.000075:  Batch Loss = 1.176442, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1813682317733765, Accuracy = 1.0\n",
      "Iter #785280:  Learning rate = 0.000075:  Batch Loss = 1.176423, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.183436393737793, Accuracy = 1.0\n",
      "Iter #785600:  Learning rate = 0.000075:  Batch Loss = 1.176907, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1841496229171753, Accuracy = 1.0\n",
      "Iter #785920:  Learning rate = 0.000075:  Batch Loss = 1.176101, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1821271181106567, Accuracy = 1.0\n",
      "Iter #786240:  Learning rate = 0.000075:  Batch Loss = 1.177252, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1781259775161743, Accuracy = 1.0\n",
      "Iter #786560:  Learning rate = 0.000075:  Batch Loss = 1.174182, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.18174409866333, Accuracy = 1.0\n",
      "Iter #786880:  Learning rate = 0.000075:  Batch Loss = 1.178657, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1815634965896606, Accuracy = 1.0\n",
      "Iter #787200:  Learning rate = 0.000075:  Batch Loss = 1.173609, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1784995794296265, Accuracy = 1.0\n",
      "Iter #787520:  Learning rate = 0.000075:  Batch Loss = 1.175778, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1797399520874023, Accuracy = 1.0\n",
      "Iter #787840:  Learning rate = 0.000075:  Batch Loss = 1.172732, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.177905797958374, Accuracy = 1.0\n",
      "Iter #788160:  Learning rate = 0.000075:  Batch Loss = 1.172197, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1753921508789062, Accuracy = 1.0\n",
      "Iter #788480:  Learning rate = 0.000075:  Batch Loss = 1.171641, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1763843297958374, Accuracy = 1.0\n",
      "Iter #788800:  Learning rate = 0.000075:  Batch Loss = 1.171286, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1766433715820312, Accuracy = 1.0\n",
      "Iter #789120:  Learning rate = 0.000075:  Batch Loss = 1.170471, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1834909915924072, Accuracy = 1.0\n",
      "Iter #789440:  Learning rate = 0.000075:  Batch Loss = 1.171202, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1723504066467285, Accuracy = 1.0\n",
      "Iter #789760:  Learning rate = 0.000075:  Batch Loss = 1.169875, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1710973978042603, Accuracy = 1.0\n",
      "Iter #790080:  Learning rate = 0.000075:  Batch Loss = 1.519818, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.170332670211792, Accuracy = 1.0\n",
      "Iter #790400:  Learning rate = 0.000075:  Batch Loss = 1.171338, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.169461727142334, Accuracy = 1.0\n",
      "Iter #790720:  Learning rate = 0.000075:  Batch Loss = 1.170073, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.168950080871582, Accuracy = 1.0\n",
      "Iter #791040:  Learning rate = 0.000075:  Batch Loss = 1.168218, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1684482097625732, Accuracy = 1.0\n",
      "Iter #791360:  Learning rate = 0.000075:  Batch Loss = 1.486766, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1680511236190796, Accuracy = 1.0\n",
      "Iter #791680:  Learning rate = 0.000075:  Batch Loss = 1.166962, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1676503419876099, Accuracy = 1.0\n",
      "Iter #792000:  Learning rate = 0.000075:  Batch Loss = 1.475079, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1672555208206177, Accuracy = 1.0\n",
      "Iter #792320:  Learning rate = 0.000075:  Batch Loss = 1.166608, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1670012474060059, Accuracy = 1.0\n",
      "Iter #792640:  Learning rate = 0.000075:  Batch Loss = 1.169756, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1668347120285034, Accuracy = 1.0\n",
      "Iter #792960:  Learning rate = 0.000075:  Batch Loss = 1.168772, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1666219234466553, Accuracy = 1.0\n",
      "Iter #793280:  Learning rate = 0.000075:  Batch Loss = 1.164358, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1662750244140625, Accuracy = 1.0\n",
      "Iter #793600:  Learning rate = 0.000075:  Batch Loss = 1.449909, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1655837297439575, Accuracy = 1.0\n",
      "Iter #793920:  Learning rate = 0.000075:  Batch Loss = 1.163143, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.166124701499939, Accuracy = 1.0\n",
      "Iter #794240:  Learning rate = 0.000075:  Batch Loss = 1.165134, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1656348705291748, Accuracy = 1.0\n",
      "Iter #794560:  Learning rate = 0.000075:  Batch Loss = 1.165800, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.164618730545044, Accuracy = 1.0\n",
      "Iter #794880:  Learning rate = 0.000075:  Batch Loss = 1.164523, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1645519733428955, Accuracy = 1.0\n",
      "Iter #795200:  Learning rate = 0.000075:  Batch Loss = 1.164321, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1656460762023926, Accuracy = 1.0\n",
      "Iter #795520:  Learning rate = 0.000075:  Batch Loss = 1.163128, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1639597415924072, Accuracy = 1.0\n",
      "Iter #795840:  Learning rate = 0.000075:  Batch Loss = 1.165045, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.163885474205017, Accuracy = 1.0\n",
      "Iter #796160:  Learning rate = 0.000075:  Batch Loss = 1.164606, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.162867546081543, Accuracy = 1.0\n",
      "Iter #796480:  Learning rate = 0.000075:  Batch Loss = 1.161947, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.163331151008606, Accuracy = 1.0\n",
      "Iter #796800:  Learning rate = 0.000075:  Batch Loss = 1.167418, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.163285255432129, Accuracy = 1.0\n",
      "Iter #797120:  Learning rate = 0.000075:  Batch Loss = 1.161522, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.162414312362671, Accuracy = 1.0\n",
      "Iter #797440:  Learning rate = 0.000075:  Batch Loss = 1.162813, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1619759798049927, Accuracy = 1.0\n",
      "Iter #797760:  Learning rate = 0.000075:  Batch Loss = 1.160713, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1612725257873535, Accuracy = 1.0\n",
      "Iter #798080:  Learning rate = 0.000075:  Batch Loss = 1.161825, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1615138053894043, Accuracy = 1.0\n",
      "Iter #798400:  Learning rate = 0.000075:  Batch Loss = 1.156686, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1600699424743652, Accuracy = 1.0\n",
      "Iter #798720:  Learning rate = 0.000075:  Batch Loss = 1.160241, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1612478494644165, Accuracy = 1.0\n",
      "Iter #799040:  Learning rate = 0.000075:  Batch Loss = 1.156566, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1616100072860718, Accuracy = 1.0\n",
      "Iter #799360:  Learning rate = 0.000075:  Batch Loss = 1.154782, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1584663391113281, Accuracy = 1.0\n",
      "Iter #799680:  Learning rate = 0.000075:  Batch Loss = 1.160412, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1581296920776367, Accuracy = 1.0\n",
      "Iter #800000:  Learning rate = 0.000072:  Batch Loss = 1.158102, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1602656841278076, Accuracy = 1.0\n",
      "Iter #800320:  Learning rate = 0.000072:  Batch Loss = 1.156883, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1567790508270264, Accuracy = 1.0\n",
      "Iter #800640:  Learning rate = 0.000072:  Batch Loss = 1.156088, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1557707786560059, Accuracy = 1.0\n",
      "Iter #800960:  Learning rate = 0.000072:  Batch Loss = 1.153537, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1579084396362305, Accuracy = 1.0\n",
      "Iter #801280:  Learning rate = 0.000072:  Batch Loss = 1.152083, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.155432105064392, Accuracy = 1.0\n",
      "Iter #801600:  Learning rate = 0.000072:  Batch Loss = 1.157579, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1547964811325073, Accuracy = 1.0\n",
      "Iter #801920:  Learning rate = 0.000072:  Batch Loss = 1.397742, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1540321111679077, Accuracy = 1.0\n",
      "Iter #802240:  Learning rate = 0.000072:  Batch Loss = 1.160470, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.154771327972412, Accuracy = 1.0\n",
      "Iter #802560:  Learning rate = 0.000072:  Batch Loss = 1.151739, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1525715589523315, Accuracy = 1.0\n",
      "Iter #802880:  Learning rate = 0.000072:  Batch Loss = 1.150104, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1524112224578857, Accuracy = 1.0\n",
      "Iter #803200:  Learning rate = 0.000072:  Batch Loss = 1.151024, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1519694328308105, Accuracy = 1.0\n",
      "Iter #803520:  Learning rate = 0.000072:  Batch Loss = 1.149347, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1522926092147827, Accuracy = 1.0\n",
      "Iter #803840:  Learning rate = 0.000072:  Batch Loss = 1.156058, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.152664303779602, Accuracy = 1.0\n",
      "Iter #804160:  Learning rate = 0.000072:  Batch Loss = 1.154024, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1503212451934814, Accuracy = 1.0\n",
      "Iter #804480:  Learning rate = 0.000072:  Batch Loss = 1.147230, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.150680422782898, Accuracy = 1.0\n",
      "Iter #804800:  Learning rate = 0.000072:  Batch Loss = 1.148371, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.150220274925232, Accuracy = 1.0\n",
      "Iter #805120:  Learning rate = 0.000072:  Batch Loss = 1.388069, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1485145092010498, Accuracy = 1.0\n",
      "Iter #805440:  Learning rate = 0.000072:  Batch Loss = 1.144792, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.147975206375122, Accuracy = 1.0\n",
      "Iter #805760:  Learning rate = 0.000072:  Batch Loss = 1.145307, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1477422714233398, Accuracy = 1.0\n",
      "Iter #806080:  Learning rate = 0.000072:  Batch Loss = 1.384896, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1461577415466309, Accuracy = 1.0\n",
      "Iter #806400:  Learning rate = 0.000072:  Batch Loss = 1.147318, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1467677354812622, Accuracy = 1.0\n",
      "Iter #806720:  Learning rate = 0.000072:  Batch Loss = 1.146292, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1450903415679932, Accuracy = 1.0\n",
      "Iter #807040:  Learning rate = 0.000072:  Batch Loss = 1.145570, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1443116664886475, Accuracy = 1.0\n",
      "Iter #807360:  Learning rate = 0.000072:  Batch Loss = 1.139996, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1451858282089233, Accuracy = 1.0\n",
      "Iter #807680:  Learning rate = 0.000072:  Batch Loss = 1.143814, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1452172994613647, Accuracy = 1.0\n",
      "Iter #808000:  Learning rate = 0.000072:  Batch Loss = 1.378821, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1425365209579468, Accuracy = 1.0\n",
      "Iter #808320:  Learning rate = 0.000072:  Batch Loss = 1.145289, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1437008380889893, Accuracy = 1.0\n",
      "Iter #808640:  Learning rate = 0.000072:  Batch Loss = 1.142629, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.144446611404419, Accuracy = 1.0\n",
      "Iter #808960:  Learning rate = 0.000072:  Batch Loss = 1.141383, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1405408382415771, Accuracy = 1.0\n",
      "Iter #809280:  Learning rate = 0.000072:  Batch Loss = 1.136868, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1409142017364502, Accuracy = 1.0\n",
      "Iter #809600:  Learning rate = 0.000072:  Batch Loss = 1.365960, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1413112878799438, Accuracy = 1.0\n",
      "Iter #809920:  Learning rate = 0.000072:  Batch Loss = 1.365573, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1397775411605835, Accuracy = 1.0\n",
      "Iter #810240:  Learning rate = 0.000072:  Batch Loss = 1.136014, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1416116952896118, Accuracy = 1.0\n",
      "Iter #810560:  Learning rate = 0.000072:  Batch Loss = 1.137664, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1382293701171875, Accuracy = 1.0\n",
      "Iter #810880:  Learning rate = 0.000072:  Batch Loss = 1.134437, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1364960670471191, Accuracy = 1.0\n",
      "Iter #811200:  Learning rate = 0.000072:  Batch Loss = 1.137782, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1364481449127197, Accuracy = 1.0\n",
      "Iter #811520:  Learning rate = 0.000072:  Batch Loss = 1.135769, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1369622945785522, Accuracy = 1.0\n",
      "Iter #811840:  Learning rate = 0.000072:  Batch Loss = 1.343338, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1408166885375977, Accuracy = 1.0\n",
      "Iter #812160:  Learning rate = 0.000072:  Batch Loss = 1.132025, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1344293355941772, Accuracy = 1.0\n",
      "Iter #812480:  Learning rate = 0.000072:  Batch Loss = 1.129804, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1375012397766113, Accuracy = 1.0\n",
      "Iter #812800:  Learning rate = 0.000072:  Batch Loss = 1.132973, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.132064938545227, Accuracy = 1.0\n",
      "Iter #813120:  Learning rate = 0.000072:  Batch Loss = 1.131534, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1307382583618164, Accuracy = 1.0\n",
      "Iter #813440:  Learning rate = 0.000072:  Batch Loss = 1.127824, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1413335800170898, Accuracy = 1.0\n",
      "Iter #813760:  Learning rate = 0.000072:  Batch Loss = 1.131147, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1298389434814453, Accuracy = 1.0\n",
      "Iter #814080:  Learning rate = 0.000072:  Batch Loss = 1.127477, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1284129619598389, Accuracy = 1.0\n",
      "Iter #814400:  Learning rate = 0.000072:  Batch Loss = 1.128314, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1289708614349365, Accuracy = 1.0\n",
      "Iter #814720:  Learning rate = 0.000072:  Batch Loss = 1.136422, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1464481353759766, Accuracy = 1.0\n",
      "Iter #815040:  Learning rate = 0.000072:  Batch Loss = 1.128774, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1268419027328491, Accuracy = 1.0\n",
      "Iter #815360:  Learning rate = 0.000072:  Batch Loss = 1.124361, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1259527206420898, Accuracy = 1.0\n",
      "Iter #815680:  Learning rate = 0.000072:  Batch Loss = 1.123580, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1255494356155396, Accuracy = 1.0\n",
      "Iter #816000:  Learning rate = 0.000072:  Batch Loss = 1.117599, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1252434253692627, Accuracy = 1.0\n",
      "Iter #816320:  Learning rate = 0.000072:  Batch Loss = 1.127367, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1243128776550293, Accuracy = 1.0\n",
      "Iter #816640:  Learning rate = 0.000072:  Batch Loss = 1.126964, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1356863975524902, Accuracy = 1.0\n",
      "Iter #816960:  Learning rate = 0.000072:  Batch Loss = 1.123539, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.123844027519226, Accuracy = 1.0\n",
      "Iter #817280:  Learning rate = 0.000072:  Batch Loss = 1.115998, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.121517300605774, Accuracy = 1.0\n",
      "Iter #817600:  Learning rate = 0.000072:  Batch Loss = 1.117024, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1218791007995605, Accuracy = 1.0\n",
      "Iter #817920:  Learning rate = 0.000072:  Batch Loss = 1.115306, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.123457670211792, Accuracy = 1.0\n",
      "Iter #818240:  Learning rate = 0.000072:  Batch Loss = 1.117170, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1202850341796875, Accuracy = 1.0\n",
      "Iter #818560:  Learning rate = 0.000072:  Batch Loss = 1.113315, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1192728281021118, Accuracy = 1.0\n",
      "Iter #818880:  Learning rate = 0.000072:  Batch Loss = 1.118352, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1199897527694702, Accuracy = 1.0\n",
      "Iter #819200:  Learning rate = 0.000072:  Batch Loss = 1.117684, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1223113536834717, Accuracy = 1.0\n",
      "Iter #819520:  Learning rate = 0.000072:  Batch Loss = 1.117442, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.115140438079834, Accuracy = 1.0\n",
      "Iter #819840:  Learning rate = 0.000072:  Batch Loss = 1.110852, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1162662506103516, Accuracy = 1.0\n",
      "Iter #820160:  Learning rate = 0.000072:  Batch Loss = 1.114639, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.114410400390625, Accuracy = 1.0\n",
      "Iter #820480:  Learning rate = 0.000072:  Batch Loss = 1.108951, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1119773387908936, Accuracy = 1.0\n",
      "Iter #820800:  Learning rate = 0.000072:  Batch Loss = 1.108196, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.111753225326538, Accuracy = 1.0\n",
      "Iter #821120:  Learning rate = 0.000072:  Batch Loss = 1.105829, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.111194372177124, Accuracy = 1.0\n",
      "Iter #821440:  Learning rate = 0.000072:  Batch Loss = 1.105255, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1154073476791382, Accuracy = 1.0\n",
      "Iter #821760:  Learning rate = 0.000072:  Batch Loss = 1.106047, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1088498830795288, Accuracy = 1.0\n",
      "Iter #822080:  Learning rate = 0.000072:  Batch Loss = 1.104436, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1101350784301758, Accuracy = 1.0\n",
      "Iter #822400:  Learning rate = 0.000072:  Batch Loss = 1.120870, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1204981803894043, Accuracy = 1.0\n",
      "Iter #822720:  Learning rate = 0.000072:  Batch Loss = 1.103897, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1055067777633667, Accuracy = 1.0\n",
      "Iter #823040:  Learning rate = 0.000072:  Batch Loss = 1.101992, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1046357154846191, Accuracy = 1.0\n",
      "Iter #823360:  Learning rate = 0.000072:  Batch Loss = 1.101265, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.107730746269226, Accuracy = 1.0\n",
      "Iter #823680:  Learning rate = 0.000072:  Batch Loss = 1.101647, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1038684844970703, Accuracy = 1.0\n",
      "Iter #824000:  Learning rate = 0.000072:  Batch Loss = 1.103406, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1021684408187866, Accuracy = 1.0\n",
      "Iter #824320:  Learning rate = 0.000072:  Batch Loss = 1.100087, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1028130054473877, Accuracy = 1.0\n",
      "Iter #824640:  Learning rate = 0.000072:  Batch Loss = 1.312749, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1046981811523438, Accuracy = 1.0\n",
      "Iter #824960:  Learning rate = 0.000072:  Batch Loss = 1.094194, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1073741912841797, Accuracy = 1.0\n",
      "Iter #825280:  Learning rate = 0.000072:  Batch Loss = 1.097660, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.10079824924469, Accuracy = 1.0\n",
      "Iter #825600:  Learning rate = 0.000072:  Batch Loss = 1.097118, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.098104476928711, Accuracy = 1.0\n",
      "Iter #825920:  Learning rate = 0.000072:  Batch Loss = 1.091422, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1001566648483276, Accuracy = 1.0\n",
      "Iter #826240:  Learning rate = 0.000072:  Batch Loss = 1.099816, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1100202798843384, Accuracy = 1.0\n",
      "Iter #826560:  Learning rate = 0.000072:  Batch Loss = 1.097654, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0971934795379639, Accuracy = 1.0\n",
      "Iter #826880:  Learning rate = 0.000072:  Batch Loss = 1.092442, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0961047410964966, Accuracy = 1.0\n",
      "Iter #827200:  Learning rate = 0.000072:  Batch Loss = 1.100438, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.1101961135864258, Accuracy = 1.0\n",
      "Iter #827520:  Learning rate = 0.000072:  Batch Loss = 1.091264, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0930908918380737, Accuracy = 1.0\n",
      "Iter #827840:  Learning rate = 0.000072:  Batch Loss = 1.087812, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0946283340454102, Accuracy = 1.0\n",
      "Iter #828160:  Learning rate = 0.000072:  Batch Loss = 1.088006, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.091983437538147, Accuracy = 1.0\n",
      "Iter #828480:  Learning rate = 0.000072:  Batch Loss = 1.090828, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0899858474731445, Accuracy = 1.0\n",
      "Iter #828800:  Learning rate = 0.000072:  Batch Loss = 1.084018, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.091947317123413, Accuracy = 1.0\n",
      "Iter #829120:  Learning rate = 0.000072:  Batch Loss = 1.086556, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0905356407165527, Accuracy = 1.0\n",
      "Iter #829440:  Learning rate = 0.000072:  Batch Loss = 1.082079, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0885710716247559, Accuracy = 1.0\n",
      "Iter #829760:  Learning rate = 0.000072:  Batch Loss = 1.090212, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0879453420639038, Accuracy = 1.0\n",
      "Iter #830080:  Learning rate = 0.000072:  Batch Loss = 1.295047, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0867490768432617, Accuracy = 1.0\n",
      "Iter #830400:  Learning rate = 0.000072:  Batch Loss = 1.081671, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0965443849563599, Accuracy = 1.0\n",
      "Iter #830720:  Learning rate = 0.000072:  Batch Loss = 1.144905, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.088310718536377, Accuracy = 1.0\n",
      "Iter #831040:  Learning rate = 0.000072:  Batch Loss = 1.075688, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0821893215179443, Accuracy = 1.0\n",
      "Iter #831360:  Learning rate = 0.000072:  Batch Loss = 1.080384, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.082404613494873, Accuracy = 1.0\n",
      "Iter #831680:  Learning rate = 0.000072:  Batch Loss = 1.076229, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0809619426727295, Accuracy = 1.0\n",
      "Iter #832000:  Learning rate = 0.000072:  Batch Loss = 1.081795, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0809686183929443, Accuracy = 1.0\n",
      "Iter #832320:  Learning rate = 0.000072:  Batch Loss = 1.286246, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0803108215332031, Accuracy = 1.0\n",
      "Iter #832640:  Learning rate = 0.000072:  Batch Loss = 1.072178, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0871654748916626, Accuracy = 1.0\n",
      "Iter #832960:  Learning rate = 0.000072:  Batch Loss = 1.080598, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0775758028030396, Accuracy = 1.0\n",
      "Iter #833280:  Learning rate = 0.000072:  Batch Loss = 1.073496, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.076071858406067, Accuracy = 1.0\n",
      "Iter #833600:  Learning rate = 0.000072:  Batch Loss = 1.070501, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0765641927719116, Accuracy = 1.0\n",
      "Iter #833920:  Learning rate = 0.000072:  Batch Loss = 1.068897, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0768386125564575, Accuracy = 1.0\n",
      "Iter #834240:  Learning rate = 0.000072:  Batch Loss = 1.077150, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0770913362503052, Accuracy = 1.0\n",
      "Iter #834560:  Learning rate = 0.000072:  Batch Loss = 1.068438, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0713541507720947, Accuracy = 1.0\n",
      "Iter #834880:  Learning rate = 0.000072:  Batch Loss = 1.067956, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.075964331626892, Accuracy = 1.0\n",
      "Iter #835200:  Learning rate = 0.000072:  Batch Loss = 1.068835, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0738129615783691, Accuracy = 1.0\n",
      "Iter #835520:  Learning rate = 0.000072:  Batch Loss = 1.063616, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0742132663726807, Accuracy = 1.0\n",
      "Iter #835840:  Learning rate = 0.000072:  Batch Loss = 1.263395, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.069447636604309, Accuracy = 1.0\n",
      "Iter #836160:  Learning rate = 0.000072:  Batch Loss = 1.253004, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0715705156326294, Accuracy = 1.0\n",
      "Iter #836480:  Learning rate = 0.000072:  Batch Loss = 1.061541, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0676648616790771, Accuracy = 1.0\n",
      "Iter #836800:  Learning rate = 0.000072:  Batch Loss = 1.306908, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.065161108970642, Accuracy = 1.0\n",
      "Iter #837120:  Learning rate = 0.000072:  Batch Loss = 1.058788, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0624181032180786, Accuracy = 1.0\n",
      "Iter #837440:  Learning rate = 0.000072:  Batch Loss = 1.058523, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0653386116027832, Accuracy = 1.0\n",
      "Iter #837760:  Learning rate = 0.000072:  Batch Loss = 1.062862, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.066684365272522, Accuracy = 1.0\n",
      "Iter #838080:  Learning rate = 0.000072:  Batch Loss = 1.060261, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0608938932418823, Accuracy = 1.0\n",
      "Iter #838400:  Learning rate = 0.000072:  Batch Loss = 1.052660, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0637823343276978, Accuracy = 1.0\n",
      "Iter #838720:  Learning rate = 0.000072:  Batch Loss = 1.055500, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0671718120574951, Accuracy = 1.0\n",
      "Iter #839040:  Learning rate = 0.000072:  Batch Loss = 1.273663, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0563725233078003, Accuracy = 1.0\n",
      "Iter #839360:  Learning rate = 0.000072:  Batch Loss = 1.051255, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.062182903289795, Accuracy = 1.0\n",
      "Iter #839680:  Learning rate = 0.000072:  Batch Loss = 1.049309, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0697277784347534, Accuracy = 1.0\n",
      "Iter #840000:  Learning rate = 0.000072:  Batch Loss = 1.047630, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0534147024154663, Accuracy = 1.0\n",
      "Iter #840320:  Learning rate = 0.000072:  Batch Loss = 1.048272, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0552759170532227, Accuracy = 1.0\n",
      "Iter #840640:  Learning rate = 0.000072:  Batch Loss = 1.280037, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0504719018936157, Accuracy = 1.0\n",
      "Iter #840960:  Learning rate = 0.000072:  Batch Loss = 1.048436, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0525598526000977, Accuracy = 1.0\n",
      "Iter #841280:  Learning rate = 0.000072:  Batch Loss = 1.042710, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0538983345031738, Accuracy = 1.0\n",
      "Iter #841600:  Learning rate = 0.000072:  Batch Loss = 1.041990, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0476382970809937, Accuracy = 1.0\n",
      "Iter #841920:  Learning rate = 0.000072:  Batch Loss = 1.052812, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.047379732131958, Accuracy = 1.0\n",
      "Iter #842240:  Learning rate = 0.000072:  Batch Loss = 1.044143, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0472373962402344, Accuracy = 1.0\n",
      "Iter #842560:  Learning rate = 0.000072:  Batch Loss = 1.249145, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.04425048828125, Accuracy = 1.0\n",
      "Iter #842880:  Learning rate = 0.000072:  Batch Loss = 1.037392, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0576246976852417, Accuracy = 1.0\n",
      "Iter #843200:  Learning rate = 0.000072:  Batch Loss = 1.039009, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0442143678665161, Accuracy = 1.0\n",
      "Iter #843520:  Learning rate = 0.000072:  Batch Loss = 1.036654, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0445209741592407, Accuracy = 1.0\n",
      "Iter #843840:  Learning rate = 0.000072:  Batch Loss = 1.221472, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0418766736984253, Accuracy = 1.0\n",
      "Iter #844160:  Learning rate = 0.000072:  Batch Loss = 1.220794, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0429121255874634, Accuracy = 1.0\n",
      "Iter #844480:  Learning rate = 0.000072:  Batch Loss = 1.031876, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.045326590538025, Accuracy = 1.0\n",
      "Iter #844800:  Learning rate = 0.000072:  Batch Loss = 1.027383, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0362002849578857, Accuracy = 1.0\n",
      "Iter #845120:  Learning rate = 0.000072:  Batch Loss = 1.276114, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.033687710762024, Accuracy = 1.0\n",
      "Iter #845440:  Learning rate = 0.000072:  Batch Loss = 1.039825, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.038248896598816, Accuracy = 1.0\n",
      "Iter #845760:  Learning rate = 0.000072:  Batch Loss = 1.852348, Accuracy = 0.8125\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0395352840423584, Accuracy = 1.0\n",
      "Iter #846080:  Learning rate = 0.000072:  Batch Loss = 1.285167, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0585763454437256, Accuracy = 0.9833333492279053\n",
      "Iter #846400:  Learning rate = 0.000072:  Batch Loss = 1.032784, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0533334016799927, Accuracy = 1.0\n",
      "Iter #846720:  Learning rate = 0.000072:  Batch Loss = 1.024449, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.030179500579834, Accuracy = 1.0\n",
      "Iter #847040:  Learning rate = 0.000072:  Batch Loss = 1.033661, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.031606912612915, Accuracy = 1.0\n",
      "Iter #847360:  Learning rate = 0.000072:  Batch Loss = 1.024387, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0332406759262085, Accuracy = 1.0\n",
      "Iter #847680:  Learning rate = 0.000072:  Batch Loss = 1.023323, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0305407047271729, Accuracy = 1.0\n",
      "Iter #848000:  Learning rate = 0.000072:  Batch Loss = 1.021443, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0304595232009888, Accuracy = 1.0\n",
      "Iter #848320:  Learning rate = 0.000072:  Batch Loss = 1.022910, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0299885272979736, Accuracy = 1.0\n",
      "Iter #848640:  Learning rate = 0.000072:  Batch Loss = 1.021968, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0325008630752563, Accuracy = 1.0\n",
      "Iter #848960:  Learning rate = 0.000072:  Batch Loss = 1.028017, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0316327810287476, Accuracy = 1.0\n",
      "Iter #849280:  Learning rate = 0.000072:  Batch Loss = 1.028629, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.031020164489746, Accuracy = 1.0\n",
      "Iter #849600:  Learning rate = 0.000072:  Batch Loss = 1.021119, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.028330683708191, Accuracy = 1.0\n",
      "Iter #849920:  Learning rate = 0.000072:  Batch Loss = 1.021511, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0322037935256958, Accuracy = 1.0\n",
      "Iter #850240:  Learning rate = 0.000072:  Batch Loss = 1.016868, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0286304950714111, Accuracy = 1.0\n",
      "Iter #850560:  Learning rate = 0.000072:  Batch Loss = 1.018200, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0252519845962524, Accuracy = 1.0\n",
      "Iter #850880:  Learning rate = 0.000072:  Batch Loss = 1.023671, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0298519134521484, Accuracy = 1.0\n",
      "Iter #851200:  Learning rate = 0.000072:  Batch Loss = 1.016908, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0227060317993164, Accuracy = 1.0\n",
      "Iter #851520:  Learning rate = 0.000072:  Batch Loss = 1.018038, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0284318923950195, Accuracy = 1.0\n",
      "Iter #851840:  Learning rate = 0.000072:  Batch Loss = 1.020786, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0325204133987427, Accuracy = 1.0\n",
      "Iter #852160:  Learning rate = 0.000072:  Batch Loss = 1.014500, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0227431058883667, Accuracy = 1.0\n",
      "Iter #852480:  Learning rate = 0.000072:  Batch Loss = 1.017507, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0256950855255127, Accuracy = 1.0\n",
      "Iter #852800:  Learning rate = 0.000072:  Batch Loss = 1.019216, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.025931715965271, Accuracy = 1.0\n",
      "Iter #853120:  Learning rate = 0.000072:  Batch Loss = 1.014997, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.022293210029602, Accuracy = 1.0\n",
      "Iter #853440:  Learning rate = 0.000072:  Batch Loss = 1.014277, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0267918109893799, Accuracy = 1.0\n",
      "Iter #853760:  Learning rate = 0.000072:  Batch Loss = 1.012567, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0207306146621704, Accuracy = 1.0\n",
      "Iter #854080:  Learning rate = 0.000072:  Batch Loss = 1.011211, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0232625007629395, Accuracy = 1.0\n",
      "Iter #854400:  Learning rate = 0.000072:  Batch Loss = 1.018910, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0232691764831543, Accuracy = 1.0\n",
      "Iter #854720:  Learning rate = 0.000072:  Batch Loss = 1.014610, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0189906358718872, Accuracy = 1.0\n",
      "Iter #855040:  Learning rate = 0.000072:  Batch Loss = 1.010029, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0164904594421387, Accuracy = 1.0\n",
      "Iter #855360:  Learning rate = 0.000072:  Batch Loss = 1.013761, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0238691568374634, Accuracy = 1.0\n",
      "Iter #855680:  Learning rate = 0.000072:  Batch Loss = 1.015094, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0200611352920532, Accuracy = 1.0\n",
      "Iter #856000:  Learning rate = 0.000072:  Batch Loss = 1.007332, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0180584192276, Accuracy = 1.0\n",
      "Iter #856320:  Learning rate = 0.000072:  Batch Loss = 1.005211, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0177340507507324, Accuracy = 1.0\n",
      "Iter #856640:  Learning rate = 0.000072:  Batch Loss = 1.005933, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0213934183120728, Accuracy = 1.0\n",
      "Iter #856960:  Learning rate = 0.000072:  Batch Loss = 1.004954, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0175689458847046, Accuracy = 1.0\n",
      "Iter #857280:  Learning rate = 0.000072:  Batch Loss = 1.003992, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0146197080612183, Accuracy = 1.0\n",
      "Iter #857600:  Learning rate = 0.000072:  Batch Loss = 1.012492, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.015488624572754, Accuracy = 1.0\n",
      "Iter #857920:  Learning rate = 0.000072:  Batch Loss = 1.007189, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0166089534759521, Accuracy = 1.0\n",
      "Iter #858240:  Learning rate = 0.000072:  Batch Loss = 1.002981, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0137929916381836, Accuracy = 1.0\n",
      "Iter #858560:  Learning rate = 0.000072:  Batch Loss = 1.000639, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0146465301513672, Accuracy = 1.0\n",
      "Iter #858880:  Learning rate = 0.000072:  Batch Loss = 1.008598, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0191712379455566, Accuracy = 1.0\n",
      "Iter #859200:  Learning rate = 0.000072:  Batch Loss = 1.003933, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.012229084968567, Accuracy = 1.0\n",
      "Iter #859520:  Learning rate = 0.000072:  Batch Loss = 1.004250, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0138012170791626, Accuracy = 1.0\n",
      "Iter #859840:  Learning rate = 0.000072:  Batch Loss = 1.018656, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.019450068473816, Accuracy = 1.0\n",
      "Iter #860160:  Learning rate = 0.000072:  Batch Loss = 1.004049, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0066134929656982, Accuracy = 1.0\n",
      "Iter #860480:  Learning rate = 0.000072:  Batch Loss = 1.172645, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0099241733551025, Accuracy = 1.0\n",
      "Iter #860800:  Learning rate = 0.000072:  Batch Loss = 0.995244, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0071507692337036, Accuracy = 1.0\n",
      "Iter #861120:  Learning rate = 0.000072:  Batch Loss = 0.994085, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0127358436584473, Accuracy = 1.0\n",
      "Iter #861440:  Learning rate = 0.000072:  Batch Loss = 0.997657, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0113739967346191, Accuracy = 1.0\n",
      "Iter #861760:  Learning rate = 0.000072:  Batch Loss = 1.001617, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0066815614700317, Accuracy = 1.0\n",
      "Iter #862080:  Learning rate = 0.000072:  Batch Loss = 0.994596, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0074896812438965, Accuracy = 1.0\n",
      "Iter #862400:  Learning rate = 0.000072:  Batch Loss = 1.001020, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0024818181991577, Accuracy = 1.0\n",
      "Iter #862720:  Learning rate = 0.000072:  Batch Loss = 0.992035, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0029518604278564, Accuracy = 1.0\n",
      "Iter #863040:  Learning rate = 0.000072:  Batch Loss = 0.997417, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0096772909164429, Accuracy = 1.0\n",
      "Iter #863360:  Learning rate = 0.000072:  Batch Loss = 0.992054, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.00154447555542, Accuracy = 1.0\n",
      "Iter #863680:  Learning rate = 0.000072:  Batch Loss = 0.995831, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.000708818435669, Accuracy = 1.0\n",
      "Iter #864000:  Learning rate = 0.000072:  Batch Loss = 0.993779, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0039891004562378, Accuracy = 1.0\n",
      "Iter #864320:  Learning rate = 0.000072:  Batch Loss = 0.989014, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9970889091491699, Accuracy = 1.0\n",
      "Iter #864640:  Learning rate = 0.000072:  Batch Loss = 0.995183, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0059857368469238, Accuracy = 1.0\n",
      "Iter #864960:  Learning rate = 0.000072:  Batch Loss = 1.170374, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9966753721237183, Accuracy = 1.0\n",
      "Iter #865280:  Learning rate = 0.000072:  Batch Loss = 0.987753, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9938637018203735, Accuracy = 1.0\n",
      "Iter #865600:  Learning rate = 0.000072:  Batch Loss = 0.995383, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0025076866149902, Accuracy = 1.0\n",
      "Iter #865920:  Learning rate = 0.000072:  Batch Loss = 1.002314, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0070443153381348, Accuracy = 1.0\n",
      "Iter #866240:  Learning rate = 0.000072:  Batch Loss = 0.989238, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9974290728569031, Accuracy = 1.0\n",
      "Iter #866560:  Learning rate = 0.000072:  Batch Loss = 0.983675, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9924823045730591, Accuracy = 1.0\n",
      "Iter #866880:  Learning rate = 0.000072:  Batch Loss = 0.985780, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9984325766563416, Accuracy = 1.0\n",
      "Iter #867200:  Learning rate = 0.000072:  Batch Loss = 0.986186, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.991838276386261, Accuracy = 1.0\n",
      "Iter #867520:  Learning rate = 0.000072:  Batch Loss = 0.981445, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.994808554649353, Accuracy = 1.0\n",
      "Iter #867840:  Learning rate = 0.000072:  Batch Loss = 0.999097, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0043766498565674, Accuracy = 1.0\n",
      "Iter #868160:  Learning rate = 0.000072:  Batch Loss = 0.982520, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9916541576385498, Accuracy = 1.0\n",
      "Iter #868480:  Learning rate = 0.000072:  Batch Loss = 0.979617, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9884190559387207, Accuracy = 1.0\n",
      "Iter #868800:  Learning rate = 0.000072:  Batch Loss = 0.989148, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9958606362342834, Accuracy = 1.0\n",
      "Iter #869120:  Learning rate = 0.000072:  Batch Loss = 1.146234, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9896165728569031, Accuracy = 1.0\n",
      "Iter #869440:  Learning rate = 0.000072:  Batch Loss = 0.974719, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9889475703239441, Accuracy = 1.0\n",
      "Iter #869760:  Learning rate = 0.000072:  Batch Loss = 0.981179, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9895973205566406, Accuracy = 1.0\n",
      "Iter #870080:  Learning rate = 0.000072:  Batch Loss = 0.976761, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9836016893386841, Accuracy = 1.0\n",
      "Iter #870400:  Learning rate = 0.000072:  Batch Loss = 0.978685, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9902921319007874, Accuracy = 1.0\n",
      "Iter #870720:  Learning rate = 0.000072:  Batch Loss = 1.153008, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9830558896064758, Accuracy = 1.0\n",
      "Iter #871040:  Learning rate = 0.000072:  Batch Loss = 0.978101, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9841351509094238, Accuracy = 1.0\n",
      "Iter #871360:  Learning rate = 0.000072:  Batch Loss = 0.981225, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9834516644477844, Accuracy = 1.0\n",
      "Iter #871680:  Learning rate = 0.000072:  Batch Loss = 1.165895, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.983333945274353, Accuracy = 1.0\n",
      "Iter #872000:  Learning rate = 0.000072:  Batch Loss = 0.977997, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9876347780227661, Accuracy = 1.0\n",
      "Iter #872320:  Learning rate = 0.000072:  Batch Loss = 0.966761, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.980593204498291, Accuracy = 1.0\n",
      "Iter #872640:  Learning rate = 0.000072:  Batch Loss = 0.968047, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9830923080444336, Accuracy = 1.0\n",
      "Iter #872960:  Learning rate = 0.000072:  Batch Loss = 0.969507, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9771008491516113, Accuracy = 1.0\n",
      "Iter #873280:  Learning rate = 0.000072:  Batch Loss = 0.970852, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9848710298538208, Accuracy = 1.0\n",
      "Iter #873600:  Learning rate = 0.000072:  Batch Loss = 0.970023, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9787033200263977, Accuracy = 1.0\n",
      "Iter #873920:  Learning rate = 0.000072:  Batch Loss = 0.963177, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.976040244102478, Accuracy = 1.0\n",
      "Iter #874240:  Learning rate = 0.000072:  Batch Loss = 0.967057, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9843374490737915, Accuracy = 1.0\n",
      "Iter #874560:  Learning rate = 0.000072:  Batch Loss = 0.961948, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9773011803627014, Accuracy = 1.0\n",
      "Iter #874880:  Learning rate = 0.000072:  Batch Loss = 0.966312, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9705461263656616, Accuracy = 1.0\n",
      "Iter #875200:  Learning rate = 0.000072:  Batch Loss = 0.963401, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9695866703987122, Accuracy = 1.0\n",
      "Iter #875520:  Learning rate = 0.000072:  Batch Loss = 0.966222, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9814809560775757, Accuracy = 1.0\n",
      "Iter #875840:  Learning rate = 0.000072:  Batch Loss = 0.960052, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9719294309616089, Accuracy = 1.0\n",
      "Iter #876160:  Learning rate = 0.000072:  Batch Loss = 0.960458, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9677866101264954, Accuracy = 1.0\n",
      "Iter #876480:  Learning rate = 0.000072:  Batch Loss = 0.990094, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9801833629608154, Accuracy = 1.0\n",
      "Iter #876800:  Learning rate = 0.000072:  Batch Loss = 0.968540, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9698741436004639, Accuracy = 1.0\n",
      "Iter #877120:  Learning rate = 0.000072:  Batch Loss = 1.124975, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9676602482795715, Accuracy = 1.0\n",
      "Iter #877440:  Learning rate = 0.000072:  Batch Loss = 0.953884, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9660256505012512, Accuracy = 1.0\n",
      "Iter #877760:  Learning rate = 0.000072:  Batch Loss = 0.954642, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9655548334121704, Accuracy = 1.0\n",
      "Iter #878080:  Learning rate = 0.000072:  Batch Loss = 0.957040, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9717714786529541, Accuracy = 1.0\n",
      "Iter #878400:  Learning rate = 0.000072:  Batch Loss = 0.954313, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9647250771522522, Accuracy = 1.0\n",
      "Iter #878720:  Learning rate = 0.000072:  Batch Loss = 0.951823, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9591745138168335, Accuracy = 1.0\n",
      "Iter #879040:  Learning rate = 0.000072:  Batch Loss = 1.141248, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9601287245750427, Accuracy = 1.0\n",
      "Iter #879360:  Learning rate = 0.000072:  Batch Loss = 0.948724, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9616528749465942, Accuracy = 1.0\n",
      "Iter #879680:  Learning rate = 0.000072:  Batch Loss = 0.952065, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9598466157913208, Accuracy = 1.0\n",
      "Iter #880000:  Learning rate = 0.000072:  Batch Loss = 0.949071, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9546879529953003, Accuracy = 1.0\n",
      "Iter #880320:  Learning rate = 0.000072:  Batch Loss = 0.944390, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9719274044036865, Accuracy = 1.0\n",
      "Iter #880640:  Learning rate = 0.000072:  Batch Loss = 0.964489, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9663420915603638, Accuracy = 1.0\n",
      "Iter #880960:  Learning rate = 0.000072:  Batch Loss = 0.945848, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9539828300476074, Accuracy = 1.0\n",
      "Iter #881280:  Learning rate = 0.000072:  Batch Loss = 1.119410, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9560648202896118, Accuracy = 1.0\n",
      "Iter #881600:  Learning rate = 0.000072:  Batch Loss = 0.944264, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9502184391021729, Accuracy = 1.0\n",
      "Iter #881920:  Learning rate = 0.000072:  Batch Loss = 1.091609, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9657517671585083, Accuracy = 1.0\n",
      "Iter #882240:  Learning rate = 0.000072:  Batch Loss = 0.944034, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9506939053535461, Accuracy = 1.0\n",
      "Iter #882560:  Learning rate = 0.000072:  Batch Loss = 0.966593, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9789624810218811, Accuracy = 1.0\n",
      "Iter #882880:  Learning rate = 0.000072:  Batch Loss = 0.938399, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.946982741355896, Accuracy = 1.0\n",
      "Iter #883200:  Learning rate = 0.000072:  Batch Loss = 0.938083, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9485601186752319, Accuracy = 1.0\n",
      "Iter #883520:  Learning rate = 0.000072:  Batch Loss = 0.938541, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.947143018245697, Accuracy = 1.0\n",
      "Iter #883840:  Learning rate = 0.000072:  Batch Loss = 0.935970, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9449882507324219, Accuracy = 1.0\n",
      "Iter #884160:  Learning rate = 0.000072:  Batch Loss = 0.933437, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.948169469833374, Accuracy = 1.0\n",
      "Iter #884480:  Learning rate = 0.000072:  Batch Loss = 0.933794, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.946172833442688, Accuracy = 1.0\n",
      "Iter #884800:  Learning rate = 0.000072:  Batch Loss = 0.933012, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9433472752571106, Accuracy = 1.0\n",
      "Iter #885120:  Learning rate = 0.000072:  Batch Loss = 0.934224, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9492257237434387, Accuracy = 1.0\n",
      "Iter #885440:  Learning rate = 0.000072:  Batch Loss = 0.931556, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9422537088394165, Accuracy = 1.0\n",
      "Iter #885760:  Learning rate = 0.000072:  Batch Loss = 0.940267, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9438429474830627, Accuracy = 1.0\n",
      "Iter #886080:  Learning rate = 0.000072:  Batch Loss = 0.930166, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9443520307540894, Accuracy = 1.0\n",
      "Iter #886400:  Learning rate = 0.000072:  Batch Loss = 0.933775, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9397850036621094, Accuracy = 1.0\n",
      "Iter #886720:  Learning rate = 0.000072:  Batch Loss = 0.934368, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9495828151702881, Accuracy = 1.0\n",
      "Iter #887040:  Learning rate = 0.000072:  Batch Loss = 0.936633, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9430424571037292, Accuracy = 1.0\n",
      "Iter #887360:  Learning rate = 0.000072:  Batch Loss = 1.047355, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.0106030702590942, Accuracy = 0.9666666388511658\n",
      "Iter #887680:  Learning rate = 0.000072:  Batch Loss = 1.152171, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9423579573631287, Accuracy = 1.0\n",
      "Iter #888000:  Learning rate = 0.000072:  Batch Loss = 0.926628, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9393513798713684, Accuracy = 1.0\n",
      "Iter #888320:  Learning rate = 0.000072:  Batch Loss = 0.927402, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9371413588523865, Accuracy = 1.0\n",
      "Iter #888640:  Learning rate = 0.000072:  Batch Loss = 0.927017, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9370792508125305, Accuracy = 1.0\n",
      "Iter #888960:  Learning rate = 0.000072:  Batch Loss = 0.933092, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9334126114845276, Accuracy = 1.0\n",
      "Iter #889280:  Learning rate = 0.000072:  Batch Loss = 0.923764, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9333063960075378, Accuracy = 1.0\n",
      "Iter #889600:  Learning rate = 0.000072:  Batch Loss = 0.924101, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9374659657478333, Accuracy = 1.0\n",
      "Iter #889920:  Learning rate = 0.000072:  Batch Loss = 0.924611, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9333921670913696, Accuracy = 1.0\n",
      "Iter #890240:  Learning rate = 0.000072:  Batch Loss = 0.923594, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9291287660598755, Accuracy = 1.0\n",
      "Iter #890560:  Learning rate = 0.000072:  Batch Loss = 1.068968, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9379959106445312, Accuracy = 1.0\n",
      "Iter #890880:  Learning rate = 0.000072:  Batch Loss = 0.924756, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9269208312034607, Accuracy = 1.0\n",
      "Iter #891200:  Learning rate = 0.000072:  Batch Loss = 0.923323, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.941049337387085, Accuracy = 1.0\n",
      "Iter #891520:  Learning rate = 0.000072:  Batch Loss = 0.920702, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9263309836387634, Accuracy = 1.0\n",
      "Iter #891840:  Learning rate = 0.000072:  Batch Loss = 0.920903, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9321420192718506, Accuracy = 1.0\n",
      "Iter #892160:  Learning rate = 0.000072:  Batch Loss = 0.914442, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9245233535766602, Accuracy = 1.0\n",
      "Iter #892480:  Learning rate = 0.000072:  Batch Loss = 0.912191, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.921690821647644, Accuracy = 1.0\n",
      "Iter #892800:  Learning rate = 0.000072:  Batch Loss = 0.918896, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.922198474407196, Accuracy = 1.0\n",
      "Iter #893120:  Learning rate = 0.000072:  Batch Loss = 0.921444, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9293922781944275, Accuracy = 1.0\n",
      "Iter #893440:  Learning rate = 0.000072:  Batch Loss = 0.910457, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9187600016593933, Accuracy = 1.0\n",
      "Iter #893760:  Learning rate = 0.000072:  Batch Loss = 0.908079, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.932039737701416, Accuracy = 1.0\n",
      "Iter #894080:  Learning rate = 0.000072:  Batch Loss = 0.908422, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9228683710098267, Accuracy = 1.0\n",
      "Iter #894400:  Learning rate = 0.000072:  Batch Loss = 1.116410, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9187483787536621, Accuracy = 1.0\n",
      "Iter #894720:  Learning rate = 0.000072:  Batch Loss = 0.915975, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9259136915206909, Accuracy = 1.0\n",
      "Iter #895040:  Learning rate = 0.000072:  Batch Loss = 0.911208, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9158673882484436, Accuracy = 1.0\n",
      "Iter #895360:  Learning rate = 0.000072:  Batch Loss = 0.905162, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9181911945343018, Accuracy = 1.0\n",
      "Iter #895680:  Learning rate = 0.000072:  Batch Loss = 0.910426, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9208257794380188, Accuracy = 1.0\n",
      "Iter #896000:  Learning rate = 0.000072:  Batch Loss = 0.904601, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9150822758674622, Accuracy = 1.0\n",
      "Iter #896320:  Learning rate = 0.000072:  Batch Loss = 0.922660, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9235737323760986, Accuracy = 1.0\n",
      "Iter #896640:  Learning rate = 0.000072:  Batch Loss = 0.904087, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.925385057926178, Accuracy = 0.9833333492279053\n",
      "Iter #896960:  Learning rate = 0.000072:  Batch Loss = 0.903367, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9148241877555847, Accuracy = 1.0\n",
      "Iter #897280:  Learning rate = 0.000072:  Batch Loss = 0.900624, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.926899254322052, Accuracy = 1.0\n",
      "Iter #897600:  Learning rate = 0.000072:  Batch Loss = 0.902895, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9088908433914185, Accuracy = 1.0\n",
      "Iter #897920:  Learning rate = 0.000072:  Batch Loss = 0.903013, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9052962064743042, Accuracy = 1.0\n",
      "Iter #898240:  Learning rate = 0.000072:  Batch Loss = 0.897434, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9205853343009949, Accuracy = 1.0\n",
      "Iter #898560:  Learning rate = 0.000072:  Batch Loss = 0.896188, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9073585271835327, Accuracy = 1.0\n",
      "Iter #898880:  Learning rate = 0.000072:  Batch Loss = 0.894157, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9109382033348083, Accuracy = 1.0\n",
      "Iter #899200:  Learning rate = 0.000072:  Batch Loss = 0.894075, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9065728783607483, Accuracy = 1.0\n",
      "Iter #899520:  Learning rate = 0.000072:  Batch Loss = 1.115453, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9014084935188293, Accuracy = 1.0\n",
      "Iter #899840:  Learning rate = 0.000072:  Batch Loss = 0.948258, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9431295394897461, Accuracy = 1.0\n",
      "Iter #900160:  Learning rate = 0.000069:  Batch Loss = 0.892743, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9041469693183899, Accuracy = 1.0\n",
      "Iter #900480:  Learning rate = 0.000069:  Batch Loss = 1.059806, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9026947021484375, Accuracy = 1.0\n",
      "Iter #900800:  Learning rate = 0.000069:  Batch Loss = 1.074772, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.902501106262207, Accuracy = 1.0\n",
      "Iter #901120:  Learning rate = 0.000069:  Batch Loss = 1.055786, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9038913249969482, Accuracy = 1.0\n",
      "Iter #901440:  Learning rate = 0.000069:  Batch Loss = 0.887241, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.901395320892334, Accuracy = 1.0\n",
      "Iter #901760:  Learning rate = 0.000069:  Batch Loss = 0.896758, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9115533232688904, Accuracy = 1.0\n",
      "Iter #902080:  Learning rate = 0.000069:  Batch Loss = 0.887246, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8971708416938782, Accuracy = 1.0\n",
      "Iter #902400:  Learning rate = 0.000069:  Batch Loss = 0.901579, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8992488980293274, Accuracy = 1.0\n",
      "Iter #902720:  Learning rate = 0.000069:  Batch Loss = 0.888561, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.89518803358078, Accuracy = 1.0\n",
      "Iter #903040:  Learning rate = 0.000069:  Batch Loss = 0.897703, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.909211277961731, Accuracy = 1.0\n",
      "Iter #903360:  Learning rate = 0.000069:  Batch Loss = 0.882429, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8942359089851379, Accuracy = 1.0\n",
      "Iter #903680:  Learning rate = 0.000069:  Batch Loss = 0.888238, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9064627289772034, Accuracy = 1.0\n",
      "Iter #904000:  Learning rate = 0.000069:  Batch Loss = 1.063483, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8920819759368896, Accuracy = 1.0\n",
      "Iter #904320:  Learning rate = 0.000069:  Batch Loss = 0.880905, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8970312476158142, Accuracy = 1.0\n",
      "Iter #904640:  Learning rate = 0.000069:  Batch Loss = 0.883559, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8907530903816223, Accuracy = 1.0\n",
      "Iter #904960:  Learning rate = 0.000069:  Batch Loss = 0.879995, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.891359806060791, Accuracy = 1.0\n",
      "Iter #905280:  Learning rate = 0.000069:  Batch Loss = 0.876725, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8906365036964417, Accuracy = 1.0\n",
      "Iter #905600:  Learning rate = 0.000069:  Batch Loss = 0.885760, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8880325555801392, Accuracy = 1.0\n",
      "Iter #905920:  Learning rate = 0.000069:  Batch Loss = 1.033249, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8934100270271301, Accuracy = 1.0\n",
      "Iter #906240:  Learning rate = 0.000069:  Batch Loss = 0.875522, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8913581371307373, Accuracy = 1.0\n",
      "Iter #906560:  Learning rate = 0.000069:  Batch Loss = 0.874861, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8925965428352356, Accuracy = 1.0\n",
      "Iter #906880:  Learning rate = 0.000069:  Batch Loss = 0.880075, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8929600119590759, Accuracy = 1.0\n",
      "Iter #907200:  Learning rate = 0.000069:  Batch Loss = 0.872754, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8856068849563599, Accuracy = 1.0\n",
      "Iter #907520:  Learning rate = 0.000069:  Batch Loss = 0.882147, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8904604315757751, Accuracy = 1.0\n",
      "Iter #907840:  Learning rate = 0.000069:  Batch Loss = 1.056067, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8817561268806458, Accuracy = 1.0\n",
      "Iter #908160:  Learning rate = 0.000069:  Batch Loss = 0.874035, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8852083683013916, Accuracy = 1.0\n",
      "Iter #908480:  Learning rate = 0.000069:  Batch Loss = 0.869678, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8813820481300354, Accuracy = 1.0\n",
      "Iter #908800:  Learning rate = 0.000069:  Batch Loss = 0.869449, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8806479573249817, Accuracy = 1.0\n",
      "Iter #909120:  Learning rate = 0.000069:  Batch Loss = 0.876607, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8902241587638855, Accuracy = 1.0\n",
      "Iter #909440:  Learning rate = 0.000069:  Batch Loss = 0.870627, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8855739235877991, Accuracy = 1.0\n",
      "Iter #909760:  Learning rate = 0.000069:  Batch Loss = 0.883098, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9058160185813904, Accuracy = 1.0\n",
      "Iter #910080:  Learning rate = 0.000069:  Batch Loss = 0.865434, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8781595230102539, Accuracy = 1.0\n",
      "Iter #910400:  Learning rate = 0.000069:  Batch Loss = 0.867515, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8749678134918213, Accuracy = 1.0\n",
      "Iter #910720:  Learning rate = 0.000069:  Batch Loss = 0.866649, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.887158989906311, Accuracy = 1.0\n",
      "Iter #911040:  Learning rate = 0.000069:  Batch Loss = 1.039393, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.873467206954956, Accuracy = 1.0\n",
      "Iter #911360:  Learning rate = 0.000069:  Batch Loss = 0.894807, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.9102557301521301, Accuracy = 1.0\n",
      "Iter #911680:  Learning rate = 0.000069:  Batch Loss = 0.862053, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.898738443851471, Accuracy = 0.9833333492279053\n",
      "Iter #912000:  Learning rate = 0.000069:  Batch Loss = 0.867671, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8823622465133667, Accuracy = 1.0\n",
      "Iter #912320:  Learning rate = 0.000069:  Batch Loss = 0.863393, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.875752866268158, Accuracy = 1.0\n",
      "Iter #912640:  Learning rate = 0.000069:  Batch Loss = 0.868675, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8722718954086304, Accuracy = 1.0\n",
      "Iter #912960:  Learning rate = 0.000069:  Batch Loss = 0.859473, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8736699223518372, Accuracy = 1.0\n",
      "Iter #913280:  Learning rate = 0.000069:  Batch Loss = 0.858571, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8713408708572388, Accuracy = 1.0\n",
      "Iter #913600:  Learning rate = 0.000069:  Batch Loss = 0.856411, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8756843209266663, Accuracy = 1.0\n",
      "Iter #913920:  Learning rate = 0.000069:  Batch Loss = 0.858186, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8687543272972107, Accuracy = 1.0\n",
      "Iter #914240:  Learning rate = 0.000069:  Batch Loss = 0.854133, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8797022700309753, Accuracy = 1.0\n",
      "Iter #914560:  Learning rate = 0.000069:  Batch Loss = 1.112227, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8699495196342468, Accuracy = 1.0\n",
      "Iter #914880:  Learning rate = 0.000069:  Batch Loss = 0.854570, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8658960461616516, Accuracy = 1.0\n",
      "Iter #915200:  Learning rate = 0.000069:  Batch Loss = 0.853203, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8626697063446045, Accuracy = 1.0\n",
      "Iter #915520:  Learning rate = 0.000069:  Batch Loss = 0.856249, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8649439811706543, Accuracy = 1.0\n",
      "Iter #915840:  Learning rate = 0.000069:  Batch Loss = 0.853206, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8612450361251831, Accuracy = 1.0\n",
      "Iter #916160:  Learning rate = 0.000069:  Batch Loss = 0.861181, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8725104928016663, Accuracy = 1.0\n",
      "Iter #916480:  Learning rate = 0.000069:  Batch Loss = 0.848873, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8660596609115601, Accuracy = 1.0\n",
      "Iter #916800:  Learning rate = 0.000069:  Batch Loss = 0.853635, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8625656366348267, Accuracy = 1.0\n",
      "Iter #917120:  Learning rate = 0.000069:  Batch Loss = 0.851592, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8671746253967285, Accuracy = 1.0\n",
      "Iter #917440:  Learning rate = 0.000069:  Batch Loss = 0.854461, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8790062069892883, Accuracy = 1.0\n",
      "Iter #917760:  Learning rate = 0.000069:  Batch Loss = 0.847325, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.863560140132904, Accuracy = 1.0\n",
      "Iter #918080:  Learning rate = 0.000069:  Batch Loss = 0.845605, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8586946129798889, Accuracy = 1.0\n",
      "Iter #918400:  Learning rate = 0.000069:  Batch Loss = 0.843625, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8642997741699219, Accuracy = 1.0\n",
      "Iter #918720:  Learning rate = 0.000069:  Batch Loss = 1.007546, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8588189482688904, Accuracy = 1.0\n",
      "Iter #919040:  Learning rate = 0.000069:  Batch Loss = 0.845028, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8577866554260254, Accuracy = 1.0\n",
      "Iter #919360:  Learning rate = 0.000069:  Batch Loss = 0.842548, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.858681321144104, Accuracy = 1.0\n",
      "Iter #919680:  Learning rate = 0.000069:  Batch Loss = 0.846758, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8625881671905518, Accuracy = 1.0\n",
      "Iter #920000:  Learning rate = 0.000069:  Batch Loss = 0.840861, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8576505184173584, Accuracy = 1.0\n",
      "Iter #920320:  Learning rate = 0.000069:  Batch Loss = 0.842762, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8550030589103699, Accuracy = 1.0\n",
      "Iter #920640:  Learning rate = 0.000069:  Batch Loss = 0.842060, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8550349473953247, Accuracy = 1.0\n",
      "Iter #920960:  Learning rate = 0.000069:  Batch Loss = 2.336897, Accuracy = 0.6875\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 1.6898157596588135, Accuracy = 0.8166666626930237\n",
      "Iter #921280:  Learning rate = 0.000069:  Batch Loss = 0.843730, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8533974289894104, Accuracy = 1.0\n",
      "Iter #921600:  Learning rate = 0.000069:  Batch Loss = 0.848071, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.856999933719635, Accuracy = 1.0\n",
      "Iter #921920:  Learning rate = 0.000069:  Batch Loss = 0.845795, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8517295718193054, Accuracy = 1.0\n",
      "Iter #922240:  Learning rate = 0.000069:  Batch Loss = 0.842620, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.851351261138916, Accuracy = 1.0\n",
      "Iter #922560:  Learning rate = 0.000069:  Batch Loss = 0.842676, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8498616218566895, Accuracy = 1.0\n",
      "Iter #922880:  Learning rate = 0.000069:  Batch Loss = 0.842002, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8483666181564331, Accuracy = 1.0\n",
      "Iter #923200:  Learning rate = 0.000069:  Batch Loss = 0.838354, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8502932190895081, Accuracy = 1.0\n",
      "Iter #923520:  Learning rate = 0.000069:  Batch Loss = 0.839085, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8500520586967468, Accuracy = 1.0\n",
      "Iter #923840:  Learning rate = 0.000069:  Batch Loss = 0.837965, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8610934019088745, Accuracy = 1.0\n",
      "Iter #924160:  Learning rate = 0.000069:  Batch Loss = 0.839360, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8534978628158569, Accuracy = 1.0\n",
      "Iter #924480:  Learning rate = 0.000069:  Batch Loss = 0.837175, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8485280275344849, Accuracy = 1.0\n",
      "Iter #924800:  Learning rate = 0.000069:  Batch Loss = 0.835453, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8570961356163025, Accuracy = 1.0\n",
      "Iter #925120:  Learning rate = 0.000069:  Batch Loss = 0.838049, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8500350117683411, Accuracy = 1.0\n",
      "Iter #925440:  Learning rate = 0.000069:  Batch Loss = 0.836773, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8586647510528564, Accuracy = 1.0\n",
      "Iter #925760:  Learning rate = 0.000069:  Batch Loss = 0.834742, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8499926924705505, Accuracy = 1.0\n",
      "Iter #926080:  Learning rate = 0.000069:  Batch Loss = 0.837814, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8528026342391968, Accuracy = 1.0\n",
      "Iter #926400:  Learning rate = 0.000069:  Batch Loss = 0.833821, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8497446775436401, Accuracy = 1.0\n",
      "Iter #926720:  Learning rate = 0.000069:  Batch Loss = 0.839590, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8542569875717163, Accuracy = 1.0\n",
      "Iter #927040:  Learning rate = 0.000069:  Batch Loss = 0.834394, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8552094101905823, Accuracy = 1.0\n",
      "Iter #927360:  Learning rate = 0.000069:  Batch Loss = 0.833248, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8503963351249695, Accuracy = 1.0\n",
      "Iter #927680:  Learning rate = 0.000069:  Batch Loss = 0.833923, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8526818156242371, Accuracy = 1.0\n",
      "Iter #928000:  Learning rate = 0.000069:  Batch Loss = 0.836640, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8486226201057434, Accuracy = 1.0\n",
      "Iter #928320:  Learning rate = 0.000069:  Batch Loss = 0.842102, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.857074499130249, Accuracy = 1.0\n",
      "Iter #928640:  Learning rate = 0.000069:  Batch Loss = 0.836214, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8485249280929565, Accuracy = 1.0\n",
      "Iter #928960:  Learning rate = 0.000069:  Batch Loss = 0.832617, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.848686695098877, Accuracy = 1.0\n",
      "Iter #929280:  Learning rate = 0.000069:  Batch Loss = 0.833467, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8527795076370239, Accuracy = 1.0\n",
      "Iter #929600:  Learning rate = 0.000069:  Batch Loss = 0.852656, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8572807908058167, Accuracy = 1.0\n",
      "Iter #929920:  Learning rate = 0.000069:  Batch Loss = 0.831386, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8496547937393188, Accuracy = 1.0\n",
      "Iter #930240:  Learning rate = 0.000069:  Batch Loss = 0.831292, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8592175841331482, Accuracy = 1.0\n",
      "Iter #930560:  Learning rate = 0.000069:  Batch Loss = 0.966573, Accuracy = 0.9375\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.850296676158905, Accuracy = 1.0\n",
      "Iter #930880:  Learning rate = 0.000069:  Batch Loss = 0.830352, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.846063494682312, Accuracy = 1.0\n",
      "Iter #931200:  Learning rate = 0.000069:  Batch Loss = 0.830026, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8505253195762634, Accuracy = 1.0\n",
      "Iter #931520:  Learning rate = 0.000069:  Batch Loss = 0.829724, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.854026734828949, Accuracy = 1.0\n",
      "Iter #931840:  Learning rate = 0.000069:  Batch Loss = 0.835483, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8530304431915283, Accuracy = 1.0\n",
      "Iter #932160:  Learning rate = 0.000069:  Batch Loss = 0.829527, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8471071124076843, Accuracy = 1.0\n",
      "Iter #932480:  Learning rate = 0.000069:  Batch Loss = 0.829203, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8612883687019348, Accuracy = 1.0\n",
      "Iter #932800:  Learning rate = 0.000069:  Batch Loss = 0.829222, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8498210906982422, Accuracy = 0.9833333492279053\n",
      "Iter #933120:  Learning rate = 0.000069:  Batch Loss = 0.854876, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8640501499176025, Accuracy = 1.0\n",
      "Iter #933440:  Learning rate = 0.000069:  Batch Loss = 0.831342, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8471342325210571, Accuracy = 1.0\n",
      "Iter #933760:  Learning rate = 0.000069:  Batch Loss = 0.827954, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8396204113960266, Accuracy = 1.0\n",
      "Iter #934080:  Learning rate = 0.000069:  Batch Loss = 0.828452, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8505072593688965, Accuracy = 1.0\n",
      "Iter #934400:  Learning rate = 0.000069:  Batch Loss = 0.827018, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8468719720840454, Accuracy = 1.0\n",
      "Iter #934720:  Learning rate = 0.000069:  Batch Loss = 0.826857, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8449671268463135, Accuracy = 1.0\n",
      "Iter #935040:  Learning rate = 0.000069:  Batch Loss = 0.826447, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8613816499710083, Accuracy = 1.0\n",
      "Iter #935360:  Learning rate = 0.000069:  Batch Loss = 0.832736, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8428215980529785, Accuracy = 1.0\n",
      "Iter #935680:  Learning rate = 0.000069:  Batch Loss = 0.828848, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8382907509803772, Accuracy = 1.0\n",
      "Iter #936000:  Learning rate = 0.000069:  Batch Loss = 0.826073, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8383358716964722, Accuracy = 1.0\n",
      "Iter #936320:  Learning rate = 0.000069:  Batch Loss = 0.834385, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8489916324615479, Accuracy = 1.0\n",
      "Iter #936640:  Learning rate = 0.000069:  Batch Loss = 0.825304, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8355738520622253, Accuracy = 1.0\n",
      "Iter #936960:  Learning rate = 0.000069:  Batch Loss = 0.827349, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8700017333030701, Accuracy = 1.0\n",
      "Iter #937280:  Learning rate = 0.000069:  Batch Loss = 0.825175, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8432251214981079, Accuracy = 1.0\n",
      "Iter #937600:  Learning rate = 0.000069:  Batch Loss = 0.836683, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8555476665496826, Accuracy = 1.0\n",
      "Iter #937920:  Learning rate = 0.000069:  Batch Loss = 0.829904, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8382445573806763, Accuracy = 1.0\n",
      "Iter #938240:  Learning rate = 0.000069:  Batch Loss = 0.825412, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8459452986717224, Accuracy = 1.0\n",
      "Iter #938560:  Learning rate = 0.000069:  Batch Loss = 0.827569, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.836760401725769, Accuracy = 1.0\n",
      "Iter #938880:  Learning rate = 0.000069:  Batch Loss = 0.842854, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.860136091709137, Accuracy = 1.0\n",
      "Iter #939200:  Learning rate = 0.000069:  Batch Loss = 0.828626, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8389534950256348, Accuracy = 1.0\n",
      "Iter #939520:  Learning rate = 0.000069:  Batch Loss = 0.843888, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.8511661291122437, Accuracy = 1.0\n",
      "Iter #939840:  Learning rate = 0.000069:  Batch Loss = 0.825227, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET:          Batch Loss = 0.840682327747345, Accuracy = 1.0\n",
      "Optimization Finished!\n",
      "TOTAL TRAINING TIME: 530.1851415634155\n",
      "Model saved in path: C:\\\\Users\\\\admin\\\\Downloads\\\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\\\weights\\model.ckpt\n",
      "\n",
      "--- Final Evaluation on Test Set (after training) ---\n",
      "FINAL RESULT: Batch Loss = 0.839375376701355, Accuracy = 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[15  0  0  0]\n",
      " [ 0 15  0  0]\n",
      " [ 0  0 15  0]\n",
      " [ 0  0  0 15]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "import random\n",
    "from random import randint\n",
    "import time\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "# TensorFlow 1.x\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# ---  ---\n",
    "\n",
    "# Output classes to learn how to classify\n",
    "LABELS = [\n",
    "    \"ageru\",\n",
    "    \"understand\",\n",
    "    \"annsinnsuru\",\n",
    "    \"heavy\"\n",
    "]\n",
    "\n",
    "# \n",
    "DATASET_PATH = \"data/HAR_pose_activities/database/\"\n",
    "X_train_path = os.path.join(DATASET_PATH, \"X_train.txt\")\n",
    "X_test_path = os.path.join(DATASET_PATH, \"X_test.txt\")\n",
    "y_train_path = os.path.join(DATASET_PATH, \"Y_train.txt\")\n",
    "y_test_path = os.path.join(DATASET_PATH, \"Y_test.txt\")\n",
    "\n",
    "#   \n",
    "MODEL_SAVE_PATH = r\"C:\\\\Users\\\\admin\\\\Downloads\\\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\\\weights\"\n",
    "if not os.path.exists(MODEL_SAVE_PATH):\n",
    "    os.makedirs(MODEL_SAVE_PATH)\n",
    "\n",
    "\n",
    "# ---  () ---\n",
    "n_steps = 30\n",
    "\n",
    "def load_X(X_path):\n",
    "    file = open(X_path, 'r')\n",
    "    X_ = np.array(\n",
    "        [elem for elem in [\n",
    "            row.split(',') for row in file\n",
    "        ]],\n",
    "        dtype=np.float32\n",
    "    )\n",
    "    file.close()\n",
    "    blocks = int(len(X_) / n_steps)\n",
    "    X_ = np.array(np.split(X_, blocks))\n",
    "    return X_\n",
    "\n",
    "def load_y(y_path):\n",
    "    file = open(y_path, 'r')\n",
    "    y_ = np.array(\n",
    "        [elem for elem in [\n",
    "            row.replace('  ', ' ').strip().split(' ') for row in file\n",
    "        ]],\n",
    "        dtype=np.int32\n",
    "    )\n",
    "    file.close()\n",
    "    return y_ - 1\n",
    "\n",
    "X_train = load_X(X_train_path)\n",
    "X_test = load_X(X_test_path)\n",
    "y_train = load_y(y_train_path)\n",
    "y_test = load_y(y_test_path)\n",
    "\n",
    "# ---  () ---\n",
    "training_data_count = len(X_train)\n",
    "test_data_count = len(X_test)\n",
    "n_input = len(X_train[0][0])\n",
    "n_hidden = 34\n",
    "n_classes = 4\n",
    "decaying_learning_rate = True\n",
    "learning_rate = 0.0001\n",
    "init_learning_rate = 0.0001\n",
    "decay_rate = 0.96\n",
    "decay_steps = 100000\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "lambda_loss_amount = 0.01\n",
    "training_iters = training_data_count * 1700\n",
    "batch_size = 16\n",
    "display_iter = batch_size * 20\n",
    "\n",
    "print(\"(X shape, y shape, every X's mean, every X's standard deviation)\")\n",
    "print(X_train.shape, y_test.shape, np.mean(X_test), np.std(X_test))\n",
    "print(\"\\nThe dataset has not been preprocessed, is not normalised etc\")\n",
    "\n",
    "# --- LSTM () ---\n",
    "def LSTM_RNN(_X, _weights, _biases):\n",
    "    _X = tf.transpose(_X, [1, 0, 2])\n",
    "    _X = tf.reshape(_X, [-1, n_input])\n",
    "    _X = tf.nn.relu(tf.matmul(_X, _weights['hidden']) + _biases['hidden'])\n",
    "    _X = tf.split(_X, n_steps, 0)\n",
    "    lstm_cell_1 = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
    "    lstm_cell_2 = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
    "    lstm_cells = tf.contrib.rnn.MultiRNNCell([lstm_cell_1, lstm_cell_2], state_is_tuple=True)\n",
    "    outputs, states = tf.contrib.rnn.static_rnn(lstm_cells, _X, dtype=tf.float32)\n",
    "    lstm_last_output = outputs[-1]\n",
    "    return tf.matmul(lstm_last_output, _weights['out']) + _biases['out']\n",
    "\n",
    "def extract_batch_size(_train, _labels, _unsampled, batch_size):\n",
    "    shape = list(_train.shape)\n",
    "    shape[0] = batch_size\n",
    "    batch_s = np.empty(shape)\n",
    "    batch_labels = np.empty((batch_size, 1))\n",
    "    for i in range(batch_size):\n",
    "        index = random.choice(_unsampled)\n",
    "        batch_s[i] = _train[index]\n",
    "        batch_labels[i] = _labels[index]\n",
    "        _unsampled.remove(index)\n",
    "    return batch_s, batch_labels, _unsampled\n",
    "\n",
    "def one_hot(y_):\n",
    "    y_ = y_.reshape(len(y_))\n",
    "    n_values = n_classes\n",
    "    return np.eye(n_values)[np.array(y_, dtype=np.int32)]\n",
    "\n",
    "# --- TensorFlow () ---\n",
    "x = tf.placeholder(tf.float32, [None, n_steps, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([n_input, n_hidden]), name=\"weights_hidden\"),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes], mean=1.0), name=\"weights_out\")\n",
    "}\n",
    "biases = {\n",
    "    'hidden': tf.Variable(tf.random_normal([n_hidden]), name=\"biases_hidden\"),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]), name=\"biases_out\")\n",
    "}\n",
    "pred = LSTM_RNN(x, weights, biases)\n",
    "l2 = lambda_loss_amount * sum(tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables())\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred)) + l2\n",
    "if decaying_learning_rate:\n",
    "    learning_rate = tf.train.exponential_decay(init_learning_rate, global_step * batch_size, decay_steps, decay_rate, staircase=True)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost, global_step=global_step)\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "#  Saver \n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "# --- Plotting additions start ---\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "# --- Plotting additions end ---\n",
    "\n",
    "# ---  ---\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(log_device_placement=False))\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "step = 1\n",
    "time_start = time.time()\n",
    "unsampled_indices = list(range(0, len(X_train)))\n",
    "\n",
    "while step * batch_size <= training_iters:\n",
    "    if len(unsampled_indices) < batch_size:\n",
    "        unsampled_indices = list(range(0, len(X_train)))\n",
    "    batch_xs, raw_labels, unsampled_indices = extract_batch_size(X_train, y_train, unsampled_indices, batch_size)\n",
    "    batch_ys = one_hot(raw_labels)\n",
    "    if len(batch_ys[0]) < n_classes:\n",
    "        temp_ys = np.zeros((batch_size, n_classes))\n",
    "        temp_ys[:batch_ys.shape[0], :batch_ys.shape[1]] = batch_ys\n",
    "        batch_ys = temp_ys\n",
    "    \n",
    "    _, loss, acc = sess.run([optimizer, cost, accuracy], feed_dict={x: batch_xs, y: batch_ys})\n",
    "    \n",
    "    # --- Plotting additions start ---\n",
    "    train_losses.append(loss)\n",
    "    train_accuracies.append(acc)\n",
    "    # --- Plotting additions end ---\n",
    "\n",
    "    if (step * batch_size % display_iter == 0) or (step == 1) or (step * batch_size > training_iters):\n",
    "        print(\"Iter #\" + str(step * batch_size) + \\\n",
    "              \":  Learning rate = \" + \"{:.6f}\".format(sess.run(learning_rate)) + \\\n",
    "              \":  Batch Loss = \" + \"{:.6f}\".format(loss) + \\\n",
    "              \", Accuracy = {}\".format(acc))\n",
    "        \n",
    "        loss_test, acc_test = sess.run([cost, accuracy], feed_dict={x: X_test, y: one_hot(y_test)})\n",
    "        \n",
    "        # --- Plotting additions start ---\n",
    "        test_losses.append(loss_test)\n",
    "        test_accuracies.append(acc_test)\n",
    "        # --- Plotting additions end ---\n",
    "\n",
    "        print(\"PERFORMANCE ON TEST SET:          \" + \\\n",
    "              \"Batch Loss = {}\".format(loss_test) + \\\n",
    "              \", Accuracy = {}\".format(acc_test))\n",
    "\n",
    "    step += 1\n",
    "\n",
    "print(\"Optimization Finished!\")\n",
    "time_stop = time.time()\n",
    "print(\"TOTAL TRAINING TIME: {}\".format(time_stop - time_start))\n",
    "\n",
    "#   \n",
    "save_path = saver.save(sess, os.path.join(MODEL_SAVE_PATH, \"model.ckpt\"))\n",
    "print(f\"Model saved in path: {save_path}\")\n",
    "\n",
    "\n",
    "# ---  (train.py) ---\n",
    "print(\"\\n--- Final Evaluation on Test Set (after training) ---\")\n",
    "one_hot_predictions, final_accuracy, final_loss = sess.run(\n",
    "    [pred, accuracy, cost],\n",
    "    feed_dict={\n",
    "        x: X_test,\n",
    "        y: one_hot(y_test)\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"FINAL RESULT: \" + \\\n",
    "      \"Batch Loss = {}\".format(final_loss) + \\\n",
    "      \", Accuracy = {}\".format(final_accuracy))\n",
    "\n",
    "# --- Plotting additions start ---\n",
    "font = {\n",
    "    'family' : 'Bitstream Vera Sans',\n",
    "    'weight' : 'bold',\n",
    "    'size'   : 18\n",
    "}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "width = 12\n",
    "height = 12\n",
    "plt.figure(figsize=(width, height))\n",
    "\n",
    "indep_train_axis = np.array(range(batch_size, (len(train_losses)+1)*batch_size, batch_size))\n",
    "plt.plot(indep_train_axis, np.array(train_accuracies), \"g--\", label=\"Train accuracies\")\n",
    "\n",
    "indep_test_axis = np.append(\n",
    "    np.array(range(batch_size, len(test_losses)*display_iter, display_iter)[:-1]),\n",
    "    [training_iters]\n",
    ")\n",
    "plt.plot(indep_test_axis, np.array(test_accuracies), \"b-\", linewidth=2.0, label=\"Test accuracies\")\n",
    "\n",
    "plt.title(\"Training session's Accuracy over Iterations\")\n",
    "plt.legend(loc='lower right', shadow=True)\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.xlabel('Training Iteration')\n",
    "plt.show()\n",
    "\n",
    "# Loss\n",
    "plt.figure(figsize=(width, height))\n",
    "plt.plot(indep_train_axis, np.array(train_losses), \"r--\", label=\"Train losses\")\n",
    "plt.plot(indep_test_axis, np.array(test_losses), \"k-\", linewidth=2.0, label=\"Validation losses\")\n",
    "plt.title(\"Training session's Loss over Iterations\")\n",
    "plt.legend(loc='upper right', shadow=True)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Training Iteration')\n",
    "plt.show()\n",
    "# --- Plotting additions end ---\n",
    "\n",
    "# \n",
    "predictions = one_hot_predictions.argmax(1)\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, predictions)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix)\n",
    "\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RNNhumanactivityrecognize",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

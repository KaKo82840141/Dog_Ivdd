{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f4ab880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote MediaPipe 42-point data for ageru video 1 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\ageru\\agerul01_c01_s01_a01_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for ageru video 2 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\ageru\\agerul01_c01_s02_a01_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for ageru video 3 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\ageru\\agerul01_c01_s03_a01_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for ageru video 4 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\ageru\\agerul01_c01_s04_a01_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for ageru video 5 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\ageru\\agerul01_c01_s05_a01_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for ageru video 6 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\ageru\\agerul01_c01_s06_a01_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for ageru video 7 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\ageru\\agerul01_c01_s07_a01_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for ageru video 8 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\ageru\\agerul01_c01_s08_a01_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for ageru video 9 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\ageru\\agerul01_c01_s09_a01_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for ageru video 10 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\ageru\\agerul01_c01_s10_a01_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for ageru video 11 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\ageru\\agerul01_c01_s11_a01_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for ageru video 12 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\ageru\\agerul01_c01_s12_a01_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for ageru video 13 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\ageru\\agerul01_c01_s13_a01_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for ageru video 14 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\ageru\\agerul01_c01_s14_a01_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for ageru video 15 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\ageru\\agerul01_c01_s15_a01_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for understand video 1 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\understand\\understandl01_c01_s01_a02_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for understand video 2 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\understand\\understandl01_c01_s02_a02_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for understand video 3 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\understand\\understandl01_c01_s03_a02_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for understand video 4 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\understand\\understandl01_c01_s04_a02_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for understand video 5 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\understand\\understandl01_c01_s05_a02_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for understand video 6 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\understand\\understandl01_c01_s06_a02_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for understand video 7 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\understand\\understandl01_c01_s07_a02_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for understand video 8 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\understand\\understandl01_c01_s08_a02_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for understand video 9 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\understand\\understandl01_c01_s09_a02_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for understand video 10 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\understand\\understandl01_c01_s10_a02_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for understand video 11 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\understand\\understandl01_c01_s11_a02_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for understand video 12 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\understand\\understandl01_c01_s12_a02_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for understand video 13 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\understand\\understandl01_c01_s13_a02_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for understand video 14 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\understand\\understandl01_c01_s14_a02_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for understand video 15 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\understand\\understandl01_c01_s15_a02_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for annsinnsuru video 1 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\annsinnsuru\\annsinnsurul01_c01_s01_a03_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for annsinnsuru video 2 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\annsinnsuru\\annsinnsurul01_c01_s02_a03_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for annsinnsuru video 3 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\annsinnsuru\\annsinnsurul01_c01_s03_a03_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for annsinnsuru video 4 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\annsinnsuru\\annsinnsurul01_c01_s04_a03_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for annsinnsuru video 5 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\annsinnsuru\\annsinnsurul01_c01_s05_a03_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for annsinnsuru video 6 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\annsinnsuru\\annsinnsurul01_c01_s06_a03_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for annsinnsuru video 7 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\annsinnsuru\\annsinnsurul01_c01_s07_a03_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for annsinnsuru video 8 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\annsinnsuru\\annsinnsurul01_c01_s08_a03_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for annsinnsuru video 9 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\annsinnsuru\\annsinnsurul01_c01_s09_a03_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for annsinnsuru video 10 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\annsinnsuru\\annsinnsurul01_c01_s10_a03_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for annsinnsuru video 11 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\annsinnsuru\\annsinnsurul01_c01_s11_a03_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for annsinnsuru video 12 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\annsinnsuru\\annsinnsurul01_c01_s12_a03_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for annsinnsuru video 13 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\annsinnsuru\\annsinnsurul01_c01_s13_a03_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for annsinnsuru video 14 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\annsinnsuru\\annsinnsurul01_c01_s14_a03_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for annsinnsuru video 15 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\annsinnsuru\\annsinnsurul01_c01_s15_a03_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for heavy video 1 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\heavy\\heavyl01_c01_s01_a04_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for heavy video 2 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\heavy\\heavyl01_c01_s02_a04_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for heavy video 3 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\heavy\\heavyl01_c01_s03_a04_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for heavy video 4 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\heavy\\heavyl01_c01_s04_a04_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for heavy video 5 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\heavy\\heavyl01_c01_s05_a04_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for heavy video 6 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\heavy\\heavyl01_c01_s06_a04_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for heavy video 7 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\heavy\\heavyl01_c01_s07_a04_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for heavy video 8 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\heavy\\heavyl01_c01_s08_a04_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for heavy video 9 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\heavy\\heavyl01_c01_s09_a04_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for heavy video 10 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\heavy\\heavyl01_c01_s10_a04_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for heavy video 11 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\heavy\\heavyl01_c01_s11_a04_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for heavy video 12 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\heavy\\heavyl01_c01_s12_a04_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for heavy video 13 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\heavy\\heavyl01_c01_s13_a04_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for heavy video 14 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\heavy\\heavyl01_c01_s14_a04_r01_mp33.txt\n",
      "Successfully wrote MediaPipe 42-point data for heavy video 15 to C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\heavy\\heavyl01_c01_s15_a04_r01_mp33.txt\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Converts output of MediaPipe (.json) to a .txt file using all 33 pose keypoints.\n",
    "(Adapted from a script originally for OpenPose output)\n",
    "creat_db.py is required to be run after this script to merge all text files into format required for RNN for Human Activity Recognition - (Now 33*2D Pose Input)\n",
    "\n",
    "Original OpenPose script by Stuart Eiffert 13/12/2017\n",
    "Modifications for MediaPipe (33 points) by Your Name/AI 2025/05/28\n",
    "\n",
    "All code is provided under the MIT License (assuming original license applies)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import json\n",
    "from pprint import pprint # Keep for debugging if needed\n",
    "import glob, os\n",
    "import numpy as np # For handling missing keypoints\n",
    "\n",
    "# --- Configuration based on your MediaPipe script ---\n",
    "data_path = os.path.join(os.getcwd(), r'C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON')\n",
    "#activity_list = np.array(['heel_hook', 'deadpoint', 'dyno','cross_move'])\n",
    "activity_list = np.array(['ageru', 'understand', 'annsinnsuru' , 'heavy'])\n",
    "num_videos_per_action =15 #10#90 \n",
    "\n",
    "fixed_cluster_num = 1\n",
    "fixed_camera_num = 1\n",
    "fixed_repetition_num = 1\n",
    "\n",
    "# Number of keypoints from MediaPipe Pose (33 landmarks)\n",
    "NUM_MEDIAPIPE_KEYPOINTS = 42 #12\n",
    "NUM_OUTPUT_VALUES = NUM_MEDIAPIPE_KEYPOINTS * 2 # x and y for each keypoint\n",
    "\n",
    "# Loop through actions (activities) and videos (subjects)\n",
    "for activity_idx, activity_name in enumerate(activity_list):\n",
    "    for video_num_loop in range(1, num_videos_per_action + 1):\n",
    "\n",
    "        subject_num_str = str(video_num_loop)\n",
    "        if video_num_loop < 10:\n",
    "            subject_num_str = \"0\" + subject_num_str\n",
    "\n",
    "        activity_num_str = str(activity_idx + 1)\n",
    "        if activity_idx + 1 < 10:\n",
    "             activity_num_str = \"0\" + activity_num_str\n",
    "\n",
    "        frame_set = f\"l0{fixed_cluster_num}_c0{fixed_camera_num}_s{subject_num_str}_a{activity_num_str}_r0{fixed_repetition_num}\"\n",
    "        current_video_json_path = os.path.join(data_path, activity_name, str(video_num_loop))\n",
    "\n",
    "        if not os.path.isdir(current_video_json_path):\n",
    "            print(f\"Warning: Directory not found, skipping: {current_video_json_path}\")\n",
    "            continue\n",
    "\n",
    "        os.chdir(current_video_json_path)\n",
    "\n",
    "        kps_all_frames = []\n",
    "\n",
    "        json_files = sorted(glob.glob(\"*.json\"), key=lambda x: int(os.path.splitext(x)[0]))\n",
    "\n",
    "        for file_name in json_files:\n",
    "            with open(file_name) as data_file:\n",
    "                data = json.load(data_file)\n",
    "\n",
    "                frame_kps_mp33 = [] # For all 33 MediaPipe keypoints (66 values)\n",
    "\n",
    "                mp_pose_landmarks = data.get(\"pose\", [])\n",
    "\n",
    "                if not mp_pose_landmarks:\n",
    "                    # Fill with zeros if no pose landmarks are found\n",
    "                    frame_kps_mp33 = [0.0] * NUM_OUTPUT_VALUES\n",
    "                    # print(f\"Warning: No pose landmarks in {file_name}. Filling with zeros.\")\n",
    "                else:\n",
    "                    # Extract x, y for all 33 landmarks\n",
    "                    for landmark_idx in range(NUM_MEDIAPIPE_KEYPOINTS):\n",
    "                        if landmark_idx < len(mp_pose_landmarks):\n",
    "                            landmark = mp_pose_landmarks[landmark_idx]\n",
    "                            frame_kps_mp33.append(landmark.get('x', 0.0))\n",
    "                            frame_kps_mp33.append(landmark.get('y', 0.0))\n",
    "                        else:\n",
    "                            # Should not happen if mp_pose_landmarks has 33 elements\n",
    "                            # or if we are iterating up to len(mp_pose_landmarks)\n",
    "                            # However, to be safe, if a landmark is missing for some reason before 33.\n",
    "                            frame_kps_mp33.extend([0.0, 0.0])\n",
    "\n",
    "                    # Ensure we always have NUM_OUTPUT_VALUES values\n",
    "                    # This is important if mp_pose_landmarks had less than 33 elements\n",
    "                    # (though MediaPipe typically returns all 33 or none)\n",
    "                    if len(frame_kps_mp33) < NUM_OUTPUT_VALUES:\n",
    "                        frame_kps_mp33.extend([0.0] * (NUM_OUTPUT_VALUES - len(frame_kps_mp33)))\n",
    "                    elif len(frame_kps_mp33) > NUM_OUTPUT_VALUES: # Should not happen with current logic\n",
    "                        frame_kps_mp33 = frame_kps_mp33[:NUM_OUTPUT_VALUES]\n",
    "\n",
    "\n",
    "                kps_all_frames.append(frame_kps_mp33)\n",
    "\n",
    "        output_dir_for_action = os.path.join(data_path, activity_name)\n",
    "        if not os.path.isdir(output_dir_for_action):\n",
    "             os.makedirs(output_dir_for_action)\n",
    "\n",
    "        output_file_name = f\"{activity_name}{frame_set}_mp33.txt\" # Added _mp33 to distinguish\n",
    "        output_file_path = os.path.join(output_dir_for_action, output_file_name)\n",
    "\n",
    "        with open(output_file_path, \"w\") as text_file:\n",
    "            for frame_data in kps_all_frames:\n",
    "                if len(frame_data) != NUM_OUTPUT_VALUES:\n",
    "                    print(f\"Error: Frame data for {output_file_name} has {len(frame_data)} values, expected {NUM_OUTPUT_VALUES}. Skipping frame or writing as is.\")\n",
    "                    # Decide how to handle this: skip, pad, or write as is. For now, writing as is.\n",
    "                \n",
    "                for i, val in enumerate(frame_data):\n",
    "                    text_file.write('{}'.format(val))\n",
    "                    # Adjust comma separation for NUM_OUTPUT_VALUES\n",
    "                    if i < (NUM_OUTPUT_VALUES - 1):\n",
    "                        text_file.write(',')\n",
    "                text_file.write('\\n')\n",
    "        print(f\"Successfully wrote MediaPipe 42-point data for {activity_name} video {video_num_loop} to {output_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

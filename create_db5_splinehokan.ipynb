{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59181a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Processing activity: heel_hook in C:\\kanno\\vscode\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\heel_hook\n",
      "Warning: Directory not found for activity heel_hook, skipping: C:\\kanno\\vscode\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\heel_hook\n",
      "Processing activity: deadpoint in C:\\kanno\\vscode\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\deadpoint\n",
      "Warning: Directory not found for activity deadpoint, skipping: C:\\kanno\\vscode\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\deadpoint\n",
      "Processing activity: dyno in C:\\kanno\\vscode\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\dyno\n",
      "Warning: Directory not found for activity dyno, skipping: C:\\kanno\\vscode\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\dyno\n",
      "Processing activity: cross_move in C:\\kanno\\vscode\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\cross_move\n",
      "Warning: Directory not found for activity cross_move, skipping: C:\\kanno\\vscode\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\\cross_move\n",
      "------------------------------\n",
      "Database creation process finished.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Creates database from converted MediaPipe output files (should now be in .txt format with _mp33 suffix)\n",
    "for use with RNN for Human Activity Recognition - 2D Pose Input (now 33*2D = 66 features)\n",
    "\n",
    "Adapted from original OpenPose script by Stuart Eiffert 13/12/2017\n",
    "Modifications for MediaPipe (33 points) by Your Name/AI DATE\n",
    "\n",
    "All code is provided under the MIT License (assuming original license applies)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "# ★★★ pandasライブラリをインポートします ★★★\n",
    "import pandas as pd\n",
    "\n",
    "# --- Configuration for Output Files ---\n",
    "# These files will be created in the 'data_path' directory specified below.\n",
    "test_file_X = \"X_test.txt\"\n",
    "test_file_Y = \"Y_test.txt\"\n",
    "train_file_X = \"X_train.txt\"\n",
    "train_file_Y = \"Y_train.txt\"\n",
    "\n",
    "# --- Configuration based on your MediaPipe setup ---\n",
    "# MODIFIED: Path to the root directory where action folders (containing _mp33.txt files) are located.\n",
    "# This should be the 'MP_Data_JSON' directory.\n",
    "# If MP_Data_JSON is in the same directory as this script, a relative path is fine.\n",
    "data_path = r\"C:\\kanno\\vscode\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\MP_Data_JSON\"\n",
    "# To use the script's current directory as a base for MP_Data_JSON:\n",
    "# data_path_abs = os.path.join(os.getcwd(), \"MP_Data_JSON\") # Use this if you prefer an absolute path from start\n",
    "\n",
    "# MODIFIED: Your list of actions from the MediaPipe script\n",
    "activity_list = ['heel_hook', 'deadpoint', 'dyno', 'cross_move']\n",
    "#activity_list = ['deadpoint', 'cross_move']\n",
    "# Original script's variables, kept for context\n",
    "# cluster_nums=4\n",
    "# camera_nums=1\n",
    "# subject_nums=12\n",
    "# activity_nums=len(activity_list)\n",
    "# repetition_nums=5\n",
    "\n",
    "# --- RNN Sequence Configuration ---\n",
    "num_steps = 180 #32  # Window width for RNN input (number of frames per sequence)\n",
    "test_train_split = 0.0  # Percentage of data for training\n",
    "split = False  # If True, a second stage of shuffling and splitting is performed.\n",
    "overlap = 0.8125  # Overlap when creating sequences. 0 = 0% overlap.\n",
    "\n",
    "# --- Ensure data_path exists ---\n",
    "if not os.path.isdir(data_path):\n",
    "    print(f\"Error: data_path '{data_path}' not found. Please check the path.\")\n",
    "    exit() # Exit if base data path doesn't exist\n",
    "\n",
    "# --- Clean up old train/test files if they exist ---\n",
    "# Output files are placed in the 'data_path' directory.\n",
    "files_to_remove = [test_file_X, test_file_Y, train_file_X, train_file_Y]\n",
    "for f_name in files_to_remove:\n",
    "    f_path = os.path.join(data_path, f_name)\n",
    "    if os.path.exists(f_path):\n",
    "        print(f\"Removing existing file: {f_path}\")\n",
    "        os.remove(f_path)\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Store the original CWD to return to it if needed at the very end,\n",
    "# or to construct absolute paths if data_path is relative.\n",
    "initial_cwd = os.getcwd()\n",
    "abs_data_path = os.path.abspath(data_path) # Use absolute path for data_path internally\n",
    "\n",
    "# Process each activity\n",
    "for activity_idx, activity_name in enumerate(activity_list):\n",
    "    current_activity_path_relative_to_abs_data_path = activity_name # e.g., \"heel_hook\"\n",
    "    current_activity_full_path = os.path.join(abs_data_path, current_activity_path_relative_to_abs_data_path)\n",
    "    \n",
    "    print(f\"Processing activity: {activity_name} in {current_activity_full_path}\")\n",
    "\n",
    "    if not os.path.isdir(current_activity_full_path):\n",
    "        print(f\"Warning: Directory not found for activity {activity_name}, skipping: {current_activity_full_path}\")\n",
    "        continue\n",
    "\n",
    "    # Change directory into the activity's folder\n",
    "    try:\n",
    "        os.chdir(current_activity_full_path)\n",
    "        print(f\"  Changed CWD to: {os.getcwd()}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  Error: Could not change directory to {current_activity_full_path}, skipping activity.\")\n",
    "        # Change back to abs_data_path before continuing to next activity iteration\n",
    "        os.chdir(abs_data_path) # Go back to parent (e.g., MP_Data_JSON)\n",
    "        continue\n",
    "\n",
    "    # MODIFIED: Search for files ending with _mp33.txt within the current activity directory\n",
    "    for file_name_in_activity_dir in sorted(glob.glob(\"*_mp33.txt\")):\n",
    "        print(f\"    Processing file: {file_name_in_activity_dir}\")\n",
    "\n",
    "        is_train = np.random.rand() < test_train_split\n",
    "        print(f\"      Assigning to {'train' if is_train else 'test'} set.\")\n",
    "\n",
    "        # --- ★★★ ここからが修正部分です ★★★ ---\n",
    "        try:\n",
    "            # pandasでテキストファイルを読み込みます。\n",
    "            # '0.0'は欠損値(NaN)として扱います。ヘッダーはないのでNoneを指定。\n",
    "            data_df = pd.read_csv(file_name_in_activity_dir, header=None, na_values=0.0)\n",
    "            \n",
    "            # DataFrameが空でないことを確認\n",
    "            if data_df.empty:\n",
    "                print(f\"      Warning: File {file_name_in_activity_dir} is empty or could not be parsed, skipping.\")\n",
    "                continue\n",
    "\n",
    "            # スプライン補間を実行します。\n",
    "            # method='spline'と次数(order=3が一般的)を指定します。\n",
    "            # スプライン補間は一定数の非欠損値が必要なため、データが少なすぎるとエラーになることがあります。\n",
    "            # そこで、先に線形補間で大まかに埋めてからスプラインを適用すると安定します。\n",
    "            data_df.interpolate(method='linear', axis=0, inplace=True, limit_direction='both')\n",
    "            data_df.interpolate(method='spline', order=3, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "            # 補間後にもNaNが残る場合に備えて0.0で埋めます\n",
    "            data_df.fillna(0.0, inplace=True)\n",
    "\n",
    "            # DataFrameを元のテキスト形式（文字列のリスト）に戻します。\n",
    "            # これで以降のコードは変更不要です。\n",
    "            lines_as_strings = []\n",
    "            for index, row in data_df.iterrows():\n",
    "                # 各行をカンマ区切りの文字列に変換し、末尾に改行を追加\n",
    "                line = \",\".join(row.astype(str).tolist())\n",
    "                lines_as_strings.append(line + '\\n')\n",
    "            file_text = lines_as_strings\n",
    "        \n",
    "        except FileNotFoundError:\n",
    "            print(f\"      Error: File not found {file_name_in_activity_dir} within {os.getcwd()}, skipping.\")\n",
    "            continue\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"      Warning: File {file_name_in_activity_dir} is empty, skipping.\")\n",
    "            continue\n",
    "        # --- ★★★ 修正はここまでです ★★★ ---\n",
    "        \n",
    "        if not file_text:\n",
    "            print(f\"      Warning: File {file_name_in_activity_dir} is empty, skipping.\")\n",
    "            continue\n",
    "\n",
    "        num_frames = len(file_text)\n",
    "        if num_frames < num_steps:\n",
    "            print(f\"      Warning: File {file_name_in_activity_dir} has {num_frames} frames, less than num_steps ({num_steps}). Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        if 1 - overlap <= 1e-6: # Check for overlap close to 1 or 1\n",
    "            print(f\"      Error: Invalid overlap value ({overlap}) results in zero or negative step. Skipping file.\")\n",
    "            num_framesets = 0 \n",
    "        else:\n",
    "            num_framesets = int((num_frames - num_steps) / (num_steps * (1 - overlap))) + 1\n",
    "        \n",
    "        print(f\"      Total frames: {num_frames}, Num sequences possible: {num_framesets}\")\n",
    "\n",
    "        if num_framesets <= 0:\n",
    "            print(f\"      Not enough frames in {file_name_in_activity_dir} to create any sequences with current settings. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        if is_train:\n",
    "            output_file_X_basename = train_file_X\n",
    "            output_file_Y_basename = train_file_Y\n",
    "        else:\n",
    "            output_file_X_basename = test_file_X\n",
    "            output_file_Y_basename = test_file_Y\n",
    "\n",
    "        # Output files (X_train.txt etc.) are in the abs_data_path directory\n",
    "        x_output_full_path = os.path.join(abs_data_path, output_file_X_basename)\n",
    "        y_output_full_path = os.path.join(abs_data_path, output_file_Y_basename)\n",
    "\n",
    "        try:\n",
    "            with open(x_output_full_path, 'a') as x_file:\n",
    "                for frameset_idx in range(num_framesets):\n",
    "                    start_frame = int(frameset_idx * num_steps * (1 - overlap))\n",
    "                    end_frame = start_frame + num_steps\n",
    "                    \n",
    "                    # Ensure the slice is within bounds\n",
    "                    if start_frame < 0 or end_frame > num_frames or start_frame >= end_frame :\n",
    "                        print(f\"      Warning: Invalid frame slice [{start_frame}:{end_frame}] for num_frames {num_frames}. Skipping frameset_idx {frameset_idx}.\")\n",
    "                        continue\n",
    "\n",
    "                    for line_idx in range(start_frame, end_frame):\n",
    "                        x_file.write(file_text[line_idx])\n",
    "            print(f\"      Appended {num_framesets} sequences to {x_output_full_path}\")\n",
    "\n",
    "            with open(y_output_full_path, 'a') as y_file:\n",
    "                for _ in range(num_framesets):\n",
    "                    y_file.write(str(activity_idx + 1) + \"\\n\") # Y label is 1-based activity index\n",
    "            print(f\"      Appended {num_framesets} labels to {y_output_full_path}\")\n",
    "\n",
    "        except IOError as e:\n",
    "            print(f\"      Error writing to output files: {e}\")\n",
    "            # If there was an error writing, we should still try to chdir back\n",
    "    \n",
    "    # After processing all files in the current_activity_full_path,\n",
    "    # change CWD back to abs_data_path (e.g., MP_Data_JSON)\n",
    "    # so the next iteration of the activity loop correctly resolves paths.\n",
    "    try:\n",
    "        os.chdir(abs_data_path)\n",
    "        print(f\"  Returned CWD to: {os.getcwd()} (after processing {activity_name})\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error on os.chdir back to base data_path ({abs_data_path}) \" \\\n",
    "              f\"from within {activity_name} directory structure: {e}\")\n",
    "        print(f\"  Current CWD is: {os.getcwd()}. Subsequent paths might be incorrect.\")\n",
    "        # Potentially exit or handle more robustly if this critical chdir fails.\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# The second splitting block (if split:) from the original script\n",
    "# This block should now operate with CWD being abs_data_path (e.g., MP_Data_JSON)\n",
    "if split:\n",
    "    print(f\"Performing second stage split (if split=True) in CWD: {os.getcwd()}\")\n",
    "    \n",
    "    # This part's logic for choosing source_X/Y_to_resplit needs review if `split=True` is used.\n",
    "    # As per original, it seems to assume a single pair of X/Y files to resplit.\n",
    "    # If the first loop already created X_train/Y_train and X_test/Y_test, what should this do?\n",
    "    # For now, let's assume it tries to resplit the training data further, or a combined set if available.\n",
    "    # This is a placeholder, the exact files to read here depend on the desired workflow for `split=True`.\n",
    "    source_X_to_resplit = train_file_X # Example: re-split the training data\n",
    "    source_Y_to_resplit = train_file_Y # Example: re-split the training data\n",
    "\n",
    "    # Ensure full paths are used for reading, as CWD is now abs_data_path\n",
    "    path_X_to_resplit = os.path.join(abs_data_path, source_X_to_resplit)\n",
    "    path_Y_to_resplit = os.path.join(abs_data_path, source_Y_to_resplit)\n",
    "\n",
    "    X_data, Y_data = [], []\n",
    "    try:\n",
    "        if os.path.exists(path_X_to_resplit):\n",
    "            with open(path_X_to_resplit, 'r') as X_file_handle:\n",
    "                X_data = X_file_handle.readlines()\n",
    "        else:\n",
    "            print(f\"Error: Source file for X re-split not found: {path_X_to_resplit}\")\n",
    "\n",
    "        if os.path.exists(path_Y_to_resplit):\n",
    "            with open(path_Y_to_resplit, 'r') as Y_file_handle:\n",
    "                Y_data = Y_file_handle.readlines()\n",
    "        else:\n",
    "            print(f\"Error: Source file for Y re-split not found: {path_Y_to_resplit}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error reading files for second split: {e}. Skipping second split.\")\n",
    "\n",
    "    if X_data and Y_data:\n",
    "        print(f\"  Re-splitting {len(Y_data)} sequences from {source_X_to_resplit} and {source_Y_to_resplit}\")\n",
    "        # Remove old files again before re-writing test/train from this split\n",
    "        for f_name in files_to_remove:\n",
    "            f_path = os.path.join(abs_data_path, f_name)\n",
    "            if os.path.exists(f_path):\n",
    "                os.remove(f_path)\n",
    "\n",
    "        # Y_data contains one label per sequence created in the first loop\n",
    "        # msk should be the same length as the number of sequences in Y_data\n",
    "        num_sequences_to_resplit = len(Y_data)\n",
    "        msk = np.random.rand(num_sequences_to_resplit) < test_train_split\n",
    "        \n",
    "        current_X_sequence_lines = []\n",
    "        y_data_idx = 0 # To iterate through Y_data and msk\n",
    "\n",
    "        for i, x_line in enumerate(X_data):\n",
    "            current_X_sequence_lines.append(x_line)\n",
    "            if (i + 1) % num_steps == 0: # A full sequence for X has been collected\n",
    "                if y_data_idx < num_sequences_to_resplit:\n",
    "                    is_train_for_sequence = msk[y_data_idx]\n",
    "                    target_X_basename = train_file_X if is_train_for_sequence else test_file_X\n",
    "                    target_Y_basename = train_file_Y if is_train_for_sequence else test_file_Y\n",
    "\n",
    "                    x_out_f_path = os.path.join(abs_data_path, target_X_basename)\n",
    "                    y_out_f_path = os.path.join(abs_data_path, target_Y_basename)\n",
    "\n",
    "                    with open(x_out_f_path, 'a') as x_out_f:\n",
    "                        for line_in_seq in current_X_sequence_lines:\n",
    "                            x_out_f.write(line_in_seq)\n",
    "                    \n",
    "                    with open(y_out_f_path, 'a') as y_out_f:\n",
    "                        y_out_f.write(Y_data[y_data_idx]) # Y_data already has newlines\n",
    "                    \n",
    "                    y_data_idx += 1\n",
    "                current_X_sequence_lines = [] # Reset for next sequence\n",
    "        \n",
    "        print(\"  Second stage split completed.\")\n",
    "        # print(msk)\n",
    "    elif split: # Only print if split was true and data wasn't found\n",
    "        print(\"  Skipping second stage split due to missing data.\")\n",
    "\n",
    "\n",
    "# Optional: change back to the directory where the script was initially launched\n",
    "# os.chdir(initial_cwd)\n",
    "print(\"Database creation process finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

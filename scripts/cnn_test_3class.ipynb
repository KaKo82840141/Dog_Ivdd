{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915e669e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading model: C:\\kanno\\vscode\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\data\\models_cnn_traj\\traj_cnn_3cls_20260112-041725.h5\n",
      "Found 380 images belonging to 3 classes.\n",
      "[INFO] class_indices (dir -> index): {'normal': 0, 'one': 1, 'two': 2}\n",
      "[INFO] generator label order: ['normal', 'one', 'two']\n",
      "[INFO] display/order for outputs: ['one', 'two', 'normal']\n",
      "\u001b[1m  7/380\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 8ms/step  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\kanno\\envs\\MLya\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step\n",
      "✅ 混同行列を保存しました: C:\\kanno\\vscode\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\data\\output\\confusion_matrix\\confusion_matrix_20260112_162604.png\n",
      "\n",
      "[Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         one     0.0118    0.0167    0.0138        60\n",
      "         two     0.0214    0.0543    0.0307        92\n",
      "      normal     0.0164    0.0044    0.0069       228\n",
      "\n",
      "    accuracy                         0.0184       380\n",
      "   macro avg     0.0165    0.0251    0.0171       380\n",
      "weighted avg     0.0169    0.0184    0.0138       380\n",
      "\n",
      "✅ 誤分類CSVを保存しました: C:\\kanno\\vscode\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\data\\output\\misclassified\\misclassified_20260112_162604.csv\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "3-class CNN evaluator (one/two/normal)\n",
    "- Fixes applied:\n",
    "  1) クラス順のズレ補正（学習順→ジェネレータ順マッピング）\n",
    "  2) 学習と同一の前処理: 画像は RGB / (300,300) / 1./255\n",
    "  3) 二重正規化の防止: ImageDataGenerator(rescale=1./255) のみ。追加の /255 はしない\n",
    "  4) 入力チャネルをRGB固定（color_mode='rgb'）\n",
    "  7) predict前に test_gen.reset() を実行し順序を固定\n",
    "\"\"\"\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# =========================\n",
    "# パス設定（必要に応じて変更）\n",
    "# =========================\n",
    "TEST_DIR   = r\"C:\\path\\to\\data\\test_cnn\"  # フォルダ直下に one/ two/ normal/ の3フォルダ\n",
    "MODEL_PATH = r\"C:\\path\\to\\data\\models_cnn_traj\\traj_cnn_3cls_xxx.h5\"\n",
    "OUT_ROOT   = r\"C:\\path\\to\\data\\output\"\n",
    "\n",
    "CM_DIR   = os.path.join(OUT_ROOT, \"confusion_matrix\")\n",
    "MISS_DIR = os.path.join(OUT_ROOT, \"misclassified\")\n",
    "REPORT_DIR = os.path.join(OUT_ROOT, \"report\")\n",
    "os.makedirs(CM_DIR, exist_ok=True)\n",
    "os.makedirs(MISS_DIR, exist_ok=True)\n",
    "os.makedirs(REPORT_DIR, exist_ok=True)\n",
    "\n",
    "# 出力ファイル名に使う時刻\n",
    "NOW = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# =========================\n",
    "# 評価パラメータ（学習に準拠）\n",
    "# =========================\n",
    "IMG_SIZE   = (300, 300)  # 学習と同じ\n",
    "BATCH_SIZE = 16\n",
    "# ★学習時の出力クラス順（学習スクリプトの CLASSES と一致させる）\n",
    "TRAIN_CLASSES = [\"one\", \"two\", \"normal\"]\n",
    "\n",
    "# =========================\n",
    "# 参考: GPU が見えているか（任意で確認）\n",
    "# =========================\n",
    "try:\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    print(f\"[INFO] GPUs: {gpus}\")\n",
    "    for g in gpus:\n",
    "        tf.config.experimental.set_memory_growth(g, True)\n",
    "except Exception as e:\n",
    "    print(\"[WARN] GPU 初期化メモリ成長設定に失敗:\", e)\n",
    "\n",
    "# =========================\n",
    "# モデル読込\n",
    "# =========================\n",
    "print(f\"[INFO] Loading model: {MODEL_PATH}\")\n",
    "model = load_model(MODEL_PATH)\n",
    "\n",
    "# =========================\n",
    "# テストジェネレータ（学習の前処理に合わせる）\n",
    "# =========================\n",
    "# 学習側は tf.image.resize + /255 のみ（Augなし）だったため、\n",
    "# 評価も RGB / (300,300) / 1./255 のみを適用。色はRGB固定。\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    color_mode='rgb',         # ④ RGB固定\n",
    "    interpolation='bilinear'  # tf.image.resize の既定（近似）に合わせる\n",
    ")\n",
    "\n",
    "# ジェネレータ側のクラス辞書（dir名→index）。※辞書順で index が決まる点に注意\n",
    "gen_class_indices = test_gen.class_indices  # 例: {'normal':0,'one':1,'two':2}\n",
    "# index→ラベル名 のリスト（ジェネレータ順）\n",
    "gen_labels = [k for k, _ in sorted(gen_class_indices.items(), key=lambda kv: kv[1])]\n",
    "\n",
    "print(\"[INFO] generator class_indices:\", gen_class_indices)\n",
    "print(\"[INFO] generator label order:\", gen_labels)\n",
    "print(\"[INFO] TRAIN_CLASSES (model output order):\", TRAIN_CLASSES)\n",
    "\n",
    "# =========================\n",
    "# 1) 学習クラス順 → ジェネレータ順へのマッピングベクトルを作成\n",
    "# =========================\n",
    "# ここでズレを補正しないと、混同行列やレポートが壊滅的に悪化します。\n",
    "try:\n",
    "    map_model_to_gen = np.array([gen_class_indices[c] for c in TRAIN_CLASSES], dtype=int)\n",
    "except KeyError as e:\n",
    "    raise RuntimeError(\n",
    "        f\"学習時クラス {TRAIN_CLASSES} に含まれる '{e.args[0]}' が \"\n",
    "        f\"テストディレクトリのクラス {list(gen_class_indices.keys())} に存在しません。\"\n",
    "    )\n",
    "\n",
    "# =========================\n",
    "# 予測（predict前に 7) reset を必ず実施）\n",
    "# =========================\n",
    "test_gen.reset()  # ⑦\n",
    "y_prob_model = model.predict(test_gen, verbose=1)  # (N, C_model) ここでの列順は TRAIN_CLASSES\n",
    "y_pred_model = np.argmax(y_prob_model, axis=1)     # モデル出力index（TRAIN_CLASSES系）\n",
    "\n",
    "# --- 1) マッピングで“ジェネレータindex系”の予測に変換 ---\n",
    "y_pred = map_model_to_gen[y_pred_model]            # これで y_true と同じ index 系列になる\n",
    "\n",
    "# --- 正解（ジェネレータindex）とファイル相対パス ---\n",
    "y_true = test_gen.classes\n",
    "file_relpaths = test_gen.filenames\n",
    "\n",
    "# =========================\n",
    "# 混同行列（PNG）— ラベル順は“ジェネレータ順”\n",
    "# =========================\n",
    "cm = confusion_matrix(y_true, y_pred, labels=list(range(len(gen_labels))))\n",
    "cm_png = os.path.join(CM_DIR, f\"confusion_matrix_3cls_{NOW}.png\")\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=gen_labels, yticklabels=gen_labels)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix (3-class)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(cm_png, dpi=150)\n",
    "plt.close()\n",
    "print(f\"✅ 混同行列を保存しました: {cm_png}\")\n",
    "\n",
    "# =========================\n",
    "# 分類レポート（ジェネレータ順で出力）\n",
    "# =========================\n",
    "report_txt = classification_report(\n",
    "    y_true, y_pred,\n",
    "    labels=list(range(len(gen_labels))),\n",
    "    target_names=gen_labels,\n",
    "    digits=4\n",
    ")\n",
    "report_path = os.path.join(REPORT_DIR, f\"classification_report_3cls_{NOW}.txt\")\n",
    "with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(report_txt)\n",
    "print(f\"✅ 分類レポート保存: {report_path}\")\n",
    "print(\"\\n[Classification Report]\\n\" + report_txt)\n",
    "\n",
    "# =========================\n",
    "# 誤分類一覧 CSV（True/Pred/各クラス確率）\n",
    "#  確率も“ジェネレータ順”で列整列（可読性のため）\n",
    "# =========================\n",
    "# モデル出力確率（TRAIN_CLASSES順）→ ジェネレータ順に並べ替え\n",
    "order_idx = [TRAIN_CLASSES.index(lbl) for lbl in gen_labels]  # ジェネ順で“モデル出力列の位置”を取る\n",
    "y_prob_genorder = y_prob_model[:, order_idx]                  # (N, C) with columns in gen_labels order\n",
    "\n",
    "df_all = pd.DataFrame({\n",
    "    \"file\": [os.path.join(TEST_DIR, p) for p in file_relpaths],\n",
    "    \"true\": [gen_labels[i] for i in y_true],\n",
    "    \"pred\": [gen_labels[i] for i in y_pred],\n",
    "})\n",
    "for i, lbl in enumerate(gen_labels):\n",
    "    df_all[f\"p_{lbl}\"] = y_prob_genorder[:, i]\n",
    "\n",
    "df_miss = df_all[df_all[\"true\"] != df_all[\"pred\"]].copy()\n",
    "miss_csv = os.path.join(MISS_DIR, f\"misclassified_3cls_{NOW}.csv\")\n",
    "df_miss.to_csv(miss_csv, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"✅ 誤分類CSVを保存しました: {miss_csv}\")\n",
    "\n",
    "# （必要なら全件CSVも保存）\n",
    "# pred_all_csv = os.path.join(OUT_ROOT, f\"predictions_3cls_{NOW}.csv\")\n",
    "# df_all.to_csv(pred_all_csv, index=False, encoding=\"utf-8-sig\")\n",
    "# print(f\"ℹ️ 全件予測CSV: {pred_all_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926ed2a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLya",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

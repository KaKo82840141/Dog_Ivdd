{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccee13c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import json\n",
    "\n",
    "# --- ★変更点: 描画するパーツを選択するフラグ ---\n",
    "# Trueに設定したパーツのランドマークが描画・保存されます\n",
    "DRAW_FACE = False\n",
    "DRAW_HANDS = True\n",
    "DRAW_POSE = False\n",
    "\n",
    "# 設定\n",
    "DATA_PATH = os.path.join(os.getcwd(), 'MP_Data_JSON')\n",
    "actions = np.array(['ageru', 'understand', 'annsinnsuru' , 'heavy'])  #クラスの部分。必要に応じて増やしていく。\n",
    "no_videos = 10  #入力する動画数(指定したファイルのパス)\n",
    "sequence_length = 30  #指定するフレーム数\n",
    "\n",
    "# MediaPipe Holisticモデルの準備\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def multiple_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results\n",
    "\n",
    "def draw_styled_landmarks(image, results):\n",
    "    \"\"\"\n",
    "    指定されたフラグに基づいて、顔、手、ポーズのランドマークを描画する関数\n",
    "    \"\"\"\n",
    "    # 顔のランドマークを描画 (DRAW_FACEがTrueの場合)\n",
    "    if DRAW_FACE and results.face_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            results.face_landmarks,\n",
    "            mp_holistic.FACEMESH_TESSELATION, # 顔のメッシュ\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp_drawing.DrawingSpec(color=(200, 200, 200), thickness=1, circle_radius=1) # メッシュを薄い灰色で描画\n",
    "        )\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            results.face_landmarks,\n",
    "            mp_holistic.FACEMESH_CONTOURS, # 顔の輪郭\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp_drawing.DrawingSpec(color=(224, 224, 224), thickness=1, circle_radius=1) # 輪郭を少し濃い灰色で描画\n",
    "        )\n",
    "\n",
    "    # 手のランドマークを描画 (DRAW_HANDSがTrueの場合)\n",
    "    if DRAW_HANDS:\n",
    "        # 左手\n",
    "        if results.left_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image,\n",
    "                results.left_hand_landmarks,\n",
    "                mp_holistic.HAND_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2, circle_radius=2), # 点を赤色で描画\n",
    "                connection_drawing_spec=mp_drawing.DrawingSpec(color=(255, 100, 100), thickness=2) # 線を薄い赤色で描画\n",
    "            )\n",
    "        # 右手\n",
    "        if results.right_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image,\n",
    "                results.right_hand_landmarks,\n",
    "                mp_holistic.HAND_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2), # 点を青色で描画\n",
    "                connection_drawing_spec=mp_drawing.DrawingSpec(color=(100, 100, 255), thickness=2) # 線を薄い青色で描画\n",
    "            )\n",
    "\n",
    "    # 姿勢のランドマークを描画 (DRAW_POSEがTrueの場合)\n",
    "    if DRAW_POSE and results.pose_landmarks:\n",
    "        # この部分は元のコードから削除されていますが、必要であれば\n",
    "        # DESIRED_POSE_LANDMARKSを定義した上で、元の描画ロジックをここに記述してください。\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            results.pose_landmarks,\n",
    "            mp_holistic.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "            connection_drawing_spec=mp_drawing.DrawingSpec(color=(51, 255, 51), thickness=2)\n",
    "        )\n",
    "\n",
    "\n",
    "def extract_keypoints(results):\n",
    "    \"\"\"\n",
    "    指定されたフラグに基づいて、顔、手、ポーズのキーポイントを抽出する関数\n",
    "    \"\"\"\n",
    "    keypoints_data = {}\n",
    "\n",
    "    # 顔のランドマークを抽出 (DRAW_FACEがTrueの場合)\n",
    "    if DRAW_FACE:\n",
    "        if results.face_landmarks:\n",
    "            face_landmarks_data = [{\"id\": i, \"x\": res.x, \"y\": res.y, \"z\": res.z} for i, res in enumerate(results.face_landmarks.landmark)]\n",
    "            keypoints_data[\"face\"] = face_landmarks_data\n",
    "        else:\n",
    "            keypoints_data[\"face\"] = []\n",
    "\n",
    "    # 左手のランドマークを抽出 (DRAW_HANDSがTrueの場合)\n",
    "    if DRAW_HANDS:\n",
    "        if results.left_hand_landmarks:\n",
    "            left_hand_landmarks_data = [{\"id\": i, \"x\": res.x, \"y\": res.y, \"z\": res.z} for i, res in enumerate(results.left_hand_landmarks.landmark)]\n",
    "            keypoints_data[\"left_hand\"] = left_hand_landmarks_data\n",
    "        else:\n",
    "            keypoints_data[\"left_hand\"] = []\n",
    "\n",
    "    # 右手のランドマークを抽出 (DRAW_HANDSがTrueの場合)\n",
    "    if DRAW_HANDS:\n",
    "        if results.right_hand_landmarks:\n",
    "            right_hand_landmarks_data = [{\"id\": i, \"x\": res.x, \"y\": res.y, \"z\": res.z} for i, res in enumerate(results.right_hand_landmarks.landmark)]\n",
    "            keypoints_data[\"right_hand\"] = right_hand_landmarks_data\n",
    "        else:\n",
    "            keypoints_data[\"right_hand\"] = []\n",
    "\n",
    "    # 姿勢のランドマークを抽出 (DRAW_POSEがTrueの場合)\n",
    "    if DRAW_POSE:\n",
    "        if results.pose_landmarks:\n",
    "            pose_landmarks_data = [{\"id\": i, \"x\": res.x, \"y\": res.y, \"z\": res.z, \"visibility\": res.visibility} for i, res in enumerate(results.pose_landmarks.landmark)]\n",
    "            keypoints_data[\"pose\"] = pose_landmarks_data\n",
    "        else:\n",
    "            keypoints_data[\"pose\"] = []\n",
    "\n",
    "    return keypoints_data\n",
    "\n",
    "# ★★★ ここからが新しく追加・修正した部分です ★★★\n",
    "\n",
    "def resample_keypoints(keypoints_list, target_frames):\n",
    "    \"\"\"\n",
    "    キーポイントデータのリストを、線形補間または間引きによって\n",
    "    指定したターゲットフレーム数にリサンプリングする。\n",
    "    \"\"\"\n",
    "    actual_frames = len(keypoints_list)\n",
    "    if actual_frames == target_frames:\n",
    "        return keypoints_list\n",
    "    \n",
    "    # 元のフレームのインデックスと新しいフレームのインデックスを生成\n",
    "    original_indices = np.linspace(0, actual_frames - 1, actual_frames)\n",
    "    target_indices = np.linspace(0, actual_frames - 1, target_frames)\n",
    "    \n",
    "    resampled_list = []\n",
    "    \n",
    "    for t_idx in target_indices:\n",
    "        # t_idxに最も近い元のフレームのインデックスを探す\n",
    "        p1_idx = int(np.floor(t_idx))\n",
    "        p2_idx = int(np.ceil(t_idx))\n",
    "\n",
    "        if p1_idx == p2_idx: # 補間不要（間引きの場合など）\n",
    "            resampled_list.append(keypoints_list[p1_idx])\n",
    "            continue\n",
    "        \n",
    "        # 線形補間の比率を計算\n",
    "        ratio = t_idx - p1_idx\n",
    "        if ratio < 1e-6: # ほぼp1と同じ位置\n",
    "             resampled_list.append(keypoints_list[p1_idx])\n",
    "             continue\n",
    "\n",
    "        # 補間元のフレームデータを取得\n",
    "        kp1 = keypoints_list[p1_idx]\n",
    "        kp2 = keypoints_list[p2_idx]\n",
    "        \n",
    "        # 新しい補間フレーム用のデータ構造を作成\n",
    "        interpolated_kp = {}\n",
    "        \n",
    "        # 各部位（'face', 'left_hand'など）についてループ\n",
    "        all_keys = set(kp1.keys()) | set(kp2.keys())\n",
    "        for part in all_keys:\n",
    "            part_kp1 = {lm['id']: lm for lm in kp1.get(part, [])}\n",
    "            part_kp2 = {lm['id']: lm for lm in kp2.get(part, [])}\n",
    "            \n",
    "            interpolated_part = []\n",
    "            \n",
    "            # 両方のフレームに存在するランドマークIDでループ\n",
    "            common_ids = set(part_kp1.keys()) & set(part_kp2.keys())\n",
    "            for lm_id in sorted(list(common_ids)):\n",
    "                lm1 = part_kp1[lm_id]\n",
    "                lm2 = part_kp2[lm_id]\n",
    "                \n",
    "                new_lm = {'id': lm_id}\n",
    "                # 各座標を線形補間\n",
    "                for coord in ['x', 'y', 'z']:\n",
    "                    if coord in lm1 and coord in lm2:\n",
    "                        new_lm[coord] = lm1[coord] * (1 - ratio) + lm2[coord] * ratio\n",
    "                \n",
    "                # visibilityもあれば補間（poseのみ）\n",
    "                if 'visibility' in lm1 and 'visibility' in lm2:\n",
    "                    new_lm['visibility'] = lm1['visibility'] * (1 - ratio) + lm2['visibility'] * ratio\n",
    "                \n",
    "                interpolated_part.append(new_lm)\n",
    "            \n",
    "            interpolated_kp[part] = interpolated_part\n",
    "            \n",
    "        resampled_list.append(interpolated_kp)\n",
    "        \n",
    "    return resampled_list\n",
    "\n",
    "# データの収集\n",
    "cv2.namedWindow('OpenCV Feed', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('OpenCV Feed', (1280, 720))\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic_model:\n",
    "    for action in actions:\n",
    "        action_path = os.path.join(DATA_PATH, action)\n",
    "        if not os.path.exists(action_path):\n",
    "            os.makedirs(action_path)\n",
    "\n",
    "        for video_num in range(1, no_videos + 1):\n",
    "            video_file_path = os.path.join(r\"D:\\\\卒研手話\\\\video\\\\hikensya5\", action + str(video_num) + '.mp4')\n",
    "            if not os.path.exists(video_file_path):\n",
    "                print(f\"Warning: Video file not found, skipping: {video_file_path}\")\n",
    "                continue\n",
    "\n",
    "            cap = cv2.VideoCapture(video_file_path)\n",
    "\n",
    "            # 1. まず動画の全フレームからキーポイントを抽出してリストに保存\n",
    "            all_keypoints = []\n",
    "            print(f'Processing video: {video_file_path}')\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break # 動画の終わり\n",
    "                \n",
    "                image, results = multiple_detection(frame, holistic_model)\n",
    "                draw_styled_landmarks(image, results)\n",
    "                \n",
    "                # 処理中のフレームを表示\n",
    "                cv2.putText(image, f'Extracting from {action} - Video {video_num}',\n",
    "                            (15, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "                keypoints = extract_keypoints(results)\n",
    "                all_keypoints.append(keypoints)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            \n",
    "            cap.release()\n",
    "            \n",
    "            actual_frame_count = len(all_keypoints)\n",
    "            if actual_frame_count == 0:\n",
    "                print(f\"Warning: No frames extracted from {video_file_path}. Skipping.\")\n",
    "                continue\n",
    "                \n",
    "            print(f'  -> Extracted {actual_frame_count} frames. Resampling to {sequence_length} frames.')\n",
    "            \n",
    "            # 2. フレーム数をsequence_lengthにリサンプリング（補間 or 間引き）\n",
    "            resampled_keypoints = resample_keypoints(all_keypoints, sequence_length)\n",
    "\n",
    "            # 3. リサンプリング後のキーポイントをJSONファイルに保存\n",
    "            video_data_save_path = os.path.join(action_path, str(video_num))\n",
    "            if not os.path.exists(video_data_save_path):\n",
    "                os.makedirs(video_data_save_path)\n",
    "            \n",
    "            for frame_num, keypoints in enumerate(resampled_keypoints):\n",
    "                json_path = os.path.join(video_data_save_path, f'{frame_num}.json')\n",
    "                with open(json_path, 'w') as f:\n",
    "                    json.dump(keypoints, f, indent=4)\n",
    "            \n",
    "            print(f'  -> Saved {len(resampled_keypoints)} frames to {video_data_save_path}')\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# ★★★ ここまでが新しく追加・修正した部分です ★★★"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

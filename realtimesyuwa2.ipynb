{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "064f0cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [STEP 1] ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŒ²ç”» ---\n",
      "ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã‚’åˆã‚ã›ã¦ãã ã•ã„ã€‚\n",
      "  's'ã‚­ãƒ¼: éŒ²ç”»é–‹å§‹\n",
      "  'e'ã‚­ãƒ¼: éŒ²ç”»åœæ­¢\n",
      "  'q'ã‚­ãƒ¼: ãƒ—ãƒ­ã‚°ãƒ©ãƒ çµ‚äº†\n",
      "\n",
      "[éŒ²ç”»é–‹å§‹] -> ä¿å­˜å…ˆ: c:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\Inference_Pipeline\\recorded_videos\\rec_20251012_155501.mp4\n",
      "[éŒ²ç”»çµ‚äº†]\n",
      "\n",
      "--- [STEP 2] MediaPipeã«ã‚ˆã‚‹éª¨æ ¼åº§æ¨™ã®æŠ½å‡º ---\n",
      "å‡¦ç†ä¸­ã®å‹•ç”»: c:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\Inference_Pipeline\\recorded_videos\\rec_20251012_155501.mp4\n",
      "JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ãŒå®Œäº†ã—ã¾ã—ãŸ: c:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\Inference_Pipeline\\json_output\\rec_20251012_155501\n",
      "\n",
      "--- [STEP 3] JSONã‹ã‚‰å˜ä¸€TXTãƒ•ã‚¡ã‚¤ãƒ«ã¸å¤‰æ› ---\n",
      "TXTãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®å¤‰æ›ãŒå®Œäº†ã—ã¾ã—ãŸ: c:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\Inference_Pipeline\\txt_converted\\rec_20251012_155501.txt\n",
      "\n",
      "--- [STEP 4] æ¨è«–ç”¨ãƒ‡ãƒ¼ã‚¿(X_val.txt)ã®ä½œæˆ ---\n",
      "1å€‹ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ç”Ÿæˆã—ã€æ¨è«–ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¾ã—ãŸ: c:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\Inference_Pipeline\\final_input\\X_val.txt\n",
      "\n",
      "--- [STEP 5] LSTMãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹æ¨è«– ---\n",
      "èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿: rows=30, features=84, blocks=1, shape=(1, 30, 84)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"lstm_rnn_53\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"lstm_rnn_53\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense_106 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>)                â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,890</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ time_distributed_53             â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,890</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_106 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,384</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_107 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>)                â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,384</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_107 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                 â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ dense_106 (\u001b[38;5;33mDense\u001b[0m)               â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m34\u001b[0m)                â”‚         \u001b[38;5;34m2,890\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ time_distributed_53             â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m34\u001b[0m)            â”‚         \u001b[38;5;34m2,890\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mTimeDistributed\u001b[0m)               â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_106 (\u001b[38;5;33mLSTM\u001b[0m)                 â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m34\u001b[0m)            â”‚         \u001b[38;5;34m9,384\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_107 (\u001b[38;5;33mLSTM\u001b[0m)                 â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m34\u001b[0m)                â”‚         \u001b[38;5;34m9,384\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_107 (\u001b[38;5;33mDense\u001b[0m)               â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m4\u001b[0m)                 â”‚           \u001b[38;5;34m140\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,798</span> (85.15 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,798\u001b[0m (85.15 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,798</span> (85.15 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,798\u001b[0m (85.15 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ãƒ¢ãƒ‡ãƒ«é‡ã¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\weights\\model_weights.weights.h5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step\n",
      "\n",
      "--- [æœ€çµ‚æ¨è«–çµæœ] ---\n",
      "éŒ²ç”»ã•ã‚ŒãŸæ‰‹è©±ã®å‹•ä½œã¯ã€ understand ã€ã§ã™\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã™ã¹ã¦ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "# TF2.xå½¢å¼ã§ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "class LSTM_RNN(tf.keras.Model):\n",
    "    def __init__(self, n_input, n_hidden, n_classes, **kwargs):\n",
    "        super(LSTM_RNN, self).__init__(**kwargs)\n",
    "        self.input_dense = tf.keras.layers.Dense(n_hidden, activation='relu')\n",
    "        self.time_dist_dense = tf.keras.layers.TimeDistributed(self.input_dense)\n",
    "        self.lstm1 = tf.keras.layers.LSTM(n_hidden, return_sequences=True)\n",
    "        self.lstm2 = tf.keras.layers.LSTM(n_hidden)\n",
    "        self.out = tf.keras.layers.Dense(n_classes)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.time_dist_dense(x)\n",
    "        x = self.lstm1(x)\n",
    "        x = self.lstm2(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# GPUã‚’ç„¡åŠ¹ã«ã™ã‚‹è¨­å®šï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "## ------------------------------------------------------------------------------------\n",
    "## --- ç·åˆè¨­å®š (â˜…â˜… ã“ã“ã‚’ã‚ãªãŸã®ç’°å¢ƒã«åˆã‚ã›ã¦å¿…ãšå¤‰æ›´ã—ã¦ãã ã•ã„) ---\\\n",
    "## ------------------------------------------------------------------------------------\\\n",
    "\n",
    "# 1. å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‘ã‚¹\n",
    "# (ä¾‹: \"C:\\\\Users\\\\your_name\\\\weights\\\\my_model.h5\")\n",
    "MODEL_PATH = r\"C:\\Users\\admin\\Downloads\\RNN-for-Human-Activity-Recognition-using-2D-Pose-Input-master\\weights\\model_weights.weights.h5\"\n",
    "\n",
    "# 2. ãƒ©ãƒ™ãƒ«ã®å®šç¾© (å­¦ç¿’æ™‚ã¨å®Œå…¨ã«åŒã˜é †ç•ªãƒ»å†…å®¹ã«ã—ã¦ãã ã•ã„)\n",
    "LABELS = [\n",
    "    \"ageru\", \"understand\", \"annsinnsuru\", \"heavy\"\n",
    "]\n",
    "\n",
    "# 3. ä¸­é–“ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»æœ€çµ‚çš„ãªæ¨è«–ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã™ã‚‹è¦ªãƒ•ã‚©ãƒ«ãƒ€\n",
    "# ã“ã®ãƒ•ã‚©ãƒ«ãƒ€å†…ã« 'recorded_videos', 'json_output' ãªã©ã®ãƒ•ã‚©ãƒ«ãƒ€ãŒè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã™ã€‚\n",
    "BASE_OUTPUT_DIR = os.path.join(os.getcwd(), \"Inference_Pipeline\")\n",
    "\n",
    "# 4. ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š (å­¦ç¿’æ™‚ã¨å®Œå…¨ã«åŒã˜ã«ã—ã¦ãã ã•ã„)\n",
    "SEQUENCE_LENGTH = 30  # 1å‹•ç”»ã‚ãŸã‚Šã®ãƒ•ãƒ¬ãƒ¼ãƒ æ•°\n",
    "N_HIDDEN = 34         # LSTMã®éš ã‚Œå±¤ã®æ•°\n",
    "\n",
    "## ------------------------------------------------------------------------------------\n",
    "## --- STEP 1: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŒ²ç”» (å¤‰æ›´ãªã—) ---\\\n",
    "## ------------------------------------------------------------------------------------\\\n",
    "def record_video(save_dir, sequence_length):\n",
    "    \"\"\"\n",
    "    Webã‚«ãƒ¡ãƒ©ã‹ã‚‰å‹•ç”»ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§éŒ²ç”»ã—ã€æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜ã™ã‚‹é–¢æ•°ã€‚\n",
    "    's'ã‚­ãƒ¼ã§éŒ²ç”»é–‹å§‹ã€'e'ã‚­ãƒ¼ã§éŒ²ç”»åœæ­¢ã€‚\n",
    "    Returns:\n",
    "        str: ä¿å­˜ã•ã‚ŒãŸå‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ãƒ«ãƒ‘ã‚¹ã€‚éŒ²ç”»ã•ã‚Œãªã‹ã£ãŸå ´åˆã¯Noneã€‚\n",
    "    \"\"\"\n",
    "    print(\"--- [STEP 1] ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŒ²ç”» ---\")\n",
    "    print(\"ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã‚’åˆã‚ã›ã¦ãã ã•ã„ã€‚\")\n",
    "    print(\"  's'ã‚­ãƒ¼: éŒ²ç”»é–‹å§‹\")\n",
    "    print(\"  'e'ã‚­ãƒ¼: éŒ²ç”»åœæ­¢\")\n",
    "    print(\"  'q'ã‚­ãƒ¼: ãƒ—ãƒ­ã‚°ãƒ©ãƒ çµ‚äº†\")\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"ã‚¨ãƒ©ãƒ¼: ã‚«ãƒ¡ãƒ©ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸã€‚\")\n",
    "        return None\n",
    "\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = 30.0\n",
    "\n",
    "    video_writer = None\n",
    "    is_recording = False\n",
    "    saved_filepath = None\n",
    "\n",
    "    # ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"ã‚¨ãƒ©ãƒ¼: ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’èª­ã¿å–ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚\")\n",
    "            break\n",
    "\n",
    "        display_frame = frame.copy()\n",
    "        \n",
    "        # éŒ²ç”»ä¸­ã®è¡¨ç¤º\n",
    "        if is_recording:\n",
    "            cv2.circle(display_frame, (40, 40), 15, (0, 0, 255), -1)\n",
    "            cv2.putText(display_frame, 'REC', (70, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            if video_writer:\n",
    "                video_writer.write(frame)\n",
    "\n",
    "        cv2.imshow('Real-time Video Recorder', display_frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == ord('s') and not is_recording:\n",
    "            is_recording = True\n",
    "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"rec_{timestamp}.mp4\"\n",
    "            saved_filepath = os.path.join(save_dir, filename)\n",
    "            \n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            video_writer = cv2.VideoWriter(saved_filepath, fourcc, fps, (frame_width, frame_height))\n",
    "            print(f\"\\n[éŒ²ç”»é–‹å§‹] -> ä¿å­˜å…ˆ: {saved_filepath}\")\n",
    "\n",
    "        elif key == ord('e') and is_recording:\n",
    "            print(\"[éŒ²ç”»çµ‚äº†]\")\n",
    "            is_recording = False\n",
    "            if video_writer:\n",
    "                video_writer.release()\n",
    "                video_writer = None\n",
    "            break # éŒ²ç”»ãŒçµ‚ã‚ã£ãŸã‚‰ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹\n",
    "\n",
    "        elif key == ord('q'):\n",
    "            print(\"ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’çµ‚äº†ã—ã¾ã™ã€‚\")\n",
    "            if video_writer:\n",
    "                video_writer.release()\n",
    "            saved_filepath = None # é€”ä¸­ã§çµ‚äº†ã—ãŸã®ã§ãƒ‘ã‚¹ã‚’ã‚¯ãƒªã‚¢\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return saved_filepath\n",
    "\n",
    "## ------------------------------------------------------------------------------------\n",
    "## --- STEP 2: MediaPipeã«ã‚ˆã‚‹éª¨æ ¼åº§æ¨™ã®æŠ½å‡º (å¤‰æ›´ãªã—) ---\\\n",
    "## ------------------------------------------------------------------------------------\\\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results\n",
    "\n",
    "def extract_keypoints(results):\n",
    "    keypoints = {}\n",
    "    # ä¸¡æ‰‹ã®ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã®ã¿ã‚’æŠ½å‡º\n",
    "    keypoints[\"left_hand\"] = [{\"id\": i, \"x\": res.x, \"y\": res.y, \"z\": res.z} for i, res in enumerate(results.left_hand_landmarks.landmark)] if results.left_hand_landmarks else []\n",
    "    keypoints[\"right_hand\"] = [{\"id\": i, \"x\": res.x, \"y\": res.y, \"z\": res.z} for i, res in enumerate(results.right_hand_landmarks.landmark)] if results.right_hand_landmarks else []\n",
    "    return keypoints\n",
    "\n",
    "def extract_landmarks_from_video(video_path, json_output_dir_base, sequence_length):\n",
    "    \"\"\"\n",
    "    å˜ä¸€ã®å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰MediaPipeã§æ‰‹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’æŠ½å‡ºã—ã€JSONãƒ•ã‚¡ã‚¤ãƒ«ç¾¤ã¨ã—ã¦ä¿å­˜ã™ã‚‹ã€‚\n",
    "    Returns:\n",
    "        str: JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒä¿å­˜ã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ã€‚\n",
    "    \"\"\"\n",
    "    print(\"\\n--- [STEP 2] MediaPipeã«ã‚ˆã‚‹éª¨æ ¼åº§æ¨™ã®æŠ½å‡º ---\")\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"ã‚¨ãƒ©ãƒ¼: å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {video_path}\")\n",
    "        return None\n",
    "\n",
    "    video_filename = os.path.basename(video_path)\n",
    "    video_name_no_ext = os.path.splitext(video_filename)[0]\n",
    "    \n",
    "    # ã“ã®å‹•ç”»ç”¨ã®JSONä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ\n",
    "    video_json_save_path = os.path.join(json_output_dir_base, video_name_no_ext)\n",
    "    os.makedirs(video_json_save_path, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    print(f\"å‡¦ç†ä¸­ã®å‹•ç”»: {video_path}\")\n",
    "\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        for frame_num in range(sequence_length):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(f\"è­¦å‘Š: å‹•ç”»ãŒ{sequence_length}ãƒ•ãƒ¬ãƒ¼ãƒ ã‚ˆã‚Šå‰ã«çµ‚äº†ã—ã¾ã—ãŸã€‚\")\n",
    "                break\n",
    "\n",
    "            _, results = mediapipe_detection(frame, holistic)\n",
    "            \n",
    "            keypoints = extract_keypoints(results)\n",
    "            json_path = os.path.join(video_json_save_path, f'{frame_num}.json')\n",
    "            with open(json_path, 'w') as f:\n",
    "                json.dump(keypoints, f, indent=4)\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ãŒå®Œäº†ã—ã¾ã—ãŸ: {video_json_save_path}\")\n",
    "    return video_json_save_path\n",
    "\n",
    "## ------------------------------------------------------------------------------------\n",
    "## --- STEP 3: JSONã‹ã‚‰å˜ä¸€TXTãƒ•ã‚¡ã‚¤ãƒ«ã¸å¤‰æ› (å¤‰æ›´ãªã—) ---\\\n",
    "## ------------------------------------------------------------------------------------\\\n",
    "def convert_json_to_txt(json_frames_dir, txt_output_dir):\n",
    "    \"\"\"\n",
    "    ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ç¾¤ã‚’ã€1è¡Œ1ãƒ•ãƒ¬ãƒ¼ãƒ ã®å˜ä¸€TXTãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›ã™ã‚‹ã€‚\n",
    "    Returns:\n",
    "        str: ç”Ÿæˆã•ã‚ŒãŸTXTãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã€‚\n",
    "    \"\"\"\n",
    "    print(\"\\n--- [STEP 3] JSONã‹ã‚‰å˜ä¸€TXTãƒ•ã‚¡ã‚¤ãƒ«ã¸å¤‰æ› ---\")\n",
    "    if not os.path.isdir(json_frames_dir):\n",
    "        print(f\"ã‚¨ãƒ©ãƒ¼: JSONãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {json_frames_dir}\")\n",
    "        return None\n",
    "\n",
    "    video_folder_name = os.path.basename(json_frames_dir)\n",
    "    os.makedirs(txt_output_dir, exist_ok=True)\n",
    "    \n",
    "    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹\n",
    "    output_txt_path = os.path.join(txt_output_dir, f\"{video_folder_name}.txt\")\n",
    "\n",
    "    NUM_KEYPOINTS_PER_HAND = 21\n",
    "    \n",
    "    kps_all_frames = []\n",
    "    \n",
    "    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ•ãƒ¬ãƒ¼ãƒ é †ï¼ˆ0.json, 1.json, ...ï¼‰ã«ã‚½ãƒ¼ãƒˆã—ã¦å–å¾—\n",
    "    json_files = sorted(\n",
    "        glob.glob(os.path.join(json_frames_dir, \"*.json\")), \n",
    "        key=lambda x: int(os.path.splitext(os.path.basename(x))[0])\n",
    "    )\n",
    "\n",
    "    if not json_files:\n",
    "        print(f\"è­¦å‘Š: JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™: {json_frames_dir}\")\n",
    "        return None\n",
    "        \n",
    "    for json_file_path in json_files:\n",
    "        with open(json_file_path) as data_file:\n",
    "            data = json.load(data_file)\n",
    "            frame_kps_hands = []\n",
    "            \n",
    "            # å·¦æ‰‹ (x, yã®ã¿)\n",
    "            left_hand = data.get(\"left_hand\", [])\n",
    "            if left_hand:\n",
    "                for kp in left_hand:\n",
    "                    frame_kps_hands.extend([kp.get('x', 0.0), kp.get('y', 0.0)])\n",
    "            else:\n",
    "                frame_kps_hands.extend([0.0] * (NUM_KEYPOINTS_PER_HAND * 2))\n",
    "\n",
    "            # å³æ‰‹ (x, yã®ã¿)\n",
    "            right_hand = data.get(\"right_hand\", [])\n",
    "            if right_hand:\n",
    "                for kp in right_hand:\n",
    "                    frame_kps_hands.extend([kp.get('x', 0.0), kp.get('y', 0.0)])\n",
    "            else:\n",
    "                frame_kps_hands.extend([0.0] * (NUM_KEYPOINTS_PER_HAND * 2))\n",
    "                \n",
    "            kps_all_frames.append(frame_kps_hands)\n",
    "\n",
    "    # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿\n",
    "    with open(output_txt_path, \"w\") as text_file:\n",
    "        for frame_data in kps_all_frames:\n",
    "            line = \",\".join(map(str, frame_data))\n",
    "            text_file.write(line + '\\n')\n",
    "            \n",
    "    print(f\"TXTãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®å¤‰æ›ãŒå®Œäº†ã—ã¾ã—ãŸ: {output_txt_path}\")\n",
    "    return output_txt_path\n",
    "\n",
    "## ------------------------------------------------------------------------------------\n",
    "## --- STEP 4: æ¨è«–ç”¨ãƒ‡ãƒ¼ã‚¿(X_val.txt)ã®ä½œæˆ (å¤‰æ›´ãªã—) ---\\\n",
    "## ------------------------------------------------------------------------------------\\\n",
    "def prepare_data_for_lstm(source_txt_path, final_output_path, num_steps, overlap=0.8125):\n",
    "    \"\"\"\n",
    "    å˜ä¸€ã®TXTãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ç·šå½¢è£œé–“ã¨ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’é©ç”¨ã—ã¦\n",
    "    LSTMæ¨è«–ç”¨ã®æœ€çµ‚çš„ãªå…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«(X_val.txt)ã‚’ä½œæˆã™ã‚‹ã€‚\n",
    "    Returns:\n",
    "        bool: æˆåŠŸã—ãŸå ´åˆã¯Trueã€å¤±æ•—ã—ãŸå ´åˆã¯Falseã€‚\n",
    "    \"\"\"\n",
    "    print(\"\\n--- [STEP 4] æ¨è«–ç”¨ãƒ‡ãƒ¼ã‚¿(X_val.txt)ã®ä½œæˆ ---\")\n",
    "    if not os.path.exists(source_txt_path):\n",
    "        print(f\"ã‚¨ãƒ©ãƒ¼: ã‚½ãƒ¼ã‚¹TXTãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {source_txt_path}\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€0.0ã‚’NaNã¨ã—ã¦æ‰±ã†\n",
    "        data_df = pd.read_csv(source_txt_path, header=None, na_values=0.0)\n",
    "        \n",
    "        # ç·šå½¢è£œé–“\n",
    "        data_df.interpolate(method='linear', axis=0, inplace=True, limit_direction='both')\n",
    "        # ãã‚Œã§ã‚‚æ®‹ã£ã¦ã„ã‚‹NaNã‚’0.0ã§åŸ‹ã‚ã‚‹\n",
    "        data_df.fillna(0.0, inplace=True)\n",
    "        \n",
    "        num_frames = len(data_df)\n",
    "        if num_frames < num_steps:\n",
    "            print(f\"ã‚¨ãƒ©ãƒ¼: ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™({num_frames}ãƒ•ãƒ¬ãƒ¼ãƒ )ã€‚æœ€ä½{num_steps}ãƒ•ãƒ¬ãƒ¼ãƒ å¿…è¦ã§ã™ã€‚\")\n",
    "            return False\n",
    "\n",
    "        # ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ç”Ÿæˆ\n",
    "        step_size = int(num_steps * (1 - overlap))\n",
    "        if step_size < 1: step_size = 1 # ã‚¼ãƒ­é™¤ç®—ã‚’é¿ã‘ã‚‹\n",
    "        \n",
    "        sequences = []\n",
    "        for start_frame in range(0, num_frames - num_steps + 1, step_size):\n",
    "            end_frame = start_frame + num_steps\n",
    "            sequence = data_df.iloc[start_frame:end_frame].values\n",
    "            sequences.append(sequence) # flattenã—ãªã„\n",
    "        \n",
    "        if not sequences:\n",
    "            print(\"ã‚¨ãƒ©ãƒ¼: ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\")\n",
    "            return False\n",
    "\n",
    "        # æœ€çµ‚çš„ãªãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿\n",
    "        with open(final_output_path, 'w') as f:\n",
    "            for seq in sequences:\n",
    "                np.savetxt(f, seq, delimiter=',')\n",
    "        \n",
    "        print(f\"{len(sequences)}å€‹ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ç”Ÿæˆã—ã€æ¨è«–ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¾ã—ãŸ: {final_output_path}\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ãƒ‡ãƒ¼ã‚¿æº–å‚™ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## ------------------------------------------------------------------------------------\n",
    "## --- STEP 5: LSTMãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹æ¨è«– (â˜…â˜… TensorFlow 2.x ã«æ›´æ–°) ---\\\n",
    "## ------------------------------------------------------------------------------------\\\n",
    "\n",
    "    \n",
    "\n",
    "# def run_inference(x_val_path, model_path, labels, n_steps, n_hidden):\n",
    "#     \"\"\"\n",
    "#     æº–å‚™ã•ã‚ŒãŸæ¨è«–ç”¨ãƒ‡ãƒ¼ã‚¿ã¨å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€æ‰‹è©±ã®æ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹ã€‚\n",
    "#     \"\"\"\n",
    "#     print(\"\\n--- [STEP 5] LSTMãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹æ¨è«– ---\")\n",
    "    \n",
    "#     n_classes = len(labels)\n",
    "    \n",
    "#     # -- ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° --\n",
    "#     def load_X(X_path):\n",
    "#         try:\n",
    "#             X_ = np.loadtxt(X_path, delimiter=',', dtype=np.float32)\n",
    "#             blocks = int(len(X_) / n_steps)\n",
    "#             X_ = np.array(np.split(X_, blocks))\n",
    "#             return X_\n",
    "#         except FileNotFoundError:\n",
    "#             print(f\"ã‚¨ãƒ©ãƒ¼: æ¨è«–ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ - {X_path}\")\n",
    "#             return None\n",
    "#         except Exception as e:\n",
    "#             print(f\"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")\n",
    "#             return None\n",
    "            \n",
    "#     # -- ãƒ¡ã‚¤ãƒ³å‡¦ç† --\n",
    "#     X_val = load_X(x_val_path)\n",
    "#     if X_val is None or len(X_val) == 0:\n",
    "#         print(\"æ¨è«–ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ã€å‡¦ç†ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚\")\n",
    "#         return\n",
    "\n",
    "#     n_input = X_val.shape[2]\n",
    "    \n",
    "#     # -- ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ --\n",
    "#     try:\n",
    "        \n",
    "\n",
    "#         # ã‚«ã‚¹ã‚¿ãƒ ã‚¯ãƒ©ã‚¹ã‚’ç™»éŒ²ã—ã¦èª­ã¿è¾¼ã‚€\n",
    "#         model = load_model(\n",
    "#             MODEL_PATH,\n",
    "#             custom_objects={'LSTM_RNN': LSTM_RNN}\n",
    "#         )           \n",
    "\n",
    "#         print(f\"ãƒ¢ãƒ‡ãƒ«ãŒæœŸå¾…ã™ã‚‹å…¥åŠ›å½¢çŠ¶: {model.input_shape}\")\n",
    "#         print(f\"ãƒ¢ãƒ‡ãƒ«ã‚’æ­£å¸¸ã«èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {model_path}\")\n",
    "#         model.summary() # ãƒ¢ãƒ‡ãƒ«ã®æ§‹é€ ã‚’è¡¨ç¤º\n",
    "#         print(f\"ç¾åœ¨ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒç”Ÿæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã®å½¢çŠ¶: {X_val.shape}\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")\n",
    "#         print(\"MODEL_PATHãŒæ­£ã—ã„ã‹ã€TensorFlow 2.xå½¢å¼ã§ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚\")\n",
    "#         print(\"ã‚‚ã—ãƒ¢ãƒ‡ãƒ«ãŒãªã„å ´åˆã¯ã€å…ˆã«TF2.xã§ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ãƒ»ä¿å­˜ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\")\n",
    "#         return\n",
    "\n",
    "#     # -- æ¨è«–ã®å®Ÿè¡Œ --\n",
    "#     try:\n",
    "#         # model.predict()ã§ä¸€æ‹¬ã—ã¦äºˆæ¸¬\n",
    "#         predictions_probabilities = model.predict(X_val)\n",
    "#         # æœ€ã‚‚ç¢ºç‡ã®é«˜ã„ã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—\n",
    "#         predictions = np.argmax(predictions_probabilities, axis=1)\n",
    "\n",
    "#         print(\"\\n--- [æœ€çµ‚æ¨è«–çµæœ] ---\")\n",
    "        \n",
    "#         # å„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®äºˆæ¸¬çµæœã‹ã‚‰ã€æœ€ã‚‚å¤šãäºˆæ¸¬ã•ã‚ŒãŸãƒ©ãƒ™ãƒ«ã‚’æœ€çµ‚çµæœã¨ã™ã‚‹\n",
    "#         if len(predictions) > 0:\n",
    "#             counts = np.bincount(predictions, minlength=n_classes)\n",
    "#             final_prediction_index = np.argmax(counts)\n",
    "#             final_prediction_label = labels[final_prediction_index]\n",
    "#             print(f\"ğŸ‘‰ éŒ²ç”»ã•ã‚ŒãŸæ‰‹è©±ã®å‹•ä½œã¯ã€ {final_prediction_label} ã€ã§ã™ã€‚\")\n",
    "#         else:\n",
    "#             print(\"äºˆæ¸¬å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"æ¨è«–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")\n",
    "def run_inference(x_val_path, model_path, labels, n_steps, n_hidden):\n",
    "    \"\"\"\n",
    "    x_val_path: 'final_input/X_val.txt' ã®ãƒ•ãƒ«ãƒ‘ã‚¹ï¼ˆé–¢æ•°å‘¼ã³å‡ºã—å´ã§æ¸¡ã™ï¼‰\n",
    "    model_path: .weights.h5 ã®ãƒ•ãƒ«ãƒ‘ã‚¹\n",
    "    labels: ãƒ©ãƒ™ãƒ«ãƒªã‚¹ãƒˆï¼ˆå­¦ç¿’æ™‚ã¨åŒã˜é †åºï¼‰\n",
    "    n_steps: ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ï¼ˆä¾‹: 30ï¼‰\n",
    "    n_hidden: LSTMã®ãƒ¦ãƒ‹ãƒƒãƒˆæ•°ï¼ˆå­¦ç¿’æ™‚ã¨åŒã˜ï¼‰\n",
    "    \"\"\"\n",
    "    print(\"\\n--- [STEP 5] LSTMãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹æ¨è«– ---\")\n",
    "\n",
    "    try:\n",
    "        # -------------------------\n",
    "        # 1) æ¨è«–ç”¨ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿\n",
    "        # -------------------------\n",
    "        if not os.path.exists(x_val_path):\n",
    "            print(f\"ã‚¨ãƒ©ãƒ¼: æ¨è«–ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {x_val_path}\")\n",
    "            return\n",
    "\n",
    "        X_loaded = np.loadtxt(x_val_path, delimiter=',', dtype=np.float32)\n",
    "        if X_loaded.size == 0:\n",
    "            print(\"ã‚¨ãƒ©ãƒ¼: èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚\")\n",
    "            return\n",
    "\n",
    "        # X_loaded ã¯ (rows, features) ã«ãªã‚‹ã¯ãš\n",
    "        if X_loaded.ndim == 1:\n",
    "            # 1è¡Œã—ã‹ç„¡ã„å ´åˆ -> (1, features)\n",
    "            X_loaded = X_loaded.reshape(1, -1)\n",
    "\n",
    "        rows, features = X_loaded.shape\n",
    "        if rows % n_steps != 0:\n",
    "            # å¤šãã®å ´åˆã€stepsã®å€æ•°ã«ãªã£ã¦ã„ã‚‹ã¯ãš\n",
    "            print(f\"è­¦å‘Š: èª­ã¿è¾¼ã‚“ã è¡Œæ•°({rows})ãŒã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·({n_steps})ã®å€æ•°ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "            # å¯èƒ½ãªã‚‰åˆ‡ã‚Šæ¨ã¦ã—ã¦é€²ã‚ã‚‹ï¼ˆå®‰å…¨ç­–ï¼‰\n",
    "            valid_rows = (rows // n_steps) * n_steps\n",
    "            if valid_rows == 0:\n",
    "                print(\"ã‚¨ãƒ©ãƒ¼: æœ‰åŠ¹ãªã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å‡¦ç†ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚\")\n",
    "                return\n",
    "            X_loaded = X_loaded[:valid_rows, :]\n",
    "            rows = valid_rows\n",
    "            print(f\"â†’ {valid_rows} è¡Œã«åˆ‡ã‚Šæ¨ã¦ã¾ã—ãŸã€‚\")\n",
    "        \n",
    "        blocks = rows // n_steps\n",
    "        X_val = X_loaded.reshape(blocks, n_steps, features)\n",
    "        print(f\"èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿: rows={rows}, features={features}, blocks={blocks}, shape={X_val.shape}\")\n",
    "\n",
    "        # n_input ã‚’è‡ªå‹•æ±ºå®šï¼ˆ1ãƒ•ãƒ¬ãƒ¼ãƒ ã‚ãŸã‚Šã®ç‰¹å¾´é‡ï¼‰\n",
    "        n_input = features\n",
    "        n_classes = len(labels)\n",
    "\n",
    "        # -------------------------\n",
    "        # 2) ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ï¼ˆæ§‹é€ ã‚’å­¦ç¿’æ™‚ã¨åˆã‚ã›ã‚‹ï¼‰\n",
    "        # -------------------------\n",
    "        model = LSTM_RNN(n_input, n_hidden, n_classes)\n",
    "\n",
    "        # ç¢ºå®Ÿã«å†…éƒ¨ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ãŒæ§‹ç¯‰ã•ã‚Œã‚‹ã‚ˆã†ã«ãƒ€ãƒŸãƒ¼å…¥åŠ›ã‚’ä¸€åº¦é€šã™\n",
    "        dummy = tf.zeros((1, n_steps, n_input), dtype=tf.float32)\n",
    "        _ = model(dummy)  # ã“ã‚Œã§å†…éƒ¨ãŒãƒ“ãƒ«ãƒ‰ã•ã‚Œã‚‹\n",
    "\n",
    "        # ãƒ¢ãƒ‡ãƒ«ã®ã‚µãƒãƒªï¼ˆunbuiltãŒå‡ºã‚‹å ´åˆã¯ã“ã“ã§ç¢ºèªï¼‰\n",
    "        model.summary()\n",
    "\n",
    "        # -------------------------\n",
    "        # 3) é‡ã¿èª­ã¿è¾¼ã¿\n",
    "        # -------------------------\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«é‡ã¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_path}\")\n",
    "            return\n",
    "\n",
    "        model.load_weights(model_path)\n",
    "        print(f\"ãƒ¢ãƒ‡ãƒ«é‡ã¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {model_path}\")\n",
    "\n",
    "        # -------------------------\n",
    "        # 4) æ¨è«–ï¼ˆãƒãƒƒãƒã§ï¼‰\n",
    "        # -------------------------\n",
    "        preds = model.predict(X_val)  # shape: (blocks, n_classes)\n",
    "        #print(f\"preds shape: {preds.shape}\")\n",
    "\n",
    "        # å„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã”ã¨ã®äºˆæ¸¬ã‚¯ãƒ©ã‚¹\n",
    "        pred_indices = np.argmax(preds, axis=1)\n",
    "        #print(f\"å„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®äºˆæ¸¬ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {pred_indices}\")\n",
    "\n",
    "        # å…¨ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®å¤šæ•°æ±ºã§æœ€çµ‚ãƒ©ãƒ™ãƒ«ã‚’æ±ºã‚ã‚‹ï¼ˆå…ƒã®ãƒ­ã‚¸ãƒƒã‚¯ã¨åŒã˜ï¼‰\n",
    "        counts = np.bincount(pred_indices, minlength=n_classes)\n",
    "        final_idx = np.argmax(counts)\n",
    "        final_label = labels[final_idx]\n",
    "\n",
    "        print(\"\\n--- [æœ€çµ‚æ¨è«–çµæœ] ---\")\n",
    "        print(f\"éŒ²ç”»ã•ã‚ŒãŸæ‰‹è©±ã®å‹•ä½œã¯ã€ {final_label} ã€ã§ã™\")\n",
    "        #print(f\"å„ã‚¯ãƒ©ã‚¹ã®ã‚«ã‚¦ãƒ³ãƒˆ: {counts}\")\n",
    "        #print(f\"å„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç¢ºç‡ã‚µãƒ³ãƒ—ãƒ«(æœ€åˆã®2ä»¶):\\n{preds[:min(2, len(preds))]}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã¾ãŸã¯æ¨è«–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## ------------------------------------------------------------------------------------\n",
    "## --- ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œãƒ¡ã‚¤ãƒ³å‡¦ç† (å¤‰æ›´ãªã—) ---\\\n",
    "## ------------------------------------------------------------------------------------\\\n",
    "if __name__ == '__main__':\n",
    "    # å„ã‚¹ãƒ†ãƒƒãƒ—ã§ä½¿ç”¨ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æº–å‚™\n",
    "    video_save_dir = os.path.join(BASE_OUTPUT_DIR, \"recorded_videos\")\n",
    "    json_output_dir = os.path.join(BASE_OUTPUT_DIR, \"json_output\")\n",
    "    txt_output_dir = os.path.join(BASE_OUTPUT_DIR, \"txt_converted\")\n",
    "    final_input_dir = os.path.join(BASE_OUTPUT_DIR, \"final_input\")\n",
    "    final_x_val_path = os.path.join(final_input_dir, \"X_val.txt\")\n",
    "\n",
    "    for d in [video_save_dir, json_output_dir, txt_output_dir, final_input_dir]:\n",
    "        os.makedirs(d, exist_ok=True)\n",
    "    \n",
    "    # STEP 1: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŒ²ç”»\n",
    "    recorded_video_path = record_video(video_save_dir, SEQUENCE_LENGTH)\n",
    "    \n",
    "    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†\n",
    "    if recorded_video_path:\n",
    "        try:\n",
    "            # STEP 2: MediaPipeã«ã‚ˆã‚‹éª¨æ ¼åº§æ¨™ã®æŠ½å‡º\n",
    "            json_frames_dir = extract_landmarks_from_video(recorded_video_path, json_output_dir, SEQUENCE_LENGTH)\n",
    "            if json_frames_dir is None: raise Exception(\"éª¨æ ¼åº§æ¨™ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚\")\n",
    "\n",
    "            # STEP 3: JSONã‹ã‚‰å˜ä¸€TXTãƒ•ã‚¡ã‚¤ãƒ«ã¸å¤‰æ›\n",
    "            converted_txt_path = convert_json_to_txt(json_frames_dir, txt_output_dir)\n",
    "            if converted_txt_path is None: raise Exception(\"TXTãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸã€‚\")\n",
    "            \n",
    "            # STEP 4: æ¨è«–ç”¨ãƒ‡ãƒ¼ã‚¿(X_val.txt)ã®ä½œæˆ\n",
    "            success = prepare_data_for_lstm(converted_txt_path, final_x_val_path, SEQUENCE_LENGTH)\n",
    "            if not success: raise Exception(\"æ¨è«–ç”¨ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚\")\n",
    "\n",
    "            # STEP 5: LSTMãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹æ¨è«–\n",
    "            run_inference(final_x_val_path, MODEL_PATH, LABELS, SEQUENCE_LENGTH, N_HIDDEN)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\nãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\")\n",
    "    else:\n",
    "        print(\"\\néŒ²ç”»ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚ŒãŸãŸã‚ã€å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã—ãŸã€‚\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
